{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "british-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "identified-package",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "better-hamburg",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.904\n",
      "SVC 0.896\n",
      "VotingClassifier 0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "comprehensive-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, n_jobs=-1)\n",
    "bag_clf.fit(x_train, y_train)\n",
    "y_pred = bag_clf.predict(x_test)\n",
    "print(clf.__class__.__name__, accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "christian-tactics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True)\n",
    "bag_clf.fit(x_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "severe-dietary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = bag_clf.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blind-eclipse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.421875  , 0.578125  ],\n",
       "       [0.3442623 , 0.6557377 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06451613, 0.93548387],\n",
       "       [0.37113402, 0.62886598],\n",
       "       [0.00507614, 0.99492386],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9673913 , 0.0326087 ],\n",
       "       [0.82978723, 0.17021277],\n",
       "       [0.00568182, 0.99431818],\n",
       "       [0.77714286, 0.22285714],\n",
       "       [0.85465116, 0.14534884],\n",
       "       [0.94923858, 0.05076142],\n",
       "       [0.06451613, 0.93548387],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99411765, 0.00588235],\n",
       "       [0.93846154, 0.06153846],\n",
       "       [0.99450549, 0.00549451],\n",
       "       [0.02312139, 0.97687861],\n",
       "       [0.38693467, 0.61306533],\n",
       "       [0.91803279, 0.08196721],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98295455, 0.01704545],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.62721893, 0.37278107],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00510204, 0.99489796],\n",
       "       [0.        , 1.        ],\n",
       "       [0.12299465, 0.87700535],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.36979167, 0.63020833],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.21359223, 0.78640777],\n",
       "       [0.41116751, 0.58883249],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01595745, 0.98404255],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98224852, 0.01775148],\n",
       "       [0.90374332, 0.09625668],\n",
       "       [0.95360825, 0.04639175],\n",
       "       [0.98224852, 0.01775148],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04639175, 0.95360825],\n",
       "       [0.98192771, 0.01807229],\n",
       "       [0.00537634, 0.99462366],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01058201, 0.98941799],\n",
       "       [0.985     , 0.015     ],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.36111111, 0.63888889],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.69060773, 0.30939227],\n",
       "       [0.99390244, 0.00609756],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87700535, 0.12299465],\n",
       "       [1.        , 0.        ],\n",
       "       [0.56923077, 0.43076923],\n",
       "       [0.12755102, 0.87244898],\n",
       "       [0.6631016 , 0.3368984 ],\n",
       "       [0.92121212, 0.07878788],\n",
       "       [0.        , 1.        ],\n",
       "       [0.18681319, 0.81318681],\n",
       "       [0.92146597, 0.07853403],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00564972, 0.99435028],\n",
       "       [0.04278075, 0.95721925],\n",
       "       [0.04790419, 0.95209581],\n",
       "       [0.34269663, 0.65730337],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.83157895, 0.16842105],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.28571429, 0.71428571],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94818653, 0.05181347],\n",
       "       [0.77653631, 0.22346369],\n",
       "       [0.00543478, 0.99456522],\n",
       "       [1.        , 0.        ],\n",
       "       [0.1827957 , 0.8172043 ],\n",
       "       [0.67777778, 0.32222222],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04678363, 0.95321637],\n",
       "       [0.53475936, 0.46524064],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00529101, 0.99470899],\n",
       "       [0.99489796, 0.00510204],\n",
       "       [0.23350254, 0.76649746],\n",
       "       [0.48815166, 0.51184834],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01612903, 0.98387097],\n",
       "       [0.98314607, 0.01685393],\n",
       "       [0.24193548, 0.75806452],\n",
       "       [0.9010989 , 0.0989011 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.77142857, 0.22857143],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01639344, 0.98360656],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98895028, 0.01104972],\n",
       "       [0.99441341, 0.00558659],\n",
       "       [0.        , 1.        ],\n",
       "       [0.953125  , 0.046875  ],\n",
       "       [0.99428571, 0.00571429],\n",
       "       [0.03448276, 0.96551724],\n",
       "       [0.21390374, 0.78609626],\n",
       "       [0.93567251, 0.06432749],\n",
       "       [0.29292929, 0.70707071],\n",
       "       [0.98360656, 0.01639344],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00518135, 0.99481865],\n",
       "       [0.72159091, 0.27840909],\n",
       "       [0.34444444, 0.65555556],\n",
       "       [0.52023121, 0.47976879],\n",
       "       [0.86458333, 0.13541667],\n",
       "       [0.91891892, 0.08108108],\n",
       "       [0.05527638, 0.94472362],\n",
       "       [0.82      , 0.18      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01169591, 0.98830409],\n",
       "       [0.97005988, 0.02994012],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00549451, 0.99450549],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96470588, 0.03529412],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.36956522, 0.63043478],\n",
       "       [0.28977273, 0.71022727],\n",
       "       [0.00571429, 0.99428571],\n",
       "       [0.        , 1.        ],\n",
       "       [0.35326087, 0.64673913],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96629213, 0.03370787],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.65174129, 0.34825871],\n",
       "       [0.88636364, 0.11363636],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98029557, 0.01970443],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.10582011, 0.89417989],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03743316, 0.96256684],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03468208, 0.96531792],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93548387, 0.06451613],\n",
       "       [0.74271845, 0.25728155],\n",
       "       [0.59390863, 0.40609137],\n",
       "       [0.        , 1.        ],\n",
       "       [0.16666667, 0.83333333],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96354167, 0.03645833],\n",
       "       [0.96756757, 0.03243243],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01058201, 0.98941799],\n",
       "       [0.        , 1.        ],\n",
       "       [0.41208791, 0.58791209],\n",
       "       [0.84536082, 0.15463918],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.015625  , 0.984375  ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94054054, 0.05945946],\n",
       "       [0.        , 1.        ],\n",
       "       [0.30857143, 0.69142857],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98918919, 0.01081081],\n",
       "       [0.79558011, 0.20441989],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [0.00515464, 0.99484536],\n",
       "       [0.06179775, 0.93820225],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0326087 , 0.9673913 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06842105, 0.93157895],\n",
       "       [1.        , 0.        ],\n",
       "       [0.83243243, 0.16756757],\n",
       "       [0.        , 1.        ],\n",
       "       [0.91709845, 0.08290155],\n",
       "       [0.98901099, 0.01098901],\n",
       "       [0.13559322, 0.86440678],\n",
       "       [0.18518519, 0.81481481],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.225     , 0.775     ],\n",
       "       [0.93714286, 0.06285714],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.48947368, 0.51052632],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08376963, 0.91623037],\n",
       "       [0.15025907, 0.84974093],\n",
       "       [0.98795181, 0.01204819],\n",
       "       [0.00534759, 0.99465241],\n",
       "       [1.        , 0.        ],\n",
       "       [0.45945946, 0.54054054],\n",
       "       [0.11299435, 0.88700565],\n",
       "       [0.55621302, 0.44378698],\n",
       "       [0.64367816, 0.35632184],\n",
       "       [0.00561798, 0.99438202],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.56872038, 0.43127962],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.21578947, 0.78421053],\n",
       "       [0.85561497, 0.14438503],\n",
       "       [0.08333333, 0.91666667],\n",
       "       [1.        , 0.        ],\n",
       "       [0.80701754, 0.19298246],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08839779, 0.91160221],\n",
       "       [0.01546392, 0.98453608],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99468085, 0.00531915],\n",
       "       [0.88359788, 0.11640212],\n",
       "       [0.15263158, 0.84736842],\n",
       "       [0.94512195, 0.05487805],\n",
       "       [0.01675978, 0.98324022],\n",
       "       [0.53846154, 0.46153846],\n",
       "       [0.08602151, 0.91397849],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [0.77777778, 0.22222222],\n",
       "       [0.00546448, 0.99453552],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95597484, 0.04402516],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.19251337, 0.80748663],\n",
       "       [0.98387097, 0.01612903],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.92045455, 0.07954545],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.82022472, 0.17977528],\n",
       "       [0.94011976, 0.05988024],\n",
       "       [1.        , 0.        ],\n",
       "       [0.72375691, 0.27624309],\n",
       "       [0.45549738, 0.54450262],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94581281, 0.05418719],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.85      , 0.15      ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.76300578, 0.23699422],\n",
       "       [0.14917127, 0.85082873],\n",
       "       [0.4516129 , 0.5483871 ],\n",
       "       [0.23333333, 0.76666667],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93413174, 0.06586826],\n",
       "       [0.86458333, 0.13541667],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9947644 , 0.0052356 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02247191, 0.97752809],\n",
       "       [0.94623656, 0.05376344],\n",
       "       [0.9673913 , 0.0326087 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.4640884 , 0.5359116 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00568182, 0.99431818],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00581395, 0.99418605],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95876289, 0.04123711],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08152174, 0.91847826],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.11428571, 0.88571429],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.4       , 0.6       ],\n",
       "       [0.07853403, 0.92146597],\n",
       "       [0.20670391, 0.79329609],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98863636, 0.01136364],\n",
       "       [0.23255814, 0.76744186],\n",
       "       [0.97948718, 0.02051282],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95212766, 0.04787234],\n",
       "       [0.27093596, 0.72906404],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04142012, 0.95857988],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03825137, 0.96174863],\n",
       "       [0.69945355, 0.30054645]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opening-spain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(x_test)\n",
    "\n",
    "# rought equivalent\n",
    "# bag_clf = BaggingClassifier(\n",
    "#     DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16),\n",
    "#     n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surprised-citizen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "harmful-victor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.10057649144401189\n",
      "sepal width (cm) 0.025033691548530666\n",
      "petal length (cm) 0.4497585566850691\n",
      "petal width (cm) 0.42463126032238846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "serious-wrapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5\n",
    ")\n",
    "ada_clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred_ada = ada_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "flying-prophet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numerous-assistant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "divine-elimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y_train - tree_reg1.predict(x_train)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(x_train, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pointed-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(x_train)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(x_train, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "plastic-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sum(tree.predict(x_test) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "# print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "herbal-metallic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "tough-papua",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = gbrt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "empirical-convert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, n_estimators=75)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find optimal # of tress with staged_prdict\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(x_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_test, y_pred) for y_pred in gbrt.staged_predict(x_test)]\n",
    "bst_n_estimators = numpy.argmin(errors) + 1\n",
    "\n",
    "gbrt_best = GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sacred-track",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "# early stopping by warm_start, which keeps existing trees\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_increasing = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(x_train, y_train)\n",
    "    y_pred = gbrt.predict(x_test)\n",
    "    val_error = mean_squared_error(y_test, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_incrasing = 0\n",
    "    else:\n",
    "        error_increasing += 1\n",
    "        if error_increasing == 5:\n",
    "            print(n_estimators)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "disciplinary-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost : Extreme Gradient Boosting\n",
    "# import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-checkout",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
