{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "second-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confident-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unexpected-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proud-berkeley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leaky ReLU\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "significant-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "resident-disabled",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 1.6314 - accuracy: 0.5054 - val_loss: 0.8886 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.8416 - accuracy: 0.7247 - val_loss: 0.7130 - val_accuracy: 0.7656 - loss: 0.8882 - accura - ETA: 1s - loss: - E\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7053 - accuracy: 0.7637 - val_loss: 0.6427 - val_accuracy: 0.7898\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6325 - accuracy: 0.7908 - val_loss: 0.5900 - val_accuracy: 0.8066\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.5992 - accuracy: 0.8021 - val_loss: 0.5582 - val_accuracy: 0.8198\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5624 - accuracy: 0.8142 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5379 - accuracy: 0.8218 - val_loss: 0.5156 - val_accuracy: 0.8304\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5152 - accuracy: 0.8297 - val_loss: 0.5079 - val_accuracy: 0.8284\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.5100 - accuracy: 0.8269 - val_loss: 0.4895 - val_accuracy: 0.8388\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4918 - accuracy: 0.8340 - val_loss: 0.4817 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "completed-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nominated-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PReLU\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "designing-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "durable-abraham",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.6969 - accuracy: 0.4974 - val_loss: 0.9255 - val_accuracy: 0.7186cy: \n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.8706 - accuracy: 0.7247 - val_loss: 0.7305 - val_accuracy: 0.7628\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7211 - accuracy: 0.7620 - val_loss: 0.6565 - val_accuracy: 0.7878\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.6448 - accuracy: 0.7881 - val_loss: 0.6004 - val_accuracy: 0.8046\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6078 - accuracy: 0.8004 - val_loss: 0.5656 - val_accuracy: 0.8182\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5693 - accuracy: 0.8118 - val_loss: 0.5406 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5428 - accuracy: 0.8193 - val_loss: 0.5196 - val_accuracy: 0.8312\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5193 - accuracy: 0.8283 - val_loss: 0.5113 - val_accuracy: 0.8320\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5128 - accuracy: 0.8273 - val_loss: 0.4916 - val_accuracy: 0.8380\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4941 - accuracy: 0.8313 - val_loss: 0.4826 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recreational-press",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x214adc19a30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SELU\n",
    "keras.layers.Dense(10, activation=\"selu\",\n",
    "                   kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "white-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "skilled-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "specified-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "controlled-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale inputs to mean 0 & std to 1\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "finished-wings",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 21s 11ms/step - loss: 1.3906 - accuracy: 0.4592 - val_loss: 0.7322 - val_accuracy: 0.7440\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.6896 - accuracy: 0.7526 - val_loss: 0.6524 - val_accuracy: 0.7696\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.5689 - accuracy: 0.8008 - val_loss: 0.5594 - val_accuracy: 0.7982\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.5811 - accuracy: 0.8027 - val_loss: 0.4854 - val_accuracy: 0.8346\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.5068 - accuracy: 0.8239 - val_loss: 0.4546 - val_accuracy: 0.8454\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "laughing-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU activation function\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "descending-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "flush-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "corresponding-supervisor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 19s 10ms/step - loss: 2.0875 - accuracy: 0.1791 - val_loss: 1.4671 - val_accuracy: 0.3808\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 1.3122 - accuracy: 0.4300 - val_loss: 1.0152 - val_accuracy: 0.5714\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 1.0237 - accuracy: 0.5732 - val_loss: 0.9137 - val_accuracy: 0.5864\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.8591 - accuracy: 0.6500 - val_loss: 0.7524 - val_accuracy: 0.7178\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.8111 - accuracy: 0.6780 - val_loss: 0.6833 - val_accuracy: 0.7482\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "encouraging-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch normalization\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "smart-spirit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "similar-fighter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "# 2 are trainable (backpropatation), 2 are not\n",
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "homeless-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "featured-brief",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.2287 - accuracy: 0.5994 - val_loss: 0.5525 - val_accuracy: 0.8230\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5995 - accuracy: 0.7958 - val_loss: 0.4724 - val_accuracy: 0.8472\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5311 - accuracy: 0.8172 - val_loss: 0.4375 - val_accuracy: 0.8552\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4885 - accuracy: 0.8294 - val_loss: 0.4152 - val_accuracy: 0.8602\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4717 - accuracy: 0.8347 - val_loss: 0.3998 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4420 - accuracy: 0.8459 - val_loss: 0.3867 - val_accuracy: 0.8696\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4286 - accuracy: 0.8495 - val_loss: 0.3763 - val_accuracy: 0.8702\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4087 - accuracy: 0.8552 - val_loss: 0.3713 - val_accuracy: 0.8736\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4080 - accuracy: 0.8562 - val_loss: 0.3632 - val_accuracy: 0.8746\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3903 - accuracy: 0.8614 - val_loss: 0.3573 - val_accuracy: 0.8758\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "published-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer before BatchNormalization does not  need bias\n",
    "# also batch normlization before activation function might be better\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cloudy-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "earned-orchestra",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 1.3677 - accuracy: 0.5605 - val_loss: 0.6767 - val_accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7136 - accuracy: 0.7702 - val_loss: 0.5566 - val_accuracy: 0.8180 ETA: 1s - loss: 0.7220 - accuracy - ETA: 0s -\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6123 - accuracy: 0.7988 - val_loss: 0.5007 - val_accuracy: 0.8362\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5547 - accuracy: 0.8148 - val_loss: 0.4666 - val_accuracy: 0.8448\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5255 - accuracy: 0.8232 - val_loss: 0.4434 - val_accuracy: 0.8538\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4947 - accuracy: 0.8326 - val_loss: 0.4263 - val_accuracy: 0.8548\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4736 - accuracy: 0.8385 - val_loss: 0.4130 - val_accuracy: 0.8570\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4550 - accuracy: 0.8443 - val_loss: 0.4035 - val_accuracy: 0.8608\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4494 - accuracy: 0.8439 - val_loss: 0.3943 - val_accuracy: 0.8642\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4333 - accuracy: 0.8495 - val_loss: 0.3875 - val_accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "automated-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model A to reuse\n",
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "lined-commons",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "related-breeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "parental-validity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "matched-jersey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cathedral-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "encouraging-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "czech-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "               optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "graduate-confusion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.9248 - accuracy: 0.6994 - val_loss: 0.3895 - val_accuracy: 0.8665\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3651 - accuracy: 0.8745 - val_loss: 0.3287 - val_accuracy: 0.8824\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3182 - accuracy: 0.8895 - val_loss: 0.3014 - val_accuracy: 0.8994\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3049 - accuracy: 0.8956 - val_loss: 0.2894 - val_accuracy: 0.9021\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2804 - accuracy: 0.9026 - val_loss: 0.2775 - val_accuracy: 0.9061\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2701 - accuracy: 0.9076 - val_loss: 0.2735 - val_accuracy: 0.9063\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2626 - accuracy: 0.9096 - val_loss: 0.2721 - val_accuracy: 0.9083\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2610 - accuracy: 0.9122 - val_loss: 0.2589 - val_accuracy: 0.9136\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2558 - accuracy: 0.9107 - val_loss: 0.2562 - val_accuracy: 0.9143\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2511 - accuracy: 0.9137 - val_loss: 0.2543 - val_accuracy: 0.9155\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2431 - accuracy: 0.9172 - val_loss: 0.2497 - val_accuracy: 0.9158\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2422 - accuracy: 0.9171 - val_loss: 0.2514 - val_accuracy: 0.9128\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2360 - accuracy: 0.9179 - val_loss: 0.2447 - val_accuracy: 0.9160\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2266 - accuracy: 0.9232 - val_loss: 0.2416 - val_accuracy: 0.9178\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2225 - accuracy: 0.9240 - val_loss: 0.2448 - val_accuracy: 0.9188\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2260 - accuracy: 0.9214 - val_loss: 0.2386 - val_accuracy: 0.9195\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2191 - accuracy: 0.9253 - val_loss: 0.2407 - val_accuracy: 0.9183\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2171 - accuracy: 0.9252 - val_loss: 0.2432 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2181 - accuracy: 0.9245 - val_loss: 0.2332 - val_accuracy: 0.9208\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2113 - accuracy: 0.9276 - val_loss: 0.2333 - val_accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20, validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "pressed-translation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_A.hb5\\assets\n"
     ]
    }
   ],
   "source": [
    "model_A.save(\"model_A.hb5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "racial-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "flying-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "brief-board",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 70ms/step - loss: 1.0360 - accuracy: 0.4975 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5883 - accuracy: 0.6971 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4380 - accuracy: 0.8854 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4021 - accuracy: 0.8712 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3361 - accuracy: 0.9348 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3113 - accuracy: 0.9233 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2817 - accuracy: 0.9299 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2632 - accuracy: 0.9379 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2373 - accuracy: 0.9481 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2229 - accuracy: 0.9657 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.93 - 0s 15ms/step - loss: 0.2155 - accuracy: 0.9590 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1834 - accuracy: 0.9738 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1671 - accuracy: 0.9828 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1527 - accuracy: 0.9915 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1595 - accuracy: 0.9904 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1473 - accuracy: 0.9937 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1412 - accuracy: 0.9944 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1242 - accuracy: 0.9931 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1224 - accuracy: 0.9931 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1096 - accuracy: 0.9912 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20, validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "severe-fourth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "floating-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"model_A.hb5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "wireless-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "illegal-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "comfortable-angle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 51ms/step - loss: 0.6170 - accuracy: 0.6184 - val_loss: 0.5860 - val_accuracy: 0.6318\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.5562 - accuracy: 0.6583 - val_loss: 0.5482 - val_accuracy: 0.6704\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4902 - accuracy: 0.7509 - val_loss: 0.5160 - val_accuracy: 0.7069\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4903 - accuracy: 0.7405 - val_loss: 0.4871 - val_accuracy: 0.7292\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 48ms/step - loss: 0.4387 - accuracy: 0.7774 - val_loss: 0.3469 - val_accuracy: 0.8631\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2976 - accuracy: 0.9143 - val_loss: 0.2609 - val_accuracy: 0.9249\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2036 - accuracy: 0.9777 - val_loss: 0.2115 - val_accuracy: 0.9554\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1754 - accuracy: 0.9789 - val_loss: 0.1795 - val_accuracy: 0.9696\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1349 - accuracy: 0.9809 - val_loss: 0.1565 - val_accuracy: 0.9757\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1172 - accuracy: 0.9973 - val_loss: 0.1396 - val_accuracy: 0.9807\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1139 - accuracy: 0.9931 - val_loss: 0.1269 - val_accuracy: 0.9838\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1001 - accuracy: 0.9931 - val_loss: 0.1166 - val_accuracy: 0.9858\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9888\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9899\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9899\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9899\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9899\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9899\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9899\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aboriginal-redhead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1408407837152481, 0.9704999923706055]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "entertaining-wrist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06832191348075867, 0.9929999709129333]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result is good in this instance with this configuration,\n",
    "# but transfer learning works best with deel convolutional neural networks\n",
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aerial-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "headed-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduling\n",
    "# power scheduling\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "latin-cancer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5980 - accuracy: 0.7933 - val_loss: 0.4031 - val_accuracy: 0.8598\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3829 - accuracy: 0.8636 - val_loss: 0.3714 - val_accuracy: 0.8720\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3491 - accuracy: 0.8771 - val_loss: 0.3748 - val_accuracy: 0.8740\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3277 - accuracy: 0.8813 - val_loss: 0.3503 - val_accuracy: 0.8792\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3172 - accuracy: 0.8859 - val_loss: 0.3451 - val_accuracy: 0.8780.3220 -  - ETA: 0s - loss:\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2922 - accuracy: 0.8941 - val_loss: 0.3418 - val_accuracy: 0.8820\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2869 - accuracy: 0.8969 - val_loss: 0.3361 - val_accuracy: 0.8872: 1s - l - ETA: 0s - loss: 0.287\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2720 - accuracy: 0.9033 - val_loss: 0.3412 - val_accuracy: 0.8838\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2729 - accuracy: 0.9001 - val_loss: 0.3296 - val_accuracy: 0.8866\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2585 - accuracy: 0.9068 - val_loss: 0.3268 - val_accuracy: 0.8892\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2529 - accuracy: 0.9102 - val_loss: 0.3278 - val_accuracy: 0.8886\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2484 - accuracy: 0.9102 - val_loss: 0.3342 - val_accuracy: 0.8830\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2420 - accuracy: 0.9147 - val_loss: 0.3264 - val_accuracy: 0.8896\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2372 - accuracy: 0.9148 - val_loss: 0.3296 - val_accuracy: 0.8894\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2363 - accuracy: 0.9154 - val_loss: 0.3253 - val_accuracy: 0.8880\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2309 - accuracy: 0.9180 - val_loss: 0.3215 - val_accuracy: 0.8922\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2234 - accuracy: 0.9209 - val_loss: 0.3248 - val_accuracy: 0.8912\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2247 - accuracy: 0.9194 - val_loss: 0.3200 - val_accuracy: 0.8938\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2235 - accuracy: 0.9215 - val_loss: 0.3241 - val_accuracy: 0.8906\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2226 - accuracy: 0.9224 - val_loss: 0.3223 - val_accuracy: 0.8904\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2193 - accuracy: 0.9230 - val_loss: 0.3219 - val_accuracy: 0.8916\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2162 - accuracy: 0.9225 - val_loss: 0.3194 - val_accuracy: 0.8946\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2126 - accuracy: 0.9250 - val_loss: 0.3206 - val_accuracy: 0.8910\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2076 - accuracy: 0.9276 - val_loss: 0.3226 - val_accuracy: 0.8898\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2103 - accuracy: 0.9253 - val_loss: 0.3225 - val_accuracy: 0.8920\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "injured-drawing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "decay = 1e-4\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = math.ceil(len(X_train) / batch_size)\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
    "\n",
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eleven-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "indie-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "unexpected-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "limited-franklin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.1430 - accuracy: 0.7303 - val_loss: 0.8429 - val_accuracy: 0.7736\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7260 - accuracy: 0.7897 - val_loss: 0.5542 - val_accuracy: 0.8248\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5940 - accuracy: 0.8225 - val_loss: 0.8124 - val_accuracy: 0.7616\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5440 - accuracy: 0.8361 - val_loss: 0.6128 - val_accuracy: 0.8352\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5008 - accuracy: 0.8459 - val_loss: 0.5940 - val_accuracy: 0.8422\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4403 - accuracy: 0.8645 - val_loss: 0.4643 - val_accuracy: 0.8622\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4233 - accuracy: 0.8722 - val_loss: 0.5178 - val_accuracy: 0.8552\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.88 - 5s 3ms/step - loss: 0.3643 - accuracy: 0.8844 - val_loss: 0.5250 - val_accuracy: 0.8490\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3663 - accuracy: 0.8857 - val_loss: 0.4709 - val_accuracy: 0.8656\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3198 - accuracy: 0.8972 - val_loss: 0.4766 - val_accuracy: 0.8778\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2971 - accuracy: 0.9024 - val_loss: 0.4498 - val_accuracy: 0.8814\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2736 - accuracy: 0.9102 - val_loss: 0.4493 - val_accuracy: 0.8704\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2536 - accuracy: 0.9144 - val_loss: 0.4616 - val_accuracy: 0.8824\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2347 - accuracy: 0.9204 - val_loss: 0.4579 - val_accuracy: 0.8872\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2149 - accuracy: 0.9264 - val_loss: 0.5143 - val_accuracy: 0.8846\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2121 - accuracy: 0.9272 - val_loss: 0.4635 - val_accuracy: 0.8870\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1804 - accuracy: 0.9382 - val_loss: 0.4971 - val_accuracy: 0.8768\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1734 - accuracy: 0.9408 - val_loss: 0.4704 - val_accuracy: 0.8894\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1580 - accuracy: 0.9469 - val_loss: 0.4828 - val_accuracy: 0.8932\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1510 - accuracy: 0.9483 - val_loss: 0.5025 - val_accuracy: 0.8864\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1405 - accuracy: 0.9508 - val_loss: 0.5644 - val_accuracy: 0.8854\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1317 - accuracy: 0.9551 - val_loss: 0.5463 - val_accuracy: 0.8928\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1227 - accuracy: 0.9587 - val_loss: 0.5783 - val_accuracy: 0.8882\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1096 - accuracy: 0.9635 - val_loss: 0.6094 - val_accuracy: 0.8888\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1085 - accuracy: 0.9637 - val_loss: 0.6082 - val_accuracy: 0.8892\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "portuguese-cholesterol",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEXCAYAAAC6baP3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxYElEQVR4nO3deXxU1f3/8dcnCxC2hE2WgIKsIioo4m6p1qqtX7EWlW5frVb99etS/bZabN1q5VsV61ZtFZe61LVu0LrgglGrrArKJhABgbDvBJIQwuf3x73BcZhJZoDJJJn38/GYR2buPffOZw5hPrnnnHuOuTsiIiKJykp3ACIi0rAocYiISFKUOEREJClKHCIikhQlDhERSYoSh4iIJEWJQ2QvmNkFZlaa5DFFZnZ/qmIK32Oxmf0mBecdbmZJjeGPrqM9qTOpX5Q4ZI+Y2eNm5jEek9IdW6qEn2941ObngQNT8F6/MLPpZlZqZpvM7HMzu3Vfv0+apKTOpO7kpDsAadDeAX4WtW17OgJJF3cvA8r25TnN7ELgPuBq4F0gFxgAHLMv3yddUlFnUrd0xSF7o8LdV0Y91gOY2bfMrNLMhlYXNrNLzWyzmR0Yvi4yswfN7F4z2xA+RptZVsQxbczsiXBfmZm9Y2YHR+y/IPyr/GQzm2VmW83sPTPrERmomf2XmX1iZuVmtsjMRplZk4j9i83sejN7KIxxmZldE7k/fPrP8MpjceT7R5TraWZjzWxlGMunZnZGkvV6JvCyuz/k7sXuPtfd/+nu/xv1mb5nZpPDellnZv8ys2YRRZrF+zzh8flmNsbMVpvZFjN738wGR5X5bzP7ysy2mdm/gY5R+282s1lR22psiopRZzeH/3YjzOzLMJZXzax9RJkcM7s74vfkbjP7m5kV1V6dsq8pcUhKuPv7wGjgqfDLvx9wF3CFuy+MKPoTgt/DY4BLgUuAqyL2Pw4cBQwDhgDbgDfNLC+iTFPgOuDC8DwFwIPVO83sVOBp4H7g4LDccOD/osK+GpgJHA7cDtxhZtV/5R8Z/rwY6BzxOlpL4A3gFOAw4CXg5fDzJ2olMKQ6wcZiZqcB44C3gSOAbwPv883/03E/j5kZ8BpQCJwBDAI+ACaYWeewzFEE9T8GGAj8C7glic+RjO7AecAPgO+G8YyK2P8b4ALgF8DRBJ/zxymKRWrj7nrokfSD4AtlB1Aa9bg9okwuMBV4GfgUeD7qHEXAfMAitl0PLAuf9wYcODFifz6wCfhF+PqCsEzfiDI/ASqqz0vwhXhD1HufFcZbXWYx8GxUmQXA9RGvHRgeVeYCoLSWupoUdZ4i4P4ayncGJobvtwD4B/DfQG5EmY+A52o4R42fBzgp/Px5UWVmANeGz58B3o7a/0jwtbHr9c3ArJrqJIHXNwPlQH7Ett8DxRGvVwAjI14bMA8oSvf/hUx86IpD9sYHBH+JRj5GV+9090qCvwrPAPYjuKKINsnDb4LQRKDQzFoDBwE7w23V59xE8Fd0/4hjKtx9XsTr5UAToE34+gjg92GTVmnYTPIM0ALoFHHc51GxLQ/jTpiZtTCzO8xsTtikUgoMBvZP9BzuvsLdjwEOAe4h+JJ8CJhiZs3DYoMI+j9qUtPnOQJoDqyJqpcBQM+wzEFE1H0o+vW+8lX4b7tbrGaWT/DvNKV6Z/g7MwVJC3WOy97Y5u7FtZSpblYoADoAG/fRe0cmmx1x9mVF/PwD8M8Y51kT8bwyxnmS/ePqTuA0gqaVBQRNa08SJLKkuPssYBbwgJkdD3wInEtwtZeImj5PFrAKOCHGcZuTCHMnQWKLlJvE8dX2Rd1LHdE/jKRM2EF9P3AZQVv8P8ws+o+Vo8L29mpHA8vdfTMwl6/7P6rP2ZrgL/E5SYTyKdDPg47m6Ed00qlJJZBdS5njgSfd/SV3/xxYxtd/we+N6s/bMvw5HTh5L873KUFH984YdbI6LDOX4N8jUvTrNUDHqH/DgXsR127CK5GVRPQrhe8Xr59JUkxXHLI3mppZp6htVe6+xsyygaeA9939ITN7kaCJ6SbghojyXYB7zOyvBAnhGuBWAHdfYGZjgYfM7BKCq5VRBH8RP5NEnLcA/zazr4AXCK5QBgBD3P3aJM6zGDjZzN4naB7bEKPMfOAHYdyVBJ+3WYxycZnZ3wiaaiYQJJ7OBH0/24C3wmKjgH+ZWTFBXRhBp/JD7r4tgbd5h6CfZKyZXQt8QdAcdBrwjrt/SDAk+GMzuw54ERhK0HkdqQhoC/zOzJ4Ly0Tf67Iv3Atca2bzCZLopQT1siIF7yW10BWH7I3vEPzHjXxMD/f9DugFXATg7uuA84GRYbNLtacJ/oqfDDwMPArcHbH/5wRt2ePCn82B0zy4FyAh7j4e+D7ByKMp4WMksCTxjwrAr8NzLOXrzxntf4HVBM1KbxB0jH+Y5Pu8TTCS7AWCRPRKuP0Ud58P4O6vE3yJnx7G8n4Y285E3iDsI/geQXJ6mKCj+QWgL0HSwt0nEfz7/ZKgv+Rsgo7syPPMDfdfEpY5hd1Hq+0LdxL8IfJ3gjqFoF7KU/BeUovqESUidS4cgz/L3S9PdyzS8JjZdOA/7n5FumPJNGqqEpF6z8wOAE4luLLKJbif5tDwp9QxJQ4RaQh2EtzLMpqgiX0OcLq7T0trVBlKTVUiIpIUdY6LiEhSMqKpqqCgwHv16pXuMOqVrVu30qJFi3SHUe+oXmJTvcTWmOvlk08+WevuHWLty4jE0bFjR6ZNU1NopKKiIoYOHZruMOod1UtsqpfYGnO9hPc9xaSmKhERSYoSh4iIJEWJQ0REkqLEISIiSVHiEBGRpChxiIhIUpQ4REQkKUocIiKSFCUOERFJihKHiIgkRYlDRESSosQhIiJJUeIQEZGkKHGIiEhSlDhERCQpKU0cZnaamc0zs2IzGxljf1Mzez7cP9nMuofb25nZe2ZWamb3Rx1zhJnNDI+5z8ystjgWb97JcbdN4NXpJfvss4mIZKqUJQ4zywYeAE4H+gM/MrP+UcUuAja4ey/gbuD2cHs5cAPwmxin/htwMdA7fJyWSDwlG8u47uWZSh4iInsplVccQ4Bid1/o7tuB54BhUWWGAU+Ez18ETjYzc/et7v4fggSyi5l1Blq7+yR3d+BJ4KxEAyqrrGL0+Hl79mlERARI7dKxhcDSiNfLgKPilXH3HWa2CWgHrK3hnMuizlkYq6CZXQJcAtCk09frjZdsLKOoqCjRz9BolZaWqh5iUL3EpnqJLVPrpdGuOe7uY4AxAE079/bq7YUFeY12jeBkNOa1kveG6iU21UtsmVovqWyqKgG6RbzuGm6LWcbMcoB8YF0t5+xayznjapabxTWn9k20uIiIxJDKxDEV6G1mPcysCTACGBdVZhxwfvh8ODAh7LuIyd1XAJvN7OhwNNV/A2MTDahfp1acNShmy5aIiCQoZYnD3XcAlwPjgbnAC+4+28xuMbMzw2KPAu3MrBj4X2DXkF0zWwzcBVxgZssiRmT9D/AIUAx8CbxRWyzdW2fx61P6MGPpJt6avXLffEARkQyV0j4Od38deD1q240Rz8uBc+Ic2z3O9mnAgGRjufRbPXlt5gpuGDuLow5sR35ebrKnEBERMujO8SY5Wdwx/FDWbKngtjfmpjscEZEGK2MSB8ChXQu4+IQDeXbKUj4ujjfiV0REapJRiQPg6lP60L1dc0a+PJNt23ekOxwRkQYn4xJHs9xsbvvhoSxZv4273pqf7nBERBqcjEscAEcf2I6fHLU/j320iOlLNqQ7HBGRBiUjEwfAyNP70bF1M3770uds37Ez3eGIiDQYGZs4WjXLZdQPBjB/VSl/LSpOdzgiIg1GxiYOgJP6dWTYwC488F4x81ZuSXc4IiINQkYnDoAbz+hPq2a5XPvS51TtjDvbiYiIhDI+cbRr2ZSb/qs/ny3dyN8/WpTucERE6r2MTxwAZx7WhZP77cedb83jq3Vb0x2OiEi9psQBmBm3/mAAuVlZjHxpJjVM0CsikvGUOEKd8/O47nsHMXHhOp6furT2A0REMlSjXQFwT4w4shvjPivhprGzuOedBazaXE6XgjyuObWv1vEQEQnpiiNCVpZxcr+OVFQ5KzeX4wRrlF/38kxenZ7wQoMiIo2aEkeUxz9evNu2ssoqRo+fV/fBiIjUQ0ocUZZvLEtqu4hIplHiiNKlIC+p7SIimUaJI8o1p/YlLzf7G9tysoxrTu2bpohEROoXjaqKUj16avT4eSzfWEbzJtls3V5FQXOtUS4iAkocMZ01qHBXAimvrGLY/R/xm39+xuu/OoH9WjVLc3QiIumlpqpaNMvN5i8/HkRpxQ5+/cJn7NREiCKS4ZQ4EtCnYytuPONgPlywljEfLkx3OCIiaaXEkaAfDenG6QM6cef4ecxYujHd4YiIpI0SR4LMjNvOPpSOrZtx5bPT2VJeme6QRETSQokjCfnNc7l3xECWbdjG9a/O0iy6IpKRlDiSNLh7W676Th/GzljOS59q/ioRyTxKHHvgsm/34qgebblx7CwWrilNdzgiInVKiWMPZGcZ94wYSJOcLK54djoVO6rSHZKISJ1R4thDnfPzGD38MGYv38wdb2rmXBHJHEoce+GU/h05/5gDePQ/i3jvi9XpDkdEpE6kNHGY2WlmNs/Mis1sZIz9Tc3s+XD/ZDPrHrHvunD7PDM7NWL71WY228xmmdmzZpbWOUCu+95B9OvUil//8zNWby5PZygiInUiZYnDzLKBB4DTgf7Aj8ysf1Sxi4AN7t4LuBu4PTy2PzACOBg4DfirmWWbWSFwJTDY3QcA2WG5tGmWm839Px7E5rLtnHDHe/QY+RrH3TZBKwaKSKOVyiuOIUCxuy909+3Ac8CwqDLDgCfC5y8CJ5uZhdufc/cKd18EFIfng2BixjwzywGaA8tT+BkSMqtkM2ZGxY6dWm5WRBq9VM6OWwgsjXi9DDgqXhl332Fmm4B24fZJUccWuvtEM7sTWAKUAW+5+1ux3tzMLgEuAejQoQNFRUV7/YHi+WPRNiqrvnkzYFllFX8c+xkFmxak7H33RmlpaUrrpKFSvcSmeoktU+ulQU2rbmZtCK5GegAbgX+a2U/d/R/RZd19DDAGoG/fvj506NCUxbX+zddiby93Uvm+e6OoqKjexpZOqpfYVC+xZWq9pLKpqgToFvG6a7gtZpmw6SkfWFfDsd8BFrn7GnevBF4Gjk1J9EmIt6xsp3yt3SEijU8qE8dUoLeZ9TCzJgSd2OOiyowDzg+fDwcmeDAB1DhgRDjqqgfQG5hC0ER1tJk1D/tCTgbmpvAzJCTWcrMAHVs11XxWItLopCxxuPsO4HJgPMGX+wvuPtvMbjGzM8NijwLtzKwY+F9gZHjsbOAFYA7wJnCZu1e5+2SCTvRPgZlh/GNS9RkSddagQv509iEUFuRhQGFBHmce2pkZyzbxwHvF6Q5PRGSfSmkfh7u/Drwete3GiOflwDlxjh0FjIqx/Sbgpn0b6d6LXG4WwN3Jzs7izrfm07dTa07p3zGN0YmI7Du6czxFzIw/nX0Ih3bN56rnpjN/1ZZ0hyQisk8ocaRQs9xsxvxsMM2b5vCLJ6axYev2dIckIrLXlDhSrFN+Mx762RGs3FTO5c9+yo6qnekOSURkryhx1IHD92/DqB8M4KPiddz6WtoHgYmI7JUGdQNgQ3bO4G58sXILj/5nEf07t+bcI7vVfpCISD2kK446dN3p/Tihd3t+/+pMPvlqfbrDERHZI0ocdSgnO4v7f3Q4hQV5XPrUpyzfWJbukEREkqbEUcfym+fyyPmDKa+s4tKnPqG8UsvOikjDosSRBr32a8W9IwYya/kmrn3xc01LIiINijrH0+Tkgzrym+/2ZfT4eRTNW82W8h10KcjjmlP7fuMOdBGR+kaJI4265Dcj24zN5TuArxeAApQ8RKTeqrWpysz6mNm7ZjYrfH2omV2f+tAavzvfmk+V774A1Ojx89IUkYhI7RLp43gYuA6oBHD3z0nzOt+NRbxRVRptJSL1WSKJo7m7T4natiMVwWSaeAtAdWytBaBEpP5KJHGsNbOegAOY2XBgRUqjyhDxFoDKMthcXpmGiEREapdI4rgMeAjoZ2YlwFXA/0tlUJki1gJQl37rQFZvqeDiJ6bpHg8RqZcSGVXl7v4dM2sBZLn7lnA5V9kHoheAAujfuTVXPT+DK5+dzl9/cjg52brdRkTqj0S+kV4CcPet7l69GtGLqQtJhg0s5KYz+vPWnFX8/pVZukFQROqVuFccZtYPOBjIN7OzI3a1BtR7m2IXHNeD9Vu3c9+EYtq0aMLI0/ulOyQREaDmpqq+wBlAAfBfEdu3ABenMCYJXX1KH9Zt3c6D739JuxZNuPjEA9MdkohI/MTh7mOBsWZ2jLtPrMOYJGRm3DJsABu2bWfU63Np26IJPzyia7rDEpEMl0jn+HQzu4yg2WpXE5W7X5iyqGSX7Czj7vMGsrlsGte+9Dn5ebl8p3/HdIclIhkskc7xp4BOwKnA+0BXguYqqSNNc7J58GdHcHCX1lz2zKdMXaxFoEQkfRJJHL3c/QZgq7s/AXwfOCq1YUm0lk1z+PsFR1LYJo8LH5/K3BWb0x2SiGSoRJqqqm9h3mhmA4CVwH6pC0niadeyKU9eOIThf5vIuQ9+TPOmOazeXKHp2EWkTiVyxTHGzNoA1wPjgDnA7SmNSuLq2qY55x97AFsqqli1uQLn6+nYX51eku7wRCQD1Jo43P0Rd9/g7h+4+4Huvh/wRh3EJnH8Y9KS3bZpOnYRqSs1Jg4zO8bMhpvZfuHrQ83sGeCjOolOYtJ07CKSTnETh5mNBh4Dfgi8Zma3Am8Bk4HedROexKLp2EUknWrqHP8+MMjdy8M+jqXAAHdfXCeRSVzXnNqX616eSVnU7LlVvpOVm8rplK8EIiKpU1NTVbm7lwO4+wZgQbJJw8xOM7N5ZlZsZiNj7G9qZs+H+yebWfeIfdeF2+eZ2akR2wvM7EUz+8LM5prZMcnE1BjEmo79ipN6sa2iivPGTKRETVYikkI1XXEcaGbjIl73iHzt7mfWdGIzywYeAE4BlgFTzWycu8+JKHYRsMHde5nZCILRWueZWX+C5WkPBroA75hZH3evAu4F3nT34WbWBGie8KdtRGJNx/7tfvtx/mNTOO+hiTx78dF0a5uRVSMiKVZT4hgW9frPSZ57CFDs7gsBzOy58JyRiWMYcHP4/EXgfjOzcPtz7l4BLDKzYmCImc0BTgQuAHD37cD2JONqtA7fvw3P/OJofvroZM59aCLPXHw0Pdq3SHdYItLI1DTJ4ft7ee5Cgn6RasvY/Y7zXWXcfYeZbQLahdsnRR1bCJQBa4C/m9lhwCfAr9x9a/Sbm9klwCUAHTp0oKioaC8/TsPx60HZjJ5azll/eZ/fHtmMLi13b5EsLS3NqDpJlOolNtVLbJlaL4ncOV6f5ACHA1e4+2QzuxcYCdwQXdDdxwBjAPr27etDhw6tyzjT7uijtvDjhyfz5+lVPH3xYPp1av2N/UVFRWRanSRC9RKb6iW2TK2XVK5JWgJ0i3jdNdwWs4yZ5QD5wLoajl0GLHP3yeH2FwkSiUTp07EVz196NDnZxogxk5hVsindIYlII5HKxDEV6G1mPcJO7BEEU5ZEGgecHz4fDkzwYJ3UccCIcNRVD4L7Rqa4+0pgqZn1DY85mW/2mUiEnh1a8sKlx9CiSQ4/fngSM5ZuTHdIItII1NpUZWb/AqIXvd4ETAMeqh6yGy3ss7gcGA9kA4+5+2wzuwWY5u7jgEeBp8LO7/UEyYWw3AsESWEHcFk4ogrgCuDpMBktBH6e1CfOMAe0a8Hzlx7Njx+ezE8fmczjPz+Swd3bpjssEWnAEunjWAh0AJ4NX59HsB5HH+Bh4GfxDnT314HXo7bdGPG8HDgnzrGjgFExts8ABicQt4S6tmnO85cezU8ensyPHp5Efl4ua0u3UzhpgmbVFZGkJZI4jnX3IyNe/8vMprr7kWY2O1WByb7VOT+PC449gJvGzWFtaTCCuXpWXUDJQ0QSlkgfR0sz27/6Rfi8ZfhS91A0IA99sGi3NkfNqisiyUrkiuPXwH/M7EvAgB7A/5hZC+CJVAYn+5Zm1RWRfaHWxOHur5tZb6BfuGleRIf4PakKTPa9LgV5MeexymuSTWXVTnKzUznITkQai0S/KY4gmDfqMOBcM/vv1IUkqXLNqX3Jy83+xracLGPb9iouemIaW8or4xwpIvK1RIbjPgX0BGYA1UNiHXgydWFJKlR3gI8eP4+SjWUUhmuVV+yo4nevzOKcByfy958fSef82Ot9iIhAYn0cg4H+4Y150sBVz6obPVVC5/w8/ufpTznrgY947IIjObhLfvqCFJF6LZGmqllAp1QHIul1Yp8OvPjLY8g249wHJ/LevNXpDklE6qlEEkd7YI6ZjTezcdWPVAcmda9fp9a8ctlxdG/fgl88MY2nJ3+V7pBEpB5KpKnq5lQHIfVHx9bNeOHSY7ji2en8/pVZLFm/jd+e2o+sLEt3aCJSTyQyHHdv1+WQBqZF0xzG/OwIbv7XbB56fyHL1pfx53MPo1nUiCwRyUxxE4eZ/cfdjzezLXxzkkMD3N1bxzlUGoGc7Cz+OGwAB7RtwajX5zJ7+SYqduxk5aZyuoSjsTRNiUhmqmkFwOPDn63qLhypT8yMi088kJKN23j846/7OzTHlUhmS+gGQDPLNrMuZrZ/9SPVgUn98fac3UdYaY4rkcyVyA2AVwA3AauAneFmBw5NYVxSj2iOKxGJlMioql8Bfd19XaqDkfop3hxXTXKyWL91O21bNElDVCKSLok0VS0lWPFPMlSsOa5ys40dVTs5474PtSStSIZJdAXAIjN7Daio3ujud6UsKqlXIue4Wr6xbNeoqp4dWvLLpz/hnAc/5sYz+vPTow/ATPd7iDR2iSSOJeGjSfiQDFQ9x1W0f19xPFc/P4Mbxs7mk6828H9nH0LzJon8WolIQ1Xj/3Azywb6uPtP6igeaWAKmjfh0fOP5IH3irnrnfnMWbGZB396BAd2aFn7wSLSINXYx+HuVcABZqYrDYkrK8u44uTePHnhENZsqeDM+z/ijZkr0h2WiKRIIp3jC4GPzOwGM/vf6keqA5OG54TeHXjtyhPotV9Lfvn0p4x6bQ6VVTtrP1BEGpREGqO/DB9ZgO4ilxp1KcjjhUuPYdRrc3j4w0W8M3cVZdt3smqzpioRaSwSmeTwD3URiDQeTXKy+MOwAex056lJS3Zt11QlIo1DIneOdwCuJVhzvFn1dnc/KYVxSSMw4Ys1u22rnqpEiUOk4Uqkj+Np4AugB/AHYDEwNYUxSSOhqUpEGqdEEkc7d38UqHT39939QkBXG1KrLgV5Mbc78LeiL6naqWXsRRqiRBJHZfhzhZl938wGAW1TGJM0ErGmKmmWm8WhXVtz+5tfcN5DE/lq3dY0RScieyqRxHGrmeUDvwZ+AzwCXJ3SqKRROGtQIX86+xAKC/IwoLAgj9vOPpSxlx3PPecNZN6qLZx+74c8M3kJ7rr6EGkoEhlV9e/w6Sbg26kNRxqbeFOVnDWokCE92nLti5/zu1dm8tacldzxw0PZr3WzGGcRkfqk1isOM+tjZu+a2azw9aFmdn3qQ5PGrktBHk9eOIQ/nHkwkxau47v3fMC/P1+e7rBEpBaJNFU9DFxH2Nfh7p8DIxI5uZmdZmbzzKzYzEbG2N/UzJ4P9082s+4R+64Lt88zs1Ojjss2s+lm9u/oc0rDkpVlnH9sd1678gQOaNeCy5+ZzpXPTueZyV9x3G0T6DHyNY67bQKvTi9Jd6giEkrkzvHm7j4larrsHbUdFE6Q+ABwCrAMmGpm49x9TkSxi4AN7t7LzEYAtwPnmVl/guR0MNAFeMfM+oRzZ0GwuNRcoHUC8UsD0LNDS176f8fw16Ivufvt+Yz77OsrD904KFK/JHLFsdbMehKMosTMhgOJzGA3BCh294Xuvh14DhgWVWYY8ET4/EXgZAsy1DDgOXevcPdFQHF4PsysK/B9gk56aURysrO48uTetG/VdLd9WuNcpP5I5IrjMmAM0M/MSoBFQCLTrBcSrB5YbRlwVLwy7r7DzDYB7cLtk6KOrf5T8x6CO9lrnDfLzC4BLgHo0KEDRUVFCYScOUpLS+ttnazZUhFze8nGspTHXJ/rJZ1UL7Flar0kMqpqIfAdM2sBZLn7FjO7iuALvE6Z2RnAanf/xMyG1lTW3ccQJDz69u3rQ4fWWDzjFBUVUV/rpHDShJhrnDfNyaLbwYPpmcK1PupzvaST6iW2TK2XRJqqAHD3re6+JXyZyLTqJUC3iNddw20xy5hZDpAPrKvh2OOAM81sMUHT10lm9o9EP4M0DPHWOAfn9Hs+5K635lFeWRX7YBFJuYQTR5REFpaeCvQ2sx7hQlAjgHFRZcYB54fPhwMTPLgTbBwwIhx11QPoDUxx9+vcvau7dw/PN8Hdf7qHn0HqqVg3Do4efhgf/vYkvndIJ+6bUMx37/6Aonmr0x2qSEba08Wha73NN+yzuBwYD2QDj7n7bDO7BZjm7uOAR4GnzKwYWE84zDcs9wIwh2AE12URI6okA8S7cfCeEYM4d3A3rh87iwv+PpXvHdKJG884mE75unFQpK7ETRxmtoXYCcKA2LPXRXH314HXo7bdGPG8HDgnzrGjgFE1nLsIKEokDmlcju3Vnjd+dQIPf7CQv0wo5v15a7j6lD5ccGx3crL39CJaRBIVN3G4u1b7k3qraU42l5/UmzMPK+SmcbO49bW5vPRpCd/t35EXP1nG8o1lWnFQJEX055k0aPu3a85jFxzJgz89nOUbt3Hvuwso2ViG8/WNg7rrXGTfUuKQBs/MOG1AZ5o32f0CWjcOiux7ShzSaKzcVB5ze8nGMnZq0SiRfUaJQxqNeCsOAgx74CM+/nJtHUYj0ngpcUijEevGwbzcLH5yVDfWlVbw44cnc+HjU5m3ckucM4hIIvb0Pg6Reqd69NTo8fN2G1VVXlnFEx8v5v73ijn93g8454huXH1KH93/IbIHlDikUYl342Cz3Gwu/VZPzh3cjQfeK+bJiV8x9rMSLjq+B5d+qycT5q5m9Ph5lGwso3DSBA3jFamBEodklDYtmnD9Gf05/9ju3PnWPB5470se/2gx26t2UlkVdKBr/Q+RmqmPQzJSt7bNuXfEIP51+fFU7vRdSaOahvGKxKfEIRntkK75VO7YGXPf8hhTu4uIEodI3GG8WVnGc1OWsD1OYhHJVEockvFiDeNtkm10yW/GyJdn8u07i3hq4mKtASISUuKQjBe5/gcE63/cMfwwPrj22zz+8yPplN+MG8bO5sQ73uORDxdStl0JRDKbRlWJ8PUw3uilQIf23Y9v9enAxC/X8ZcJxdz62lz+VvQlvzjhQH52zAG8M2dVzPtGRBozJQ6RWpgZx/Zqz7G92jNt8Xrum1DM7W9+wX3vzqeyytmxU8N4JbOoqUokCYO7t+XJC4fw6mXH4c6upFFNw3glEyhxiOyBgd0KqKhhGK+7ZuOVxkuJQ2QPxRvG68BZD3zEq9NLNJRXGiUlDpE9FGsYb7PcLIYfXsiWih1c9fwMjr99Ave9u4C1pRVpilJk31PnuMgeqmk23p07nQ8WrOGxjxZz19vzuf+9YoYd1oWfH9eD/l1a8+r0Eo3GkgZLiUNkL8SbjTcryxjadz+G9t2P4tVbePzjxbz0SQn//GQZPdu3YOmGbWzXpIrSQKmpSiTFeu3XilvPOoRJ153M777Xj8Xrvk4a1TQaSxoSJQ6ROpLfPJdLTuzJzjgjrko2lrGjSp3pUv8pcYjUsZrWRj/u9gmMHv8FX63bWocRiSRHiUOkjsUbjXXhcd05uEs+fyv6km+NLmLEmIm8Mn2ZJleUeked4yJ1rKbRWAArN5Xz0qfLeGHaUq5+/jNuHDubYQO7cN7g/SlevYU735qv0ViSVkocImkQbzQWQKf8Zlz27V788ls9mbxoPS9MW8o/py3jH5OWYAQ3GIJGY0n6qKlKpJ7KyjKO6dmOu88byJTff4f8vFyiu9XLKqu4/c0v0hKfZC4lDpEGID8vl81llTH3rdhUzv88/QlvzFyh/hCpEyltqjKz04B7gWzgEXe/LWp/U+BJ4AhgHXCeuy8O910HXARUAVe6+3gz6xaW70hwxT7G3e9N5WcQqS+6FORREmMd9BZNs5myaAOvz1xJiybZfPfgTpx5WBeO69WeJjnB34a6U132pZQlDjPLBh4ATgGWAVPNbJy7z4kodhGwwd17mdkI4HbgPDPrD4wADga6AO+YWR9gB/Brd//UzFoBn5jZ21HnFGmUrjm1L9e9PJOyiKuKvNxsRp11CGcc2pnJi9bzr8+W88aslbwyvYSC5rmcPqATbZo34e8fLaKsMrhHRH0jsrdSecUxBCh294UAZvYcMAyI/JIfBtwcPn8RuN/MLNz+nLtXAIvMrBgY4u4TgRUA7r7FzOYChVHnFGmUahuNdVyv9hzXqz23DBvAhwvW8K/PljN2xnK2xVjqtvpOdSUO2ROpTByFwNKI18uAo+KVcfcdZrYJaBdunxR17Dd+w82sOzAImBzrzc3sEuASgA4dOlBUVLSHH6NxKi0tVZ3EUN/rpQAYdXQW0CLYsGkBRUULdiuXDZzVCU7v0JRL394W81wlG8sY/857NM2xWt+3vtdLumRqvTTI4bhm1hJ4CbjK3TfHKuPuY4AxAH379vXIdaSF3dbWlkBjrJfCqRNi9o0AXFlUzvG92nNK/46cfFBHOrRqGrNcY6yXfSFT6yWViaME6Bbxumu4LVaZZWaWA+QTdJLHPdbMcgmSxtPu/nJqQhdpPGL1jQR3qvdg2/Yq3p6zine/WI3ZTAZ2K+CU/h35bv+O9OzQkrEzljN6/DxKNpZROGmCOtUFSG3imAr0NrMeBF/6I4AfR5UZB5wPTASGAxPc3c1sHPCMmd1F0DneG5gS9n88Csx197tSGLtIo1Fb38hN/9WfL1Zu4e05q3hn7irueHMed7w5j/Ytm7BxW+WuddXVqS7VUpY4wj6Ly4HxBE2uj7n7bDO7BZjm7uMIksBTYef3eoLkQljuBYJO7x3AZe5eZWbHAz8DZprZjPCtfufur6fqc4g0BjXdqW5mHNS5NQd1bs2VJ/dmxaYy3pm7mlv/PWdX0qhWVlnFn96Yq8SR4VLaxxF+ob8ete3GiOflwDlxjh0FjIra9h+g9p48EdljnfPz+NnRB3Djq7Ni7l+1uYKT7izihN7tOaF3B47u2Y6WTb/5VaL7Rhq3Btk5LiKpF++Gw/y8HLq3b8EL05bxxMSvyMkyDj+gDSf2bs+JfTpQvKqU3786a1efipq4Gh8lDhGJKd4Nh384cwBnDSqkYkcVn3y1gQ8XrOXDBWu486353PnWfLIMolq4dN9II6PEISIxRXaql2wsozCqyalpTjbH9mzPsT3b89vT+rGutIL/FK/lV8/NiHm+ko1lLFxTSo/2LQjGuUhDpcQhInFVd6oncr9Cu5ZNGTawkDvenBf3vpGT/vw+HVo1ZUiPthzVoy1H9WhH7/1akpUVJBL1jTQMShwisk/FbuLK4qpT+tC6WS6TF65j8qL1vPb5CgDaNM/lyO5tad4kmzdmraRih+bUqu+UOERkn6rtvpEfDdkfd2fZhjImLVzHlEXrmbxoPUvW7z41SvV6I0oc9YsSh4jsczXdNwLBvSPd2janW9vmnDM4mCSix8jXdluoCoL1Rr59ZxGDuhUwcP8CBnVrQ7/OrcjN/no5ITVx1S0lDhGpF+IN/23dLIfe+7Xkw+K1vDw9mLWoaU4WhxTmM2j/AiqrdvLclKWUq4mrzihxiEi9EG/47y3DguG/7k7JxjJmLN3I9CUbmb5kA09M/IrtYcKIVFZZxW1vzGXYwC4awZUCShwiUi/U1jdiZnRt05yubZpzxqFdANi+Yyd9r38jZhPXys0VHHHrOxzcpTUDCvODn13y2b9tc43i2ktKHCJSb9TWNxKtSU5WDXe45/Kdg/ZjVslmHvlwIZVVQXpp1TSHg7q0Ji8ni48Xrtu1XU1ciVPiEJEGLf4d7gfvSgAVO6pYsKqUWSWbmL18M7OWb2LKovW7naussoobx86iZdMc+nZqRWFB3q6rk0jVVyqZOt28EoeINGi1NXFBcJf7gMJ8BhTm79oWbxTX5vId/OLJaQC0aJJN746t6NuxFX07BY8v15Typ9e/yOi5uJQ4RKTBS7aJC+KP4uqc34z7fzyIeStLmb9qC/NWbuHtuat4ftrSGGcJVE83f+ZhXWJeoVRrLH0qShwikpHiNXH99rR+HHFAW444oO2u7e7O2tLtzF+1hZ88Mjnm+VZtrqD/TW/SvV0Leu7Xkp7tg58Htm/JgR1a8PacVd94v4Z8paLEISIZKZEmrmpmRodWTenQqimFca5UCvJyGX5EVxau3cqskk28MXPFN2YJjjdr8B213BlfH69SlDhEJGPtSRNXvCuVmyM64yHokP9q3TYWrinlyzVbGT1+XszzLd9UzlH/9w4HtG3BAe2ac0C75uzfrgUHtG3O7OWb+OO/59a7qxQlDhGRJNQ23Xy1pjnZ9OnYij4dWwHwzOQlMa9UWjXL4fheHViyfivvz1/D6i0VNb5/WWUVf/z3HPp3aU1hQR4tmsb+Gk/llYoSh4hIkpKZbr5avCuVP4Z3xlcr217FkvXbWLxuK5c+9UnMc63bup3v3v0BEMwuXNgmj64FzSlskxc0pW3Yxj8mL9mjmYarE06TTr2OiFdGiUNEpA4k2qeS1yR719DfeP0p7Vs24YYz+lOysYxlG8oo2VBG8ZpS3p+/5huJKVJZZRW/e2UmC9dupVPrZnTOb0an/OBnfl4uZsar00t2S26xKHGIiNSRZPtU4l2lXP/9/gwbuPt53J31W7cz+NZ3Yt6jsm17FX+ZsACP2tksN4vO+UGSijX3VzQlDhGReiqZkV8QjP5q17Jp3HtUCgvyKLpmKGu2VLBiUzkrN5WzYlNZ8HNzOYvWbk0oLiUOEZF6bF+O/Lrm1L7kZgfze3UpyNvtuBlLJsRd9jdSVq0lRESkQTlrUCF/OvsQCgvyMIIrjT+dfUitCeiaU/uSl5td6/l1xSEi0gjtyZVKZNPYihrK6YpDRER2OWtQIR+NPIntK4tjjwVGiUNERJKkxCEiIklR4hARkaQocYiISFKUOEREJCkpTRxmdpqZzTOzYjMbGWN/UzN7Ptw/2cy6R+y7Ltw+z8xOTfScIiKSWilLHGaWDTwAnA70B35kZv2jil0EbHD3XsDdwO3hsf2BEcDBwGnAX80sO8FziohICqXyimMIUOzuC919O/AcMCyqzDDgifD5i8DJZmbh9ufcvcLdFwHF4fkSOaeIiKRQKu8cLwQiV3dfBhwVr4y77zCzTUC7cPukqGOrb4Gs7ZwAmNklwCXhywozm7UHn6Exaw+sTXcQ9ZDqJTbVS2yNuV4OiLej0U454u5jgDEAZjbN3QenOaR6RXUSm+olNtVLbJlaL6lsqioBukW87hpui1nGzHKAfGBdDccmck4REUmhVCaOqUBvM+thZk0IOrvHRZUZB5wfPh8OTHB3D7ePCEdd9QB6A1MSPKeIiKRQypqqwj6Ly4HxQDbwmLvPNrNbgGnuPg54FHjKzIqB9QSJgLDcC8AcYAdwmbtXAcQ6ZwLhjNnHH68xUJ3EpnqJTfUSW0bWi3n0GoIiIiI10J3jIiKSFCUOERFJSqNOHJqeJDYzW2xmM81shplNS3c86WJmj5nZ6sh7fMysrZm9bWYLwp9t0hljOsSpl5vNrCT8nZlhZt9LZ4x1zcy6mdl7ZjbHzGab2a/C7Rn5+9JoE4emJ6nVt919YCaOQY/wOMGUNpFGAu+6e2/g3fB1pnmc3esF4O7wd2agu79exzGl2w7g1+7eHzgauCz8PsnI35dGmzjQ9CRSC3f/gGA0X6TIaXCeAM6qy5jqgzj1ktHcfYW7fxo+3wLMJZjNIiN/Xxpz4og15UlyK7c3Xg68ZWafhFOzyNc6uvuK8PlKoGM6g6lnLjezz8OmrIxokoklnMV7EDCZDP19acyJQ+I73t0PJ2jGu8zMTkx3QPVReDOqxqsH/gb0BAYCK4A/pzWaNDGzlsBLwFXuvjlyXyb9vjTmxKHpSeJw95Lw52rgFYJmPQmsMrPOAOHP1WmOp15w91XuXuXuO4GHycDfGTPLJUgaT7v7y+HmjPx9acyJQ9OTxGBmLcysVfVz4LuAZg7+WuQ0OOcDY9MYS71R/eUY+gEZ9jsTLvfwKDDX3e+K2JWRvy+N+s7xcMjgPXw9Pcmo9EaUfmZ2IMFVBgRTzjyTqfViZs8CQwmmxl4F3AS8CrwA7A98BZzr7hnVURynXoYSNFM5sBi4NKJtv9Ezs+OBD4GZwM5w8+8I+jky7velUScOERHZ9xpzU5WIiKSAEoeIiCRFiUNERJKixCEiIklR4hARkaQocYjsA2ZWFTFz7Ix9ORuzmXWPnKlWJN1StnSsSIYpc/eB6Q5CpC7oikMkhcK1T+4I1z+ZYma9wu3dzWxCOGngu2a2f7i9o5m9YmafhY9jw1Nlm9nD4VoQb5lZXto+lGQ8JQ6RfSMvqqnqvIh9m9z9EOB+gpkMAP4CPOHuhwJPA/eF2+8D3nf3w4DDgdnh9t7AA+5+MLAR+GFKP41IDXTnuMg+YGal7t4yxvbFwEnuvjCcJG+lu7czs7VAZ3evDLevcPf2ZrYG6OruFRHn6A68HS4WhJn9Fsh191vr4KOJ7EZXHCKp53GeJ6Mi4nkV6p+UNFLiEEm98yJ+Tgyff0wwYzPATwgm0INg+dFfQrD8sZnl11WQIonSXy0i+0aemc2IeP2mu1cPyW1jZp8TXDX8KNx2BfB3M7sGWAP8PNz+K2CMmV1EcGXxS4KFk0TqDfVxiKRQ2Mcx2N3XpjsWkX1FTVUiIpIUXXGIiEhSdMUhIiJJUeIQEZGkKHGIiEhSlDhERCQpShwiIpKU/w9uS+0K6DdlbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "coated-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "trying-electric",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.1103 - accuracy: 0.7386 - val_loss: 0.8914 - val_accuracy: 0.7382\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7407 - accuracy: 0.7795 - val_loss: 0.5423 - val_accuracy: 0.8434\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5933 - accuracy: 0.8217 - val_loss: 0.6294 - val_accuracy: 0.8234\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5129 - accuracy: 0.8418 - val_loss: 0.4616 - val_accuracy: 0.8608\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4828 - accuracy: 0.8452 - val_loss: 0.4480 - val_accuracy: 0.8506\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4250 - accuracy: 0.8630 - val_loss: 0.5007 - val_accuracy: 0.8666\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3916 - accuracy: 0.8741 - val_loss: 0.4906 - val_accuracy: 0.8596\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3522 - accuracy: 0.8823 - val_loss: 0.4861 - val_accuracy: 0.8468\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3406 - accuracy: 0.8869 - val_loss: 0.4600 - val_accuracy: 0.8742\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3050 - accuracy: 0.8972 - val_loss: 0.4123 - val_accuracy: 0.8790\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2734 - accuracy: 0.9071 - val_loss: 0.4184 - val_accuracy: 0.8730\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2661 - accuracy: 0.9089 - val_loss: 0.4389 - val_accuracy: 0.8744\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2502 - accuracy: 0.9172 - val_loss: 0.4565 - val_accuracy: 0.8830\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2213 - accuracy: 0.9237 - val_loss: 0.4632 - val_accuracy: 0.8844\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2168 - accuracy: 0.9275 - val_loss: 0.4442 - val_accuracy: 0.8836\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1972 - accuracy: 0.9324 - val_loss: 0.4326 - val_accuracy: 0.8918\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1742 - accuracy: 0.9407 - val_loss: 0.4664 - val_accuracy: 0.8900\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1663 - accuracy: 0.9438 - val_loss: 0.4858 - val_accuracy: 0.8882\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1572 - accuracy: 0.9468 - val_loss: 0.4821 - val_accuracy: 0.8932\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1481 - accuracy: 0.9505 - val_loss: 0.4898 - val_accuracy: 0.8872\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - ETA: 0s - loss: 0.1366 - accuracy: 0.95 - 5s 3ms/step - loss: 0.1366 - accuracy: 0.9543 - val_loss: 0.5314 - val_accuracy: 0.8900\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1275 - accuracy: 0.9565 - val_loss: 0.5538 - val_accuracy: 0.8930\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1178 - accuracy: 0.9607 - val_loss: 0.5575 - val_accuracy: 0.8896\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1062 - accuracy: 0.9650 - val_loss: 0.6201 - val_accuracy: 0.8908\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1058 - accuracy: 0.9660 - val_loss: 0.6177 - val_accuracy: 0.8920\n"
     ]
    }
   ],
   "source": [
    "# Custom class to update learning rate at each iteration instead of epoch\n",
    "\n",
    "K = keras.backend\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # Note: the `batch` argument is reset at each epoch\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "lr0 = 0.01\n",
    "optimizer = keras.optimizers.Nadam(lr=lr0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "exp_decay = ExponentialDecay(s)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aquatic-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = n_epochs * len(X_train) // 32\n",
    "steps = np.arange(n_steps)\n",
    "lrs = lr0 * 0.1**(steps / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "particular-cologne",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEXCAYAAAC6baP3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA7M0lEQVR4nO3deXxU5dXA8d/JvicEwh4g7AQEZVdRQUrFvVZU3LUi2qrVamuxtda3b+1bta3aaqu41R0QbUXFHaOi7PsOYQ87IWQjIYSc9497g8OQZSZkMpPkfD+f+cxdnnvn3DvLmfs89z5XVBVjjDHGV2HBDsAYY0zjYonDGGOMXyxxGGOM8YslDmOMMX6xxGGMMcYvljiMMcb4xRKHCVkicpOIFPm5TJaIPB2omNzX2CIivwzAeseJiF/nx3vvo7rss5MhIr8XkZca6vWqeH0VkXFBeN1a97OI3CEi7zdUTA3JEkcIEpF/u18I78fcYMcWKNX8AEwFugbgtSaIyBIRKRKRfBFZLiJ/rO/XCZKA7LOqiEhr4D6gUe87EXlYRFYGYNUvAINE5KwArDuoIoIdgKnW58D1XtPKghFIsKhqCVBSn+sUkZ8Afwd+AXwBRAL9gNPr83WCJRD7rAYTgPmquinQLyQikap6JNCvU59U9bCIvAn8HPgm2PHUJzviCF2HVXW31+MAgIicIyJHRGRkZWERuU1ECkSkqzueJSLPishTIpLnPh4XkTCPZVqIyCvuvBIR+VxE+nrMv8n9Vz5aRFaKSLGIfCkiGZ6BisjFIrJIREpFZLOIPCIiUR7zt4jIgyLynBtjjoj8ynO+O/i2e+SxxfP1Pcp1E5H3RGS3G8tiEbnIz/16CfCuqj6nqtmqukZV31bVe7226QIRmeful1wReV9EYjyKxFS3Pe7yySIyWUT2ikihiHwlIoO9ytwgIltF5JCIfAC08Zp/wj/h2qpIqthnD7vv3XgR2ejG8l8RaeVRJkJEnvD4nDwhIv8Skaxa9uU1wHFVMT5+7qJE5FF3vx0SkQUicp7H/JHu5+ACEZkvImXAeVSvrYh86K5rq4hc5xXTn0VknftebhGRxyrfSxG5Cfg90Fe+P7K/yZ2X7O6HXe5ne42IXOW17hq/G8AM4BIRiatlXzYuqmqPEHsA/wY+qKXMn4DtQAugN1AM3OgxPwsoBP7hzr8SyAfu9SjzHrAWOBs4BedDvh2IdeffBBzBOfoZCvQHlgCfeKzjPKAAuBnoBowC1gF/8SizBcgF7gS6A3cBCpzuzk9zxycAbYE0j9cv8ljPAOB2N9buwG9xjsJ6e2330zXst2eB9UDXGsqMBcpxqmAy3e3+JRDn4/YIMBv40N1v3YH/dfdTO7fMMKDC3YaewG3uOtUjjoeBlV6xee+T2sYfBoqA/7jbcTqwFXjOo8wkIA+4HOgFPOV+VrJq2Eepbvxnek3PovbP3RvAXJzPXVd3P5YBA9z5I939uQL4oVsmrZo41N1vt7n78bduXIM9yvwOOBPoAlwAbAP+150XC/wF53vQ1n3Euu/ht8Bq9/PQFTgfuMzX74ZbLg44CowO9u9Kvf5GBTsAe1TxpjiJo9z9wns+HvUoEwksAN4FFgNTvdaRhfMDKR7THgRy3OEe7pfubI/5ye6XfII7fpNbppdHmWuBw5XrBb4Gfuf12j9y460sswV4y6vMBuBBj3EFxnmVuQmPH8Fq9tVcr/VkUXPiaAfMcV9vA/A6cAMQ6VHmW2BKDeuocXuAc93tj/UqsxS43x1+E/jMa/4LBCZxlALJHtN+C2R7jO8CJnmMC07yz6phH5zq7sMMPz933XB+2Dt5Lfdf4J/u8Eh33Zf78F1R4HmvaZ8Dr9ewzO1e21/Vfh7jxtmnmnXcRC3fDY/pB4BbatuWxvSwqqrQ9TXOl9Pz8XjlTHXqe68BLgJa4/zj8jZX3U+uaw7QQUSSgD44X4w5HuvMx/mXl+mxzGFVXecxvhOIwjnSARgE/Nat0ipyq0neBOJx/r1VWu4V2043bp+JSLxbzbDarQIpAgYDnXxdh6ruUtXTcY5ansT5kXwOmO9RnXAaTvtHTWrankE4/zT3ee2Xfjg/nODs/zle6/Aery9b3ff2hFhFJBnnfZpfOdP9zMynZrHuc2kV82r63A3E2eervfbNhXy/byotrCUGz/V7jx/7DItzttpst4qzCHiC2j8zpwG7VHVNDWVq+25UKuH7/dUkWON46Dqkqtm1lBmO006VglPdc7CeXtvzS19ezbwwj+f/Ad6uYj37PIa9GzYV/9vY/oJTbfBLnH/4h4BXcb6sflHVlcBK4BkRGYHTeHklztGeL2ranjBgD1DV2TQFfoRZgfMj6ynSj+Ur1ce+97bffW6Bc8TiqzD39YdUEZd3o35x3UL7nogMB6bgfEZ/gfMduQTns3SyavtuVErl+O9Co2dHHI2U2wj3NHAH8Bnwuoh4/xEYJiKePzzDgZ2qWgCswXn/j51N5P4jPAWnXtdXi3HaGLKreHh/sWpyBAivpcwI4FVVfUdVlwM5nPgvtS4qtzfBfV4CjD6J9S3GaeiuqGKf7HXLrMF5Pzx5j+8D2ni9h6eeRFwncI9EduP8kAPgvt6QahdybMRJgplVzKvpc7cEJxm2rWLf7KjjZlS1HyuPFM4Edqjq/6rqAlXdAHT2Kl/GiZ+9JUA7EelTx5gA54QOIAbnM9Fk2BFH6IoWkbZe046q6j4RCQdeA75S1edEZDpOFdPvcRoCK7UHnhSRf+IkhF/hnnOvqhtE5D3gORGZiPNP7BGcH4M3/YjzD8AHIrIVmIbzL6wfMFRV7/djPVuA0SLyFU4VQF4VZdYDl7lxH8HZ3pgqylVLRP6FU6UwCyfxtMOpgz8EfOoWewR4X0SycfaF4DTSPqeqh3x4mc9x2kneE5H7+b7hdSzwuap+g3NK8Hci8gAwHade/zKv9WTh/Fv9jYhMccsE4mK3p4D7RWQ9ThK9DWe/VHskoaoVIvI5TjKf7jW7ps/dehF5A/i3iNyH84OairNtm1T13TrE/2MRWYCzv8bhJP1h7rz1ONVk1+JUYZ0HXO21/Bags4gMxGk4L8SpqpwHvCMiv3DX0x2IV9X/+hHbWTjbtcH/zQpddsQRun6A88X1fCxx5/0G50N8C4Cq5gI3ApPcapdKb+D8k5oHPA+8iFO/W+lmnLrsGe5zHDBWnWsBfKKqn+DUT49y1zEf5yydbb5vKuBcSDYK56yuJdWUuRfYi1Ot9BFOw7i/58d/hvOjMg3nx+A/7vQxqroeQFVn4vyIn+/G8pUbW4UvL+DW71+Ak5yex2lonoZzxtJOt8xcnPfvpzjtJT/GaaT1XM8ad/5Et8wYnLPp6ttfcP6IvIyzT8HZL1W1X3iaDFzl/pHx5Mvn7mXgMZyk+gHOGVZb6xj/wzhnhC3H2V83q+oCAFV9H6dt8Em+34cPeS3/DjATJ1nsA65W1Qqc9/9bnBMo1uAkWH+rRa/G2QdNSuVZL6aJcc/BX6mqdwY7FtP4iMgSYLaq3lVLuTk4Z0O95o5nYZ87AESkH04y6ul1ckKjZ1VVxjRzItIZpwrnK5zG91txrku41YfFb8M5A8mcqD1wQ1NLGmCJwxjjVMHdgFOlE4bTznG+qtZ6Oqx7koL3qckGUNVPay/VOFlVlTHGGL9Y47gxxhi/NIuqqpSUFO3evXuww6hScXEx8fHxwQ7jBKEaF1hsdWWx1U1zjW3RokX7VTWtypnB7vOkIR49e/bUUPXll18GO4QqhWpcqhZbXVlsddNcYwMWqvVVZYwxpj5Y4jDGGOMXSxzGGGP8YonDGGOMXyxxGGOM8YslDmOMMX6xxGGMMcYvljiMMcb4xRKHMcYYv1jiMMYY4xdLHMYYY/xiicMYY4xfLHEYY4zxiyUOY4wxfrHEYYwxxi8BTRwiMlZE1olItohMqmJ+tIhMdefPE5Eu7vSWIvKliBSJyNNeywwSkRXuMn8XEQnkNhhjjDlewBKHiIQDzwDnA5nA1SKS6VXsFiBPVbsDTwCPutNLgd8Bv6xi1f8CbgV6uI+x9R+9McaY6gTyiGMokK2qm1S1DJgCXOpV5lLgFXd4OjBaRERVi1V1Nk4COUZE2gFJqjrXvUPVq8CPaguk6Iie3JYYY4w5JpD3HO8AbPcYzwGGVVdGVctFJB9oCeyvYZ05XuvsUFVBEZkITASIbtONDz/7kvjI0KvVKioqIisrK9hhnCBU4wKLra4strqx2E4UyMQRVKo6GZgMEN2uhy4oac3DY/oGOaoTZWVlMXLkyGCHcYJQjQsstrqy2OrGYjtRIKuqdgDpHuMd3WlVlhGRCCAZyK1lnR1rWWeVXp2zhVU7830paowxpgaBTBwLgB4ikiEiUcB4YIZXmRnAje7wOGCW23ZRJVXdBRSIyHD3bKobgPdqCyQpSqhQeOi9VVRUWHuHMcacjIAlDlUtB+4EPgHWANNUdZWI/EFELnGLvQi0FJFs4F7g2Cm7IrIF+Btwk4jkeJyR9TPgBSAb2Ah8VFssKdFCWmI0i7bm8c7inNqKG2OMqUFA2zhUdSYw02vaQx7DpcAV1SzbpZrpC4F+/sQRJvDbC/pwz9Sl/Pmjtfwwsy3JcZH+rMIYY4yr2Vw5fump7RmakUpucRl//WxdsMMxxphGq9kkDhHhfy/tR3iY8PrcrazcYQ3lxhhTF80mcQD0apvIzWd0oULhwf+utIZyY4ypg2aVOADuGdOTNknRLN1+kDfmbwt2OMYY0+g0u8SREB3Bwxc7FwI+9tFa9hSU1rKEMcYYT80ucQCM7deWH/RpQ+Hhch6esSrY4RhjTKPSLBOHiPCHS/sSHxXORyt38+mq3cEOyRhjGo1mmTgA2qfE8qvzegHOFeWFpUeCHJExxjQOzTZxAFx/ehcGpKewu6CUv366PtjhGGNMo9CsE0d4mPB/l51CeJjwypwtLNmWF+yQjDEm5DXrxAGQ2T6JW8/qiio88O4KjhytCHZIxhgT0pp94gC4e3QPOqXGsXZ3IZO/3hTscIwxJqRZ4gBio8J55DKn38SnPt/Ahj2FQY7IGGNClyUO11k90rhqcDplRyv41fTlHLXuSIwxpkqWODz89qI+tEuOYen2g7w426qsjDGmKpY4PCTFRPKnH58CwF8+XU/23qIgR2SMMaHHEoeXUb1aM25QR8rKK7h/+jKrsjLGGC+WOKrwuwszaZMUzeJtB3n5283BDscYY0KKJY4qJMdF8n9uldXjn6xj8/7iIEdkjDGhwxJHNc7t3YYfn9aBw+UV/Optq7IyxphKljhq8NDFmaQlRrNwax4vzbYqK2OMAUscNUqJi+LRy7+vslq7uyDIERljTPBZ4qjFub3bcPXQTpQdreCeKUs5XH402CEZY0xQWeLwwYMX9qFLS6cvq799Zt2vG2OaN0scPoiPjuBvV51KmMDkrzcxd1NusEMyxpigscTho4GdWnDnqO6own3TllFgdww0xjRTljj8cNfoHpzSIZkdB0v4nxmrgx2OMcYEhSUOP0SGh/HEVacSHRHGO4tz+GjFrmCHZIwxDc4Sh5+6t07gNxf0AeCB/6xgV35JkCMyxpiGZYmjDm44vTMje6Vx8NAR7p6y1K4qN8Y0K5Y46kBE+MsVA0hLjGb+5gM8PSs72CEZY0yDCWjiEJGxIrJORLJFZFIV86NFZKo7f56IdPGY94A7fZ2InOcx/RciskpEVorIWyISE8htqE6rhGieuPJUROCpL9Yzf/OBYIRhjDENLmCJQ0TCgWeA84FM4GoRyfQqdguQp6rdgSeAR91lM4HxQF9gLPBPEQkXkQ7Az4HBqtoPCHfLBcWIHq24/ZxuVCjcM2UJBw+VBSsUY4xpMIE84hgKZKvqJlUtA6YAl3qVuRR4xR2eDowWEXGnT1HVw6q6Gch21wcQAcSKSAQQB+wM4DbU6t4xPTmtUwo780u5f/pyVK29wxjTtEmgfuhEZBwwVlUnuOPXA8NU9U6PMivdMjnu+EZgGPAwMFdVX3envwh8pKrTReRu4BGgBPhUVa+t5vUnAhMB0tLSBk2bNi0g2wmw71AFD31XQkk5XJ8ZxehOkT4vW1RUREJCQsBiq6tQjQsstrqy2OqmucY2atSoRao6uKp5EQF5xQARkRY4RyMZwEHgbRG5rjLBeFLVycBkgF69eunIkSMDGltsx53c+eYSpq4v55oxw+jTLsmn5bKysgh0bHURqnGBxVZXFlvdWGwnCmRV1Q4g3WO8ozutyjJu1VMykFvDsj8ANqvqPlU9ArwLnBGQ6P10Uf/2jB+STll5BT97YzGF1iWJMaaJCmTiWAD0EJEMEYnCacSe4VVmBnCjOzwOmKVO3dkMYLx71lUG0AOYD2wDhotInNsWMhpYE8Bt8MvvL+5L77aJbN5fzK/fsfYOY0zTFLDEoarlwJ3AJzg/7tNUdZWI/EFELnGLvQi0FJFs4F5gkrvsKmAasBr4GLhDVY+q6jycRvTFwAo3/smB2gZ/xUaF889rB5IQHcHMFbt5+dstwQ7JGGPqXUDbOFR1JjDTa9pDHsOlwBXVLPsITiO49/TfA7+v30jrT9e0BB4f15+fvrGYP81cw4D0ZAZ1Tg12WMYYU2/syvEAOP+UdtwyIoPyCuWON5aQW3Q42CEZY0y9scQRIJPO782gzi3YXVDKPVOtPytjTNNhiSNAIsPDeOaagbSMj+KbDft56osNwQ7JGGPqhSWOAGqbHMNT409DBP4xawOz1u4JdkjGGHPSLHEE2IgerbhvTE9U4e63lrJxX1GwQzLGmJNiiaMB/Gxkd8b2bUvh4XImvrrQLg40xjRqljgaQFiY8NcrB9CrTSIb9xXzi6lLqbDGcmNMI2WJo4HER0cw+YZBJMVE8PmavTxpjeXGmEbKEkcD6twynqevGUiYwN+/2MDHK3cFOyRjjPGbJY4GdnbPNCad3xuAe6ctI6ewIsgRGWOMfyxxBMGtZ3XlkgHtOVR2lL8vKSWv2O4caIxpPGpNHCLSU0S+cG+6hIj0F5EHAx9a0yUiPHp5f/q2T2LvIeW21xdRVm5HHsaYxsGXI47ngQeAIwCqupwg3ue7qYiNCueFGweTEi3M33yA3/xnhXXDboxpFHxJHHGqOt9rWnkggmlu2iXHcs/AaGIjw5m+KId/fbUx2CEZY0ytfEkc+0WkG6Bw7F7idjpQPemSHM4TV52KCDz28To+WmG71hgT2nxJHHcAzwG9RWQHcA9weyCDam7G9mvLr8c6Z1r9YtpSluccDG5AxhhTA18Sh6rqD4A0oLeqjvBxOeOH287uypWDO1J6pIJbXlnIzoMlwQ7JGGOq5EsCeAdAVYtVtdCdNj1wITVPIsIff3QKw7umsq/wMD/59wIKrE8rY0wIqjZxiEhvEbkcSBaRH3s8bgJiGizCZiQqIoxnrxtE11bxrN1dyO2v2Wm6xpjQU9MRRy/gIiAFuNjjMRC4NeCRNVMpcVG88pOhtEqI5ruNufxq+jLrENEYE1Iiqpuhqu8B74nI6ao6pwFjavbSU+P4981DuOq5Oby3dCdtk2J44II+wQ7LGGMA39o4lojIHSLyTxF5qfIR8MiauX4dknn2+kFEhAnPfb2Jl2ZvDnZIxhgD+JY4XgPaAucBXwEdgcIalzD14qweaTw2rj8A//vhaj5YvjPIERljjG+Jo7uq/g4oVtVXgAuBYYENy1T68cCO/Hpsb1Th3qnLmLspN9ghGWOaOV8SR+U5oQdFpB+QDLQOXEjG2+3ndOXG0ztTdrSCW19ZyMod+cEOyRjTjPmSOCaLSAvgQWAGsBp4NKBRmeOICA9d3JcL+7ej8HA5N7w0n+y9RcEOyxjTTNWaOFT1BVXNU9WvVbWrqrYGPmqA2IyH8DDhiStPZWSvNA4Ul3HdC/PYfuBQsMMyxjRDNSYOETldRMaJSGt3vL+IvAl82yDRmeNERYTxr2sHMbRLKrsLSrnuxXnsLSgNdljGmGampivHHwdeAi4HPhSRPwKfAvOAHg0TnvEWGxXOCzcNpl+HJLbmHuL6F+dz8JDdQdAY03BqOuK4EDhNVa8GfojTK+5wVX1KVe1vbhAlxUTyys1D6ZYWz7o9hdz08gKKD9stUowxDaOmxFFamSBUNQ/YoKpb/Fm5iIwVkXUiki0ik6qYHy0iU93580Ski8e8B9zp60TkPI/pKSIyXUTWisgaETndn5iaipYJ0bw+YRgdUmJZuv0gE15ZSEnZ0WCHZYxpBmpKHF1FZEblA8jwGq+RiIQDzwDnA5nA1SKS6VXsFiBPVbsDT+CereWWGw/0BcYC/3TXB/AU8LGq9gYGAGt83dimpl1yLG9MGEZaYjRzNuVy66sLKT1iycMYE1jV9lUFXOo1/lc/1z0UyFbVTQAiMsVd52qv13jYHZ4OPC0i4k6foqqHgc0ikg0MFZHVwNnATQCqWgY06wr+Lq3ieevW4YyfPJfZ2fu59dWFPH/DYGIiw2tf2Bhj6kBUA9PzqnuL2bGqOsEdvx4Ypqp3epRZ6ZbJccc34lyV/jAwV1Vfd6e/iHMKcDYwGSf5DAAWAXeranEVrz8RmAiQlpY2aNq0aQHZzpNVVFREQkLCSa9nR1EFj84voaAM+rcK566B0USGSdDjCgSLrW4strpprrGNGjVqkaoOrmpeTUccoSgCp1v3u1R1nog8BUwCfuddUFUn4yQZevXqpSNHjmzIOH2WlZVFfcU2eHAhVz8/l+X7y3hrWwL/um4g0RF1O/Koz7jqm8VWNxZb3VhsJwrkLWB3AOke4x3daVWWEZEInO5McmtYNgfIUdV57vTpOInEAL3aJvLGhGG0iItk1tq93PHGErsRlDGm3gUycSwAeohIhohE4TR2ezeqzwBudIfHAbPUqTubAYx3z7rKwLluZL6q7ga2i0gvd5nRHN9m0uz1aZfE6xOGkRIXyedr9nDHm4s5XG4N5saY+lNrVZWIvA94N4TkAwuB56q7pkNVy0XkTuATIBx4SVVXicgfgIWqOgN4EXjNbfw+gJNccMtNw0kK5cAdqlr563cX8IabjDYBN/u1xc1A3/bJvH7LMK59YR6frd7Dra8u4rnrBhEbZQ3mxpiT50sbxyYgDXjLHb8K534cPYHngeurW1BVZwIzvaY95DFcClxRzbKPAI9UMX0pUGWDjflevw7JvHXrcK5/cR5fr9/Hzf+ezws3DiEhurE1axljQo0vVVVnqOo1qvq++7gOGKKqd2DtCyEts30SU28bTuvEaOZuOsANL84jv+RI7QsaY0wNfEkcCSLSqXLEHa48/6tZX0PRGHRvnci0206nQ0osi7cd5NoX5pJXbG+bMabufEkc9wGzReRLEckCvgF+KSLxwCuBDM7Ujy6t4pl623A6t4xj5Y4Cxk+ey95C627MGFM3vtyPYybOWU33AHcDvVT1Q1UtVtUnAxueqS8dW8Qx7bbT6d46gXV7Crnqubl2Pw9jTJ34ejruIJx+owYAV4rIDYELyQRKm6QYpk4cTma7JDbvL+byf33H2t0FwQ7LGNPI1Jo4ROQ14C/ACGCI+7CzmhqplgnRTLltOMMyUtlbeJgrn53Dgi0Hgh2WMaYR8eWIYzBwpqr+TFXvch8/D3RgJnCSYiJ55SdDOa9vGwpKy7nuhXl8vnpPsMMyxjQSviSOlUDbQAdiGlZMZDj/vHYQVw9N53B5Bbe9vohpC7cHOyxjTCPgy9VgrYDVIjIfOFw5UVUvCVhUpkGEhwl/uuwUWiVE849Z2dw/fTm5RWXcfk7XYIdmjAlhviSOhwMdhAkeEeG+H/aiZXwUD7+/mkc/XsvOgyWMTApMd/vGmMav1sShql81RCAmuG46M4OWCdHc9/YyXpu7lWVp4Qw/s5x466LEGOOl2jYOEZntPheKSIHHo1BE7BzOJujiAe150+2Wffm+o1zx7Bx259uFgsaY41WbOFR1hPucqKpJHo9EVU1quBBNQxrcJZV3f3YmbeKE1bsK+NEz37J6p/1PMMZ8z6cLAEUkXETai0inykegAzPBk9EqngeHxzK4cwt2F5RyxbPfkbVub7DDMsaECF8uALwL2AN8BnzoPj4IcFwmyBKjhNcnDOPiAe0pLjvKLa8s5JXvthCoe9QbYxoPX1o+K/unyg10MCa0xESG89RVp9IpNZZnvtzI72esYs2uAv5waT+iIgJ580hjTCjz5du/HeeOf6YZCgsTfnVeb5686lSiI8KYsmA7174wl/1Fh2tf2BjTJPl6B8AsEfmQ4y8A/FvAojIh50endSCjVTwTX1vIgi15XPr0t0y+YRB92ycHOzRjTAPz5YhjG077RhSQ6PEwzcyA9BTev3MEp3VKYcfBEi7/13d8uHxXsMMyxjSwGo84RCQc6Kmq1zZQPCbEtU6K4a1bh/Pgf1cyfVEOd7y5mNW7unHvmF6Eh0mwwzPGNIAajzhU9SjQWUSiGige0wjERIbz+Lj+PHhhH8IEnvlyIze+NJ9ca/cwplnwpapqE/CtiPxORO6tfAQ6MBPaRIQJZ3Xl9VuG0TI+itnZ+7noH7NZvC0v2KEZYwLMl8SxEee6jTCsjcN4OaN7Kz78+VkM7JTCrvxSrnpuDq/Oses9jGnKfOnk8H8aIhDTeLVNjmHKxNP5v4/W8PK3W3jovVUs3prHn358CnFR1kmiMU1Nrd9qEUkD7se553hM5XRVPTeAcZlGJioijN9f3JeBnVrw63eW89+lO1m9q4BnrhlIjzZ2gGpMU+JLVdUbwFogA/gfYAuwIIAxmUbs4gHtmXHnmXRLi2f9niIufno2U+Zvs6orY5oQXxJHS1V9ETiiql+p6k8AO9ow1ereOpEZd47g8oEdKT1SwaR3V3DXW0soKD0S7NCMMfXAl8RR+W3fJSIXishpQGoAYzJNQHx0BH+9cgBPXDWA+KhwPli+iwv//g1L7KwrYxo9XxLHH0UkGbgP+CXwAvCLgEZlmozLTuvIBz8/i1M6JLP9QAlXPDuHf2VtpKLCqq6MaaxqTRyq+oGq5qvqSlUdpaqDVHVGQwRnmoaMVvG889MzmDAig/IK5dGP13LDS/Pt7oLGNFK+3I+jp4h8ISIr3fH+IvJg4EMzTUlURBgPXpTJyzcNIdW9YPCHT3zFe0t3BDs0Y4yffKmqeh54ALetQ1WXA+N9WbmIjBWRdSKSLSKTqpgfLSJT3fnzRKSLx7wH3OnrROQ8r+XCRWSJiNgNpRqZUb1b8/E9ZzG6d2sKSsu5e8pS7nxzMQcPlQU7NGOMj3xJHHGqOt9rWnltC7kdJD4DnA9kAleLSKZXsVuAPFXtDjwBPOoum4mTnPoCY4F/uuurdDewxofYTQhqnRjDCzcO5s8/PoU4t+H8h098bbenNaaR8CVx7BeRboACiMg4wJe+tIcC2aq6SVXLgCnApV5lLgVecYenA6NFRNzpU1T1sKpuBrLd9SEiHYELcRrpTSMlIowf2omP7z6bwZ1bsLfwMDe9vIAH/7uCQ2W1/i8xxgSR1HZhloh0BSYDZwB5wGbgWlXdWsty44CxqjrBHb8eGKaqd3qUWemWyXHHNwLDgIeBuar6ujv9ReAjVZ0uItOB/8PpL+uXqnpRNa8/EZgIkJaWNmjatGk1bmewFBUVkZCQEOwwTtCQcVWo8tHmI7y74QhHFdJihZv7RZPZMrzK8qG6z8BiqyuLrW4CGduoUaMWqergqub50lfVJuAHIhIPhKlqoYjcAzxZr1H6QEQuAvaq6iIRGVlTWVWdjJPw6NWrl44cWWPxoMnKyiIUY2vouM4dBTfvLOC+t5exZlcBjy0oZfyQdH5zYR+SYiKDGps/LLa6sdjqJlix+VJVBYCqFqtqoTvqS7fqO4B0j/GO7rQqy4hIBJAM5Naw7JnAJSKyBafq61wRed3XbTChLbN9EjPuPJP7xvQkKty5v/mYv33F56v3BDs0Y4wHnxOHF19u9bYA6CEiGe6NoMYD3td/zABudIfHAbPUqTubAYx3z7rKAHoA81X1AVXtqKpd3PXNUtXr6rgNJgRFhodx1+gefPhz5xa1ewoOM+HVhfz8rSV2oyhjQkRdE0etl/2qajlwJ/AJzhlQ01R1lYj8QUQucYu9CLQUkWyco5hJ7rKrgGnAauBj4A73boSmmejRJpHpt5/B7y7KJDYynBnLdjLmia/5z5Ic6zDRmCCrto1DRAqpOkEIEOvLylV1JjDTa9pDHsOlwBXVLPsI8EgN684CsnyJwzRO4WHCLSMyGNOnDZPeXc53G3P5xdRl9EkNI71vEd1bh2aDpTFNXbVHHKqaqKpJVTwSVdXuzmMaTKeWcbwxYRiPj+tPanwUaw5UcP5TX/P4J2spKbMDUWMaWl2rqoxpUCLCFYPT+eLeczinYwRHjirPfLmRMU98xay11nhuTEOyxGEalRbxUdzcL5p3fnoGvdsmkpNXwk/+vZDbXlvIjoMlwQ7PmGbBEodplAZ1bsEHd43gwQv7EB8Vzier9nDuX7L422fr7cpzYwLMEodptCLCw5hwVlc+v+8cLurfjsPlFfz9iw2M/qvT666dfWVMYFjiMI1eu+RYnr5mINNuO51+HZLYlV/K3VOWcsWzc1ieczDY4RnT5FjiME3G0IxU3rtjBI9d3p9WCVEs3JrHpc98y6/eXsbeArtplDH1xRKHaVLCw4Qrh6Tz5S9HctvZXYkIE95elMNIt/2j6LC1fxhzsixxmCYpMSaSBy7ow6e/OIcxmW04VHaUv3+xgXMe+5JXvttCWXlFsEM0ptGyxGGatIxW8Tx/w2Devv10BnZKIbe4jN/PWMWYJ77i/WU7rQHdmDqwxGGahSFdUnnnp2fw7HWD6JoWz9bcQ9z11hIufeZbvtu4P9jhGdOoWOIwzYaIMLZfWz6952z+dNkppCVGszwnn2uen8c1z89l4ZYDwQ7RmEbBEodpdiLCw7hmWCe++tVI7hvTk8SYCL7bmMu4Z+dw/YvzWLItL9ghGhPSLHGYZisuKoK7Rvdg9v3n8vNzu5MQHcE3G/Zz2T+/4yf/XsCKnPxgh2hMSLLEYZq95LhI7v1hL765fxQ/G9mNuKhwZq3dy8VPz2biqwtZucMSiDGeLHEY42oRH8X9Y3vzzf2jmHh2V2Iiw/h09R4u+sdsbnp5PvM3WxuIMWCJw5gTtEyI5jcX9OHr+0cxYUQGsZHhZK3bx5XPzeGKZ7/jy3V77TRe06xZ4jCmGq0TY3jwoky+m3QuPx/dg+TYSBZsyePmlxdw4d9n8+HyXRytsARimh9LHMbUokV8FPeO6cm3k87lNxf0Ji0xmtW7CrjjzcWM+dtXvDFvq92J0DQrdgtYY3yUEB3BxLO7ccPpXZi+KIdnv9rIpv3F/PY/K/nLJ+u4bnhnuql1ZWKaPkscxvgpJjKc64Z3ZvyQdD5auZsXvtnEspx8/jErmwiB2QXLuGVEBn3aJQU7VGMCwhKHMXUUER7GxQPac1H/dizcmscL32zi01V7mL4oh+mLchjRvRW3nJXBOT3SCAuTYIdrTL2xxGHMSRIRhnRJZUiXVKbNnMXq8jZMW7id2dn7mZ29ny4t47hueGfGDepISlxUsMM15qRZ47gx9ah1XBgPX9KXOZNGM+n83nRIiWVL7iH++OEahv3pC+6fvsyuSDeNnh1xGBMAyXGR3H5ON249qyuz1u7l1Tlb+GbDfqYtzGHawhwGpKdww/DOXNi/HTGR4cEO1xi/WOIwJoDCw4QxmW0Yk9mGzfuLeWPuVqYt3M6y7Qe5b/tB/vjhan48sCNXDUmnZ5vEYIdrjE8scRjTQDJaxfPgRZnc98NevL9sJ6/O3cLKHQW8OHszL87ezKnpKVw1JJ2L+rcjMSYy2OEaUy1LHMY0sNiocK4cks4VgzuyPCefqQu38/7SnSzdfpCl2w/yh/dXc2H/dlw1JJ3BnVsgYmdkmdBiicOYIBERBqSnMCA9hd9dmMnMFbuYunA78zcfOHZKb9e0eMYN6siPTu1A+5TYYIdsDGCJw5iQEBsVzuWDOnL5oI5s3l/MtIXbeWdRDpv2FfPYx+t4/JN1DMtI5bLTOjC2XzuSY60qywRPQE/HFZGxIrJORLJFZFIV86NFZKo7f56IdPGY94A7fZ2InOdOSxeRL0VktYisEpG7Axm/McGQ0SqeX4/tzXeTzuWFGwZzYf92RIaHMXfTAX79zgqGPPI5P3tjEZ+u2k1ZuXVxYhpewI44RCQceAYYA+QAC0Rkhqqu9ih2C5Cnqt1FZDzwKHCViGQC44G+QHvgcxHpCZQD96nqYhFJBBaJyGde6zSmSYgID+MHmW34QWYbCkqP8PHK3fx3yQ7mbMpl5ordzFyxm5S4SC7q346L+7dncJdUwu0KddMAAllVNRTIVtVNACIyBbgU8PyRvxR42B2eDjwtTkvgpcAUVT0MbBaRbGCoqs4BdgGoaqGIrAE6eK3TmCYnKSaSKwenc+XgdHbllzBj6U7+s2QHa3cX8vrcbbw+dxtpidGc368tF57SzpKICSgJ1A1pRGQcMFZVJ7jj1wPDVPVOjzIr3TI57vhGYBhOMpmrqq+7018EPlLV6R7LdgG+BvqpakEVrz8RmAiQlpY2aNq0aYHYzJNWVFREQkJCsMM4QajGBRabp+2FFczZWc6C3eXsK/n+u5wcLQxuE86QthH0bBFGmIjttzpqrrGNGjVqkaoOrmpeo2wcF5EE4B3gnqqSBoCqTgYmA/Tq1UtHjhzZcAH6ISsri1CMLVTjAovN2/WAqrJyRwEfrNjJzBW72H6ghC+2lfPFtnLSEqMZ27ct7Y4e5dbzzyYyPPR6GrL3tG6CFVsgE8cOIN1jvKM7raoyOSISASQDuTUtKyKROEnjDVV9NzChG9O4iAindEzmlI7JTBrb+4Qk8trcrQA8u+IzRvVuzZjMNpzTM80uNDR1EsjEsQDoISIZOD/644FrvMrMAG4E5gDjgFmqqiIyA3hTRP6G0zjeA5jvtn+8CKxR1b8FMHZjGq2qksjMlbt4b8EmdhaX897Snby3dCeR4cLwri35odsA3y7ZrhMxvglY4lDVchG5E/gECAdeUtVVIvIHYKGqzsBJAq+5jd8HcJILbrlpOI3e5cAdqnpUREbgHJmvEJGl7kv9RlVnBmo7jGnMPJPIsJjddO43hM9W7+bz1XtZuPUA32zYzzcb9vO791ZxSodkRvdpzcherenfIdnuIWKqFdA2DvcHfabXtIc8hkuBK6pZ9hHgEa9pswH7NBtTRxmt4pl4djcmnt2N3KLDzFq7l89W7+GbDftZsSOfFTvyefLzDaTGR3FWj1aM7JXG2T3SaJkQHezQTQhplI3jxpiT1zIhmisGp3PF4HRKjxzl2+z9fLluL1nr9pGTV3KsSksE+ndI5pyeaZzTqzWnpqfYqb7NnCUOYwwxkeGM7tOG0X3aoKps3FfMV+v3kbVuL/M2H2BZTj7LcvL5+6xsUuIiOaNbS87o1oozurUko1W8dcTYzFjiMMYcR0To3jqB7q0TuGVEBiVlR5m7KZesdXvJWr+PrbmHjl25DtAuOeZYEjmzeyvaJscEeQtMoFniMMbUKDYqnFG9WzOqd2sAtuwv5tuN+/luYy5zNuayK7+Udxbn8M7iHAC6psU7SaRbK4Z1bUlqvN1nvamxxGGM8UuXVvF0aRXPtcM6U1GhrN1dyHduIpm3KZdN+4rZtK+Y1+duA6B76wSGdEllaEYLhnRJpWOLuCBvgTlZljiMMXUWFiZktk8is30SE87qypGjFSzPOch32bl8u3E/S7YdJHtvEdl7i3hrvpNI2ifHMCQj1U0mqXRPC83uPEz1LHEYY+pNZHgYgzqnMqhzKneN7kFZeQUrduSzYMsBFmw+wIItB9iZX3rsjC2AFnGRdEmoYJVmc1qnFPp3TCEh2n6aQpm9O8aYgImKCGNQ5xYM6tyC28/pRkWFsn5vIQs2H2D+ljwWbD7A7oJS8g7Bkk/WARAm0LNNIqd1SuHU9BRO69SC7mkJdkFiCLHEYYxpMGFhQu+2SfRum8T1p3dBVcnJK+G1j7/jcHxblmw/yOqdBazdXcja3YW8NX87AInREfRPT+a09Bacmp7CKR2TaZNkZ28FiyUOY0zQiAjpqXGc0T6CkSP7AVB65Cgrd+SzdPtBlmw7yJJteezML+Xb7Fy+zc49tmxaYjT92idxSodk+nZI5pQOybRLjrFrShqAJQ5jTEiJiQxncJdUBndJPTZtT0HpsSSyPCeflTvz2Vd4mC/X7ePLdfuOlWsZH+UmkST6tU+mX4dkOraItWRSzyxxGGNCXpukGMb2a8vYfm0BqKhQtucdYsWOfFbuKGCl289WbnEZX6/fx9frv08miTER9G6b6FSRtUukd9tEerZJtC7lT4IlDmNMoxMWJnRuGU/nlvFc1L89wLH2klU7849LKLnFZSzYkseCLXnHrSM9NZZebZLo085JKr3aJtKlZRwRIXijq1BjicMY0yRUtpekp8Yxtl87wEkm+4oOs253IWt3FbJmdwFrdxWSvbeI7QdK2H6ghM/X7Dm2juiIMLqlJRzrcqV76wTyCisoK68gKsISSiVLHMaYJktEaJ0YQ+vEGM7qkXZs+pGjFWzZX8ya3YWsc5PJ2t2F7DhYwupdBazedfwdqR+a8zGdW8bR3SOp9GidSLfW8cRFNb+f0ea3xcaYZi8yPIwebRLp0SYRBrQ/Nr2g9MixK9037i1iw94iVmzdx/5SPdaVyqer9xy3rg4psXRpFUfnlvFktHS6Y8lo5Rz5REeEN/SmNQhLHMYY40qKiWRgpxYM7NTi2LSsrCyGn3kWm/YVk72viOw9hc7z3iI27y9mx8ESdhwsOe5UYQARaJ8cS0areDq3jCOjVTxd3MSSnhrbqJOKJQ5jjKlFTGT4sT65PJUfrWB7Xglb9hezJbeYLfuL2Zx7iC37i8nJO3QsqczOPn59YQJtk2LomBpHeos4OraIddpn3Oc2STEhfbMsSxzGGFNHEeFhZLSKJ6NV/AnzysoryMk7xJbcYjbvP/R9csktZkdeCTvzS9mZX8r8zQdOWDYyXGifEntcUunYIpaO7nirhOigJhZLHMYYEwBREWF0TUugaxW9/5aVV7DzYAnb8w6Rk1fC9gOH2J5XQk7eIbYfKGF/0WG25h5ia+6hKtcdESa0SYohXg7zzq4ltE+OoV1yDO1SYmmfHEu7lBhaxkcF7MJHSxzGGNPAoiLCjt3XpColZUfZcdBJIscnl0PsPFjKgeIydhwsAWB93s6qXyM8jLZuQmmfEuskluQY0hJjaJMUTZukGNISo4msw3UrljiMMSbExEaF0711It1bJ1Y5v/TIUXbnl/LRV3Np3aUXu/Kdqq/d+aXsPFjCrvxS8kuOsO3AIbYdqPqopVLL+ChaJ8XQOjH6WEJpXUsHkpY4jDGmkYmJDKdLq3j6tAxn5KCOVZY5VFbOzoNuMskvYdfBUvYUlrK3oJQ9BYfZW1jKvsLD5BaXkVtcxppdvr++JQ5jjGmC4qIijl2sWJ2jFUpu0WH2Fh5mj0dC2VNwmD/XsG5LHMYY00yFh4lTTZUUQ78OycfNqylxWOcrxhhj/GKJwxhjjF8scRhjjPGLJQ5jjDF+scRhjDHGL5Y4jDHG+CWgiUNExorIOhHJFpFJVcyPFpGp7vx5ItLFY94D7vR1InKer+s0xhgTWAFLHCISDjwDnA9kAleLSKZXsVuAPFXtDjwBPOoumwmMB/oCY4F/iki4j+s0xhgTQIE84hgKZKvqJlUtA6YAl3qVuRR4xR2eDowWpzvHS4EpqnpYVTcD2e76fFmnMcaYAArkleMdgO0e4znAsOrKqGq5iOQDLd3pc72W7eAO17ZOAERkIjDRHT0sIivrsA0NoRWwP9hBVCFU4wKLra4strpprrF1rm5Gk+1yRFUnA5MBRGShqg4OckhVCtXYQjUusNjqymKrG4vtRIGsqtoBpHuMd3SnVVlGRCKAZCC3hmV9WacxxpgACmTiWAD0EJEMEYnCaeye4VVmBnCjOzwOmKWq6k4f7551lQH0AOb7uE5jjDEBFLCqKrfN4k7gEyAceElVV4nIH4CFqjoDeBF4TUSygQM4iQC33DRgNVAO3KGqRwGqWqcP4Uyu582rT6EaW6jGBRZbXVlsdWOxeRHnD74xxhjjG7ty3BhjjF8scRhjjPFLk04cweqeRES2iMgKEVkqIgvdaaki8pmIbHCfW7jTRUT+7sa4XEQGeqznRrf8BhG5sbrXqyWWl0Rkr+d1LPUZi4gMcrc1211WTjK2h0Vkh7vvlorIBR7z/OqGxj2JYp47fap7QoUvcaWLyJcislpEVonI3aGy32qILRT2W4yIzBeRZW5s/1PT+qQBuxyqIbZ/i8hmj/12qju9Qb8L7vLhIrJERD4Ilf1WLVVtkg+cxvONQFcgClgGZDbQa28BWnlNewyY5A5PAh51hy8APgIEGA7Mc6enApvc5xbucIs6xHI2MBBYGYhYcM52G+4u8xFw/knG9jDwyyrKZrrvYTSQ4b634TW9z8A0YLw7/CzwUx/jagcMdIcTgfXu6wd9v9UQWyjsNwES3OFIYJ67jVWuD/gZ8Kw7PB6YWteYTyK2fwPjqijfoN8Fd/l7gTeBD2p6Hxpyv1X3aMpHHKHWPYln9yqvAD/ymP6qOuYCKSLSDjgP+ExVD6hqHvAZTr9dflHVr3HOWKv3WNx5Sao6V51P7qse66prbNXxqxsa99/euThd2XhvZ21x7VLVxe5wIbAGp+eCoO+3GmKrTkPuN1XVInc00n1oDetrsC6HaoitOg36XRCRjsCFwAvueE3vQ9C7amrKiaOqLk9q+oLVJwU+FZFF4nR9AtBGVXe5w7uBNu5wdXEGMv76iqWDO1zfMd7pVg+8JG51UB1iawkcVNXyk4nNrQY4DecfakjtN6/YIAT2m1vdshTYi/OjurGG9R3X5RDg2eVQvX8nvGNT1cr99oi7354QkWjv2HyM4WTf0yeB+4EKd7ym96FB91tVmnLiCKYRqjoQpxffO0TkbM+Z7j+SkDgPOpRicf0L6AacCuwC/hqsQEQkAXgHuEdVCzznBXu/VRFbSOw3VT2qqqfi9OowFOgdjDiq4h2biPQDHsCJcQhO9dOvGzouEbkI2Kuqixr6teuqKSeOoHVPoqo73Oe9wH9wvkB73MNZ3Oe9tcQZyPjrK5Yd7nC9xaiqe9wveAXwPM6+q0tsuTjVCxFe030iIpE4P8xvqOq77uSQ2G9VxRYq+62Sqh4EvgROr2F9QelyyCO2sW7Vn6rqYeBl6r7fTuY9PRO4RES24FQjnQs8RYjtt+PUpWGkMTxwrorfhNNIVNkg1LcBXjceSPQY/g6nbeJxjm9YfcwdvpDjG+Hm6/eNcJtxGuBauMOpdYypC8c3QNdbLJzYIHjBScbWzmP4Fzh1tuDcm8Wz4W8TTqNfte8z8DbHNy7+zMeYBKeO+kmv6UHfbzXEFgr7LQ1IcYdjgW+Ai6pbH3AHxzfyTqtrzCcRWzuP/fok8OdgfRfcdYzk+8bxoO+3auM8mYVD/YFzZsR6nHrW3zbQa3Z135hlwKrK18Wpg/wC2AB87vFhE5ybU20EVgCDPdb1E5wGrmzg5jrG8xZO1cURnLrNW+ozFmAwsNJd5mnc3ghOIrbX3NdejtMPmecP4m/d11mHxxkr1b3P7nsx3435bSDax7hG4FRDLQeWuo8LQmG/1RBbKOy3/sASN4aVwEM1rQ+Iccez3fld6xrzScQ2y91vK4HX+f7Mqwb9LnisYyTfJ46g77fqHtbliDHGGL805TYOY4wxAWCJwxhjjF8scRhjjPGLJQ5jjDF+scRhjDHGL5Y4jKknInLU7WF1mYgsFpEzaimfIiI/82G9WSIyuP4iNebkWOIwpv6UqOqpqjoApyuL/6ulfApOT6fGNCqWOIwJjCQgD5x+pUTkC/coZIWIVPZM+megm3uU8rhb9tdumWUi8meP9V3h3k9ivYic1bCbYszxImovYozxUazb+2oMzn0zznWnlwKXqWqBiLQC5orIDJxuS/qp0/EeInI+TnfXw1T1kIikeqw7QlWHinODpt8DP2iQLTKmCpY4jKk/JR5J4HTgVbcHVgH+5PaSXIHTpXWbKpb/AfCyqh4CUFXPe5VUdrS4CKd/L2OCxhKHMQGgqnPco4s0nH6C0oBBqnrE7QU1xs9VHnafj2LfWxNk1sZhTACISG+cnklzcbq93usmjVFAZ7dYIc7tXyt9BtwsInHuOjyrqowJGfbPxZj6U9nGAU711I2qelRE3gDeF5EVwEJgLYCq5orItyKyEvhIVX8lIqcCC0WkDJgJ/KbBt8KYWljvuMYYY/xiVVXGGGP8YonDGGOMXyxxGGOM8YslDmOMMX6xxGGMMcYvljiMMcb4xRKHMcYYv/w/32UiNOltfpIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
    "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "consistent-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1cycle scheduling\n",
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "funded-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "toxic-eleven",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/430 [==============================] - 2s 3ms/step - loss: nan - accuracy: 0.3117          \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "artificial-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "alpha-malaysia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.6572 - accuracy: 0.7740 - val_loss: 0.4872 - val_accuracy: 0.8336\n",
      "Epoch 2/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4581 - accuracy: 0.8396 - val_loss: 0.4275 - val_accuracy: 0.8524\n",
      "Epoch 3/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4122 - accuracy: 0.8546 - val_loss: 0.4117 - val_accuracy: 0.8580\n",
      "Epoch 4/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3837 - accuracy: 0.8643 - val_loss: 0.3868 - val_accuracy: 0.8686\n",
      "Epoch 5/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3639 - accuracy: 0.8717 - val_loss: 0.3767 - val_accuracy: 0.8682\n",
      "Epoch 6/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3456 - accuracy: 0.8773 - val_loss: 0.3741 - val_accuracy: 0.8708\n",
      "Epoch 7/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8809 - val_loss: 0.3634 - val_accuracy: 0.8714\n",
      "Epoch 8/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3185 - accuracy: 0.8859 - val_loss: 0.3954 - val_accuracy: 0.8596oss: 0.3168 - accuracy - ETA: 0s - loss: 0.3174 - ac\n",
      "Epoch 9/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3065 - accuracy: 0.8891 - val_loss: 0.3489 - val_accuracy: 0.8750\n",
      "Epoch 10/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.2945 - accuracy: 0.8925 - val_loss: 0.3397 - val_accuracy: 0.8808\n",
      "Epoch 11/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.8957 - val_loss: 0.3463 - val_accuracy: 0.8806\n",
      "Epoch 12/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.2710 - accuracy: 0.9021 - val_loss: 0.3653 - val_accuracy: 0.8686\n",
      "Epoch 13/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.2538 - accuracy: 0.9081 - val_loss: 0.3364 - val_accuracy: 0.8828\n",
      "Epoch 14/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.9135 - val_loss: 0.3466 - val_accuracy: 0.8810\n",
      "Epoch 15/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.2281 - accuracy: 0.9182 - val_loss: 0.3255 - val_accuracy: 0.8844\n",
      "Epoch 16/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.2160 - accuracy: 0.9236 - val_loss: 0.3299 - val_accuracy: 0.8846oss: 0.2161 - accuracy\n",
      "Epoch 17/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.2064 - accuracy: 0.9264 - val_loss: 0.3354 - val_accuracy: 0.8868\n",
      "Epoch 18/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1980 - accuracy: 0.9303 - val_loss: 0.3247 - val_accuracy: 0.8902\n",
      "Epoch 19/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1893 - accuracy: 0.9340 - val_loss: 0.3236 - val_accuracy: 0.8902\n",
      "Epoch 20/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1822 - accuracy: 0.9370 - val_loss: 0.3230 - val_accuracy: 0.8926\n",
      "Epoch 21/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1753 - accuracy: 0.9401 - val_loss: 0.3223 - val_accuracy: 0.8914\n",
      "Epoch 22/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1701 - accuracy: 0.9418 - val_loss: 0.3186 - val_accuracy: 0.8942\n",
      "Epoch 23/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1655 - accuracy: 0.9437 - val_loss: 0.3190 - val_accuracy: 0.8948\n",
      "Epoch 24/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1626 - accuracy: 0.9454 - val_loss: 0.3181 - val_accuracy: 0.8940\n",
      "Epoch 25/25\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1609 - accuracy: 0.9463 - val_loss: 0.3174 - val_accuracy: 0.8946\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train) / batch_size) * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "loaded-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 and l2 regularization\n",
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "exotic-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.2189 - accuracy: 0.7967 - val_loss: 0.7169 - val_accuracy: 0.8340\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7280 - accuracy: 0.8247 - val_loss: 0.6850 - val_accuracy: 0.8376\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bearing-inspector",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 3.2911 - accuracy: 0.7924 - val_loss: 0.7218 - val_accuracy: 0.8310\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7282 - accuracy: 0.8245 - val_loss: 0.6826 - val_accuracy: 0.8382\n"
     ]
    }
   ],
   "source": [
    "# functools.partial - create thin wrapper to regularize\n",
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "color-inside",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 7s 3ms/step - loss: 0.7611 - accuracy: 0.7576 - val_loss: 0.3730 - val_accuracy: 0.8644\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4306 - accuracy: 0.8401 - val_loss: 0.3395 - val_accuracy: 0.8720\n"
     ]
    }
   ],
   "source": [
    "# dropout\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "enhanced-contact",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7972 - accuracy: 0.7128 - val_loss: 0.6027 - val_accuracy: 0.8414\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5700 - accuracy: 0.7896 - val_loss: 0.5597 - val_accuracy: 0.8486\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5345 - accuracy: 0.8024 - val_loss: 0.5009 - val_accuracy: 0.8568\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5097 - accuracy: 0.8089 - val_loss: 0.4488 - val_accuracy: 0.8622\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5050 - accuracy: 0.8132 - val_loss: 0.4388 - val_accuracy: 0.8692\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4753 - accuracy: 0.8236 - val_loss: 0.4518 - val_accuracy: 0.86720s - loss: 0.4747 \n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4729 - accuracy: 0.8265 - val_loss: 0.4959 - val_accuracy: 0.8570\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4581 - accuracy: 0.8303 - val_loss: 0.4252 - val_accuracy: 0.8684\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4619 - accuracy: 0.8250 - val_loss: 0.4100 - val_accuracy: 0.8678\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4454 - accuracy: 0.8370 - val_loss: 0.4394 - val_accuracy: 0.8646\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4445 - accuracy: 0.8348 - val_loss: 0.4069 - val_accuracy: 0.8728\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4380 - accuracy: 0.8372 - val_loss: 0.5371 - val_accuracy: 0.8610\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4344 - accuracy: 0.8375 - val_loss: 0.4292 - val_accuracy: 0.8762\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4327 - accuracy: 0.8415 - val_loss: 0.4403 - val_accuracy: 0.8596\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4293 - accuracy: 0.8391 - val_loss: 0.4203 - val_accuracy: 0.8662\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4249 - accuracy: 0.8407 - val_loss: 0.4199 - val_accuracy: 0.8744\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4248 - accuracy: 0.8410 - val_loss: 0.5135 - val_accuracy: 0.8632\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4317 - accuracy: 0.8385 - val_loss: 0.4694 - val_accuracy: 0.8720\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4221 - accuracy: 0.8454 - val_loss: 0.4468 - val_accuracy: 0.8766\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4165 - accuracy: 0.8439 - val_loss: 0.4255 - val_accuracy: 0.8796\n"
     ]
    }
   ],
   "source": [
    "# alpha dropout for self-normalizing network based on SELU activation function\n",
    "# preserves mean & stdev of inputs\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "subjective-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4666905701160431, 0.862500011920929]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "minor-mistake",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3393 - accuracy: 0.8852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33931753039360046, 0.8851636648178101]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "surprised-space",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4203 - accuracy: 0.8438\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "worldwide-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo (MC) Dropout\n",
    "\n",
    "# single instance of model predict\n",
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "numerous-recovery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "gentle-greeting",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.67, 0.  , 0.3 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.83, 0.  , 0.17]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.2 , 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.37, 0.  , 0.52]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.01, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.3 , 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.07, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.22, 0.  , 0.57]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.58, 0.  , 0.01, 0.  , 0.41]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.35, 0.  , 0.01, 0.  , 0.64]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.81, 0.  , 0.16]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.01, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.04, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.12, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.52, 0.  , 0.47]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.22, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.11, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.02, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.66, 0.  , 0.28, 0.  , 0.07]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.  , 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.59, 0.  , 0.06, 0.  , 0.35]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.18, 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.33, 0.  , 0.48]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.  , 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.15, 0.  , 0.65]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.36, 0.  , 0.28, 0.01, 0.35]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.7 , 0.  , 0.  , 0.  , 0.29]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.16, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.45, 0.  , 0.43]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.15, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.31, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.45, 0.  , 0.5 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.32, 0.  , 0.49]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.71, 0.  , 0.06]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.46, 0.  , 0.  , 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.21, 0.01, 0.67]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.19, 0.  , 0.61]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.08, 0.  , 0.67]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.59, 0.  , 0.04, 0.  , 0.37]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.26, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.08, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.77, 0.  , 0.17]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.92, 0.  , 0.02]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.12, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.01, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.2 , 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.11, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.55, 0.  , 0.35, 0.  , 0.1 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.25, 0.  , 0.71]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.48, 0.  , 0.52]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.16, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.2 , 0.  , 0.7 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.18, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.09, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.35, 0.  , 0.06, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.19, 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.89, 0.  , 0.03, 0.  , 0.09]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.03, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.75, 0.  , 0.22, 0.  , 0.04]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.05, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.08, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.32, 0.  , 0.65]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.41, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.  , 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.72, 0.  , 0.12, 0.  , 0.16]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.11, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.  , 0.03, 0.  , 0.67]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fewer-yorkshire",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.16, 0.  , 0.71]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "appreciated-composition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.2 , 0.  , 0.29]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "grand-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fundamental-lawsuit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8669"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "purple-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "radio-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "sized-financing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_15 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout (MCAlphaDro (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_1 (MCAlphaD (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_2 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dying-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "everyday-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "controversial-response",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.16, 0.  , 0.74]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fallen-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max norm\n",
    "\n",
    "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "later-moldova",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5765 - accuracy: 0.8038 - val_loss: 0.3780 - val_accuracy: 0.8644\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3553 - accuracy: 0.8706 - val_loss: 0.3923 - val_accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
