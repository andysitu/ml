{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71965027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5978a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8804d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "259d3dc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ed149e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RangeDataset shapes: (), types: tf.int64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalent to\n",
    "tf.data.Dataset.range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47436f6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd4cab93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17511e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4af545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1cbb268",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35089c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: x < 5)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4bd933f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.take(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f04d2ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 3 0 4 2 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 7 1 0 3 2 5], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 6 9 8 9 7 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 1 4 5 2 8 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 9], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset = dataset.shuffle(buffer_size=3, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db668794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get housing dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "# scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72c79469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab9be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bc8ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf0a52cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
      "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
      "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n"
     ]
    }
   ],
   "source": [
    "with open(train_filepaths[0]) as f:\n",
    "    for i in range(3):\n",
    "        print(f.readline(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3341d2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets\\\\housing\\\\my_train_00.csv',\n",
       " 'datasets\\\\housing\\\\my_train_01.csv',\n",
       " 'datasets\\\\housing\\\\my_train_02.csv',\n",
       " 'datasets\\\\housing\\\\my_train_03.csv',\n",
       " 'datasets\\\\housing\\\\my_train_04.csv',\n",
       " 'datasets\\\\housing\\\\my_train_05.csv',\n",
       " 'datasets\\\\housing\\\\my_train_06.csv',\n",
       " 'datasets\\\\housing\\\\my_train_07.csv',\n",
       " 'datasets\\\\housing\\\\my_train_08.csv',\n",
       " 'datasets\\\\housing\\\\my_train_09.csv',\n",
       " 'datasets\\\\housing\\\\my_train_10.csv',\n",
       " 'datasets\\\\housing\\\\my_train_11.csv',\n",
       " 'datasets\\\\housing\\\\my_train_12.csv',\n",
       " 'datasets\\\\housing\\\\my_train_13.csv',\n",
       " 'datasets\\\\housing\\\\my_train_14.csv',\n",
       " 'datasets\\\\housing\\\\my_train_15.csv',\n",
       " 'datasets\\\\housing\\\\my_train_16.csv',\n",
       " 'datasets\\\\housing\\\\my_train_17.csv',\n",
       " 'datasets\\\\housing\\\\my_train_18.csv',\n",
       " 'datasets\\\\housing\\\\my_train_19.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aad9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input pipeline\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d1710ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_15.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_08.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_03.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_01.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_10.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_05.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_19.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_16.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_02.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_09.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_00.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_07.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_12.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_04.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_17.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_11.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_14.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_18.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_06.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_train_13.csv', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for filepath in filepath_dataset:\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50427200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interleave to read files 5 at a time & skip first line/ header row\n",
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d778d9b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'4.6477,38.0,5.03728813559322,0.911864406779661,745.0,2.5254237288135593,32.64,-117.07,1.504'\n",
      "b'8.72,44.0,6.163179916317992,1.0460251046025104,668.0,2.794979079497908,34.2,-118.18,4.159'\n",
      "b'3.8456,35.0,5.461346633416459,0.9576059850374065,1154.0,2.8778054862842892,37.96,-122.05,1.598'\n",
      "b'3.3456,37.0,4.514084507042254,0.9084507042253521,458.0,3.2253521126760565,36.67,-121.7,2.526'\n",
      "b'3.6875,44.0,4.524475524475524,0.993006993006993,457.0,3.195804195804196,34.04,-118.15,1.625'\n"
     ]
    }
   ],
   "source": [
    "for line in dataset.take(5):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce004a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 8\n",
    "\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78ba3e48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 0.16579159,  1.216324  , -0.05204564, -0.39215982, -0.5277444 ,\n",
       "        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e0c234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads housing data, preprocess, shuffles, etc\n",
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1) # prefetch is for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3eb5c02c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tf.Tensor(\n",
      "[[ 0.5804519  -0.20762321  0.05616303 -0.15191229  0.01343246  0.00604472\n",
      "   1.2525111  -1.3671792 ]\n",
      " [ 5.818099    1.8491895   1.1784915   0.28173092 -1.2496178  -0.3571987\n",
      "   0.7231292  -1.0023477 ]\n",
      " [-0.9253566   0.5834586  -0.7807257  -0.28213993 -0.36530012  0.27389365\n",
      "  -0.76194876  0.72684526]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.752]\n",
      " [1.313]\n",
      " [1.535]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "X = tf.Tensor(\n",
      "[[-0.8324941   0.6625668  -0.20741376 -0.18699841 -0.14536144  0.09635526\n",
      "   0.9807942  -0.67250353]\n",
      " [-0.62183803  0.5834586  -0.19862501 -0.3500319  -1.1437552  -0.3363751\n",
      "   1.107282   -0.8674123 ]\n",
      " [ 0.8683102   0.02970133  0.3427381  -0.29872298  0.7124906   0.28026953\n",
      "  -0.72915536  0.86178064]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[0.919]\n",
      " [1.028]\n",
      " [2.182]], shape=(3, 1), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "train_set = csv_reader_dataset(train_filepaths, batch_size=3)\n",
    "for X_batch, y_batch in train_set.take(2):\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2379a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9de1e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98c01890",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "839e4fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1332b608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "362/362 [==============================] - 2s 4ms/step - loss: 2.0914 - val_loss: 21.5124\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 0s 931us/step - loss: 0.8428 - val_loss: 0.6648\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 0s 928us/step - loss: 0.6329 - val_loss: 0.6196\n",
      "Epoch 4/10\n",
      "362/362 [==============================] - 0s 928us/step - loss: 0.5922 - val_loss: 0.5669\n",
      "Epoch 5/10\n",
      "362/362 [==============================] - 0s 865us/step - loss: 0.5622 - val_loss: 0.5402\n",
      "Epoch 6/10\n",
      "362/362 [==============================] - 0s 860us/step - loss: 0.5698 - val_loss: 0.5209\n",
      "Epoch 7/10\n",
      "362/362 [==============================] - 0s 906us/step - loss: 0.5195 - val_loss: 0.6130\n",
      "Epoch 8/10\n",
      "362/362 [==============================] - 0s 912us/step - loss: 0.5155 - val_loss: 0.4818\n",
      "Epoch 9/10\n",
      "362/362 [==============================] - 0s 915us/step - loss: 0.4965 - val_loss: 0.4904\n",
      "Epoch 10/10\n",
      "362/362 [==============================] - 0s 887us/step - loss: 0.4925 - val_loss: 0.4585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2004d37acd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10,\n",
    "          validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dc6bd63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 495us/step - loss: 0.4788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4787752032279968"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cc8de5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3576407],\n",
       "       [2.255291 ],\n",
       "       [1.4437605],\n",
       "       ...,\n",
       "       [0.5654393],\n",
       "       [3.9442453],\n",
       "       [1.0232248]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.map(lambda X, y: X)\n",
    "X_new = X_test\n",
    "model.predict(new_set, steps=len(X_new) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "821e9a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step 1810/1810"
     ]
    }
   ],
   "source": [
    "# build own custom training loop\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "total_steps = n_epochs * n_steps_per_epoch\n",
    "global_step = 0\n",
    "for X_batch, y_batch in train_set.take(total_steps):\n",
    "    global_step += 1\n",
    "    print(\"\\rGlobal step {}/{}\".format(global_step, total_steps), end=\"\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X_batch)\n",
    "        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "        loss = tf.add_n([main_loss] + model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f18827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56d080f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf function that performs training loop\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32,\n",
    "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    for X_batch, y_batch in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8f5e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFRecord\n",
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e0e30f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bbc22d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'File 0 record 0', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 1 record 0', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 2 record 0', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 0 record 1', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 1 record 1', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 2 record 1', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 0 record 2', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 1 record 2', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 2 record 2', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 3 record 0', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 4 record 0', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 3 record 1', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 4 record 1', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 3 record 2', shape=(), dtype=string)\n",
      "tf.Tensor(b'File 4 record 2', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# read multiple TFRecord in parallel\n",
    "filepaths = [\"my_test_{}.tfrecord\".format(i) for i in range(5)]\n",
    "for i, filepath in enumerate(filepaths):\n",
    "    with tf.io.TFRecordWriter(filepath) as f:\n",
    "        for j in range(3):\n",
    "            f.write(\"File {} record {}\".format(i, j).encode(\"utf-8\"))\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=3)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "517a4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compress TFRecord\n",
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47827d42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],\n",
    "                                  compression_type=\"GZIP\")\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "945146d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features api\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bda83436",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed932906",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c500accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cac12898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d4f979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_median_age = tf.feature_column.numeric_column(\"housing_median_age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d534c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mean, age_std = X_mean[1], X_std[1]  # The median age is column in 1\n",
    "housing_median_age = tf.feature_column.numeric_column(\n",
    "    \"housing_median_age\", normalizer_fn=lambda x: (x - age_mean) / age_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee3e9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_income = tf.feature_column.numeric_column(\"median_income\")\n",
    "bucketized_income = tf.feature_column.bucketized_column(\n",
    "    median_income, boundaries=[1.5, 3., 4.5, 6.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3730a0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BucketizedColumn(source_column=NumericColumn(key='median_income', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(1.5, 3.0, 4.5, 6.0))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucketized_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "669bdffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_prox_vocab = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
    "ocean_proximity = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"ocean_proximity\", ocean_prox_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "888b1f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VocabularyListCategoricalColumn(key='ocean_proximity', vocabulary_list=('<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocean_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd9d6b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HashedCategoricalColumn(key='city', hash_bucket_size=1000, dtype=tf.string)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_hash = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"city\", hash_bucket_size=1000)\n",
    "city_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e388d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketized_age = tf.feature_column.bucketized_column(\n",
    "    housing_median_age, boundaries=[-1., -0.5, 0., 0.5, 1.]) # age was scaled\n",
    "age_and_ocean_proximity = tf.feature_column.crossed_column(\n",
    "    [bucketized_age, ocean_proximity], hash_bucket_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a60994e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = tf.feature_column.numeric_column(\"latitude\")\n",
    "longitude = tf.feature_column.numeric_column(\"longitude\")\n",
    "bucketized_latitude = tf.feature_column.bucketized_column(\n",
    "    latitude, boundaries=list(np.linspace(32., 42., 20 - 1)))\n",
    "bucketized_longitude = tf.feature_column.bucketized_column(\n",
    "    longitude, boundaries=list(np.linspace(-125., -114., 20 - 1)))\n",
    "location = tf.feature_column.crossed_column(\n",
    "    [bucketized_latitude, bucketized_longitude], hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52ad793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_proximity_one_hot = tf.feature_column.indicator_column(ocean_proximity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b24569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_proximity_embed = tf.feature_column.embedding_column(ocean_proximity, dimension=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97b7bbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_house_value = tf.feature_column.numeric_column(\"median_house_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7ed0430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'housing_median_age': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None),\n",
       " 'median_house_value': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [housing_median_age, median_house_value]\n",
    "feature_descriptions = tf.feature_column.make_parse_example_spec(columns)\n",
    "feature_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a13d4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf transform\n",
    "try:\n",
    "    import tensorflow_transform as tft\n",
    "\n",
    "    def preprocess(inputs):  # inputs is a batch of input features\n",
    "        median_age = inputs[\"housing_median_age\"]\n",
    "        ocean_proximity = inputs[\"ocean_proximity\"]\n",
    "        standardized_age = tft.scale_to_z_score(median_age - tft.mean(median_age))\n",
    "        ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
    "        return {\n",
    "            \"standardized_median_age\": standardized_age,\n",
    "            \"ocean_proximity_id\": ocean_proximity_id\n",
    "        }\n",
    "except ImportError:\n",
    "    print(\"TF Transform is not installed. Try running: pip3 install -U tensorflow-transform\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18867d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf datasets\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "57408087",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abstract_reasoning', 'accentdb', 'aeslc', 'aflw2k3d', 'ag_news_subset', 'ai2_arc', 'ai2_arc_with_ir', 'amazon_us_reviews', 'anli', 'arc', 'bair_robot_pushing_small', 'bccd', 'beans', 'big_patent', 'bigearthnet', 'billsum', 'binarized_mnist', 'binary_alpha_digits', 'blimp', 'bool_q', 'c4', 'caltech101', 'caltech_birds2010', 'caltech_birds2011', 'cars196', 'cassava', 'cats_vs_dogs', 'celeb_a', 'celeb_a_hq', 'cfq', 'cherry_blossoms', 'chexpert', 'cifar10', 'cifar100', 'cifar10_1', 'cifar10_corrupted', 'citrus_leaves', 'cityscapes', 'civil_comments', 'clevr', 'clic', 'clinc_oos', 'cmaterdb', 'cnn_dailymail', 'coco', 'coco_captions', 'coil100', 'colorectal_histology', 'colorectal_histology_large', 'common_voice', 'coqa', 'cos_e', 'cosmos_qa', 'covid19sum', 'crema_d', 'curated_breast_imaging_ddsm', 'cycle_gan', 'dart', 'davis', 'deep_weeds', 'definite_pronoun_resolution', 'dementiabank', 'diabetic_retinopathy_detection', 'div2k', 'dmlab', 'downsampled_imagenet', 'drop', 'dsprites', 'dtd', 'duke_ultrasound', 'e2e_cleaned', 'emnist', 'eraser_multi_rc', 'esnli', 'eurosat', 'fashion_mnist', 'flic', 'flores', 'food101', 'forest_fires', 'fuss', 'gap', 'geirhos_conflict_stimuli', 'genomics_ood', 'german_credit_numeric', 'gigaword', 'glue', 'goemotions', 'gpt3', 'groove', 'gtzan', 'gtzan_music_speech', 'hellaswag', 'higgs', 'horses_or_humans', 'howell', 'i_naturalist2017', 'imagenet2012', 'imagenet2012_corrupted', 'imagenet2012_real', 'imagenet2012_subset', 'imagenet_a', 'imagenet_r', 'imagenet_resized', 'imagenet_v2', 'imagenette', 'imagewang', 'imdb_reviews', 'irc_disentanglement', 'iris', 'kitti', 'kmnist', 'lambada', 'lfw', 'librispeech', 'librispeech_lm', 'libritts', 'ljspeech', 'lm1b', 'lost_and_found', 'lsun', 'lvis', 'malaria', 'math_dataset', 'mctaco', 'mlqa', 'mnist', 'mnist_corrupted', 'movie_lens', 'movie_rationales', 'movielens', 'moving_mnist', 'multi_news', 'multi_nli', 'multi_nli_mismatch', 'natural_questions', 'natural_questions_open', 'newsroom', 'nsynth', 'nyu_depth_v2', 'omniglot', 'open_images_challenge2019_detection', 'open_images_v4', 'openbookqa', 'opinion_abstracts', 'opinosis', 'opus', 'oxford_flowers102', 'oxford_iiit_pet', 'para_crawl', 'patch_camelyon', 'paws_wiki', 'paws_x_wiki', 'pet_finder', 'pg19', 'piqa', 'places365_small', 'plant_leaves', 'plant_village', 'plantae_k', 'qa4mre', 'qasc', 'quac', 'quickdraw_bitmap', 'race', 'radon', 'reddit', 'reddit_disentanglement', 'reddit_tifu', 'resisc45', 'robonet', 'rock_paper_scissors', 'rock_you', 's3o4d', 'salient_span_wikipedia', 'samsum', 'savee', 'scan', 'scene_parse150', 'scicite', 'scientific_papers', 'sentiment140', 'shapes3d', 'siscore', 'smallnorb', 'snli', 'so2sat', 'speech_commands', 'spoken_digit', 'squad', 'stanford_dogs', 'stanford_online_products', 'starcraft_video', 'stl10', 'story_cloze', 'sun397', 'super_glue', 'svhn_cropped', 'ted_hrlr_translate', 'ted_multi_translate', 'tedlium', 'tf_flowers', 'the300w_lp', 'tiny_shakespeare', 'titanic', 'trec', 'trivia_qa', 'tydi_qa', 'uc_merced', 'ucf101', 'vctk', 'vgg_face2', 'visual_domain_decathlon', 'voc', 'voxceleb', 'voxforge', 'waymo_open_dataset', 'web_nlg', 'web_questions', 'wider_face', 'wiki40b', 'wiki_bio', 'wiki_table_questions', 'wiki_table_text', 'wikihow', 'wikipedia', 'wikipedia_toxicity_subtypes', 'wine_quality', 'winogrande', 'wmt14_translate', 'wmt15_translate', 'wmt16_translate', 'wmt17_translate', 'wmt18_translate', 'wmt19_translate', 'wmt_t2t_translate', 'wmt_translate', 'wordnet', 'wsc273', 'xnli', 'xquad', 'xsum', 'xtreme_pawsx', 'xtreme_xnli', 'yelp_polarity_reviews', 'yes_no']\n"
     ]
    }
   ],
   "source": [
    "print(tfds.list_builders())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8f4f4a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "mnist_train = mnist_train.repeat(5).batch(32).prefetch(1)\n",
    "for item in mnist_train:\n",
    "    images = item[\"image\"]\n",
    "    labels = item[\"label\"]\n",
    "    for index in range(5):\n",
    "        plt.subplot(1, 5, index + 1)\n",
    "        image = images[index, ..., 0]\n",
    "        label = labels[index].numpy()\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.title(label)\n",
    "        plt.axis(\"off\")\n",
    "    break # just showing part of the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28a90081",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1)\n",
      "[4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n"
     ]
    }
   ],
   "source": [
    "# keras expects each item to be tuple containing 2 elements (featuer & labels)\n",
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]\n",
    "mnist_train = mnist_train.repeat(5).batch(32)\n",
    "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "mnist_train = mnist_train.prefetch(1)\n",
    "for images, labels in mnist_train.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "04ee53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "58e2e5dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 849us/step - loss: 42.9108 - accuracy: 0.8034\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 695us/step - loss: 24.8643 - accuracy: 0.8701\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 699us/step - loss: 24.3896 - accuracy: 0.8718\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 698us/step - loss: 23.5890 - accuracy: 0.8775\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 715us/step - loss: 22.9626 - accuracy: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x200513c6250>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load() can do this with as_supervised=True\n",
    "datasets = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
    "mnist_train = datasets[\"train\"].repeat().prefetch(1)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
    "    keras.layers.Lambda(lambda images: tf.cast(images, tf.float32)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(mnist_train, steps_per_epoch=60000 // 32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "945c950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4dd2325a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 50)                48190600  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                816       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 48,191,433\n",
      "Trainable params: 833\n",
      "Non-trainable params: 48,190,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hub_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
    "                           output_shape=[50], input_shape=[], dtype=tf.string)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f1c6094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = tf.constant([\"It was a great movie\", \"The actors were amazing\"])\n",
    "embeddings = hub_layer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f210efc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 50), dtype=float32, numpy=\n",
       "array([[ 7.45939985e-02,  2.76720114e-02,  9.38646123e-02,\n",
       "         1.25124469e-01,  5.40293928e-04, -1.09435350e-01,\n",
       "         1.34755149e-01, -9.57818255e-02, -1.85177118e-01,\n",
       "        -1.69703495e-02,  1.75612606e-02, -9.06603858e-02,\n",
       "         1.12110220e-01,  1.04646273e-01,  3.87700424e-02,\n",
       "        -7.71859884e-02, -3.12189370e-01,  6.99466765e-02,\n",
       "        -4.88970093e-02, -2.99049795e-01,  1.31183028e-01,\n",
       "        -2.12630898e-01,  6.96169436e-02,  1.63592950e-01,\n",
       "         1.05169769e-02,  7.79720694e-02, -2.55230188e-01,\n",
       "        -1.80790052e-01,  2.93739915e-01,  1.62875261e-02,\n",
       "        -2.80566931e-01,  1.60284728e-01,  9.87277832e-03,\n",
       "         8.44555616e-04,  8.39456245e-02,  3.24002892e-01,\n",
       "         1.53253034e-01, -3.01048346e-02,  8.94618109e-02,\n",
       "        -2.39153411e-02, -1.50188789e-01, -1.81733668e-02,\n",
       "        -1.20483577e-01,  1.32937476e-01, -3.35325629e-01,\n",
       "        -1.46504581e-01, -1.25251599e-02, -1.64428815e-01,\n",
       "        -7.00765476e-02,  3.60923223e-02],\n",
       "       [-1.56998575e-01,  4.24599349e-02, -5.57703003e-02,\n",
       "        -8.08446854e-03,  1.23733155e-01,  3.89427543e-02,\n",
       "        -4.37901802e-02, -1.86987907e-01, -2.29341656e-01,\n",
       "        -1.27766818e-01,  3.83025259e-02, -1.07057482e-01,\n",
       "        -6.11584112e-02,  2.49654502e-01, -1.39712945e-01,\n",
       "        -3.91289443e-02, -1.35873526e-01, -3.58613044e-01,\n",
       "         2.53462754e-02, -1.58370987e-01, -1.38350084e-01,\n",
       "        -3.90771806e-01, -6.63642734e-02, -3.24838236e-02,\n",
       "        -2.20453963e-02, -1.68282315e-01, -7.40613639e-02,\n",
       "        -2.49074101e-02,  2.46460736e-01,  9.87201929e-05,\n",
       "        -1.85390845e-01, -4.92824614e-02,  1.09015472e-01,\n",
       "        -9.54203904e-02, -1.60352528e-01, -2.59811729e-02,\n",
       "         1.13778859e-01, -2.09578887e-01,  2.18261331e-01,\n",
       "        -3.11211571e-02, -6.12562597e-02, -8.66057724e-02,\n",
       "        -1.10762455e-01, -5.73977083e-03, -1.08923554e-01,\n",
       "        -1.72919363e-01,  1.00515485e-01, -5.64153939e-02,\n",
       "        -4.97694984e-02, -1.07776590e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
