{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "responsible-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2,3)] # select petal length & width\n",
    "y = (iris.target ==0).astype(np.int) # Iris setosa\n",
    "\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "important-dutch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "established-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opened-incentive",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21b065cd730>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "romance-recognition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "provincial-federal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "revised-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hazardous-contest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "consolidated-party",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suspended-albuquerque",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "linear-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "\"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "available-terminal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fallen-lambda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.17254902, 0.49803922, 0.71372549, 0.7254902 ,\n",
       "        0.63137255, 0.47058824, 0.21568627, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.16470588,\n",
       "        0.77647059, 0.98431373, 1.        , 0.98431373, 0.97647059,\n",
       "        0.96862745, 1.        , 0.98823529, 0.83921569, 0.39215686,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.        , 0.        , 0.91372549,\n",
       "        0.98823529, 0.92941176, 0.9372549 , 0.91764706, 0.92941176,\n",
       "        0.92156863, 0.92941176, 0.92941176, 0.99607843, 0.89019608,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00784314, 0.        , 0.        , 0.0627451 , 0.82352941,\n",
       "        0.88235294, 0.84313725, 0.68627451, 0.85098039, 0.84705882,\n",
       "        0.75686275, 0.76862745, 0.88627451, 0.86666667, 0.81960784,\n",
       "        0.19607843, 0.        , 0.        , 0.00784314, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
       "        0.        , 0.        , 0.78039216, 0.89803922, 0.90980392,\n",
       "        0.90196078, 0.96078431, 0.8       , 0.85882353, 0.99215686,\n",
       "        0.96078431, 0.81176471, 0.76078431, 0.8745098 , 0.90588235,\n",
       "        0.9254902 , 0.92156863, 0.        , 0.        , 0.01176471,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.        , 0.5372549 , 0.92156863, 0.8       , 0.81960784,\n",
       "        0.78823529, 0.81960784, 0.91764706, 0.74509804, 0.91764706,\n",
       "        0.85490196, 0.84313725, 0.93333333, 0.9372549 , 0.8       ,\n",
       "        0.74117647, 0.87843137, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.76078431, 0.78823529, 0.78431373, 0.81960784,\n",
       "        0.79215686, 0.75686275, 0.80392157, 0.76078431, 0.71764706,\n",
       "        0.85490196, 0.90588235, 0.77254902, 0.6745098 , 0.70980392,\n",
       "        0.75686275, 0.80392157, 0.78039216, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01176471, 0.83137255, 0.79607843, 0.7372549 , 0.74117647,\n",
       "        0.76862745, 0.77647059, 0.77647059, 0.78823529, 0.76862745,\n",
       "        0.85098039, 0.70196078, 0.65490196, 0.71764706, 0.85098039,\n",
       "        0.77254902, 0.79215686, 0.85882353, 0.11764706, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.13333333, 0.88235294, 0.78431373, 0.76078431, 0.74509804,\n",
       "        0.7372549 , 0.75294118, 0.76862745, 0.75294118, 0.66666667,\n",
       "        0.79215686, 0.74509804, 0.78823529, 0.76470588, 0.78431373,\n",
       "        0.78823529, 0.81960784, 0.89019608, 0.19607843, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.26666667, 0.88235294, 0.82352941, 0.82745098, 0.77647059,\n",
       "        0.75294118, 0.76862745, 0.8       , 0.76862745, 0.70980392,\n",
       "        0.83137255, 0.77254902, 0.76470588, 0.75294118, 0.80784314,\n",
       "        0.8627451 , 0.82352941, 0.89803922, 0.36470588, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.43529412, 0.8745098 , 0.89019608, 0.99215686, 0.81960784,\n",
       "        0.76862745, 0.8       , 0.82745098, 0.80784314, 0.71764706,\n",
       "        0.84705882, 0.80784314, 0.82352941, 0.79607843, 0.84313725,\n",
       "        0.95686275, 0.87843137, 0.89019608, 0.58823529, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.54509804, 0.88235294, 0.87843137, 1.        , 0.79215686,\n",
       "        0.80784314, 0.83137255, 0.81960784, 0.82745098, 0.74509804,\n",
       "        0.83529412, 0.79215686, 0.81176471, 0.80784314, 0.87058824,\n",
       "        1.        , 0.90196078, 0.8627451 , 0.74509804, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.70588235, 0.88627451, 0.87843137, 1.        , 0.78039216,\n",
       "        0.8       , 0.81176471, 0.83921569, 0.83921569, 0.74509804,\n",
       "        0.84705882, 0.80784314, 0.79607843, 0.80392157, 0.85882353,\n",
       "        0.95294118, 0.87843137, 0.83921569, 0.91764706, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.88235294, 0.8745098 , 0.89411765, 0.99607843, 0.81960784,\n",
       "        0.80784314, 0.81568627, 0.83529412, 0.82352941, 0.74901961,\n",
       "        0.84313725, 0.81176471, 0.8       , 0.81568627, 0.82745098,\n",
       "        0.97647059, 0.88627451, 0.83921569, 1.        , 0.14901961,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.98039216, 0.90980392, 0.94117647, 0.9372549 , 0.82745098,\n",
       "        0.79607843, 0.81960784, 0.80392157, 0.82745098, 0.77254902,\n",
       "        0.84313725, 0.81568627, 0.81568627, 0.83921569, 0.83529412,\n",
       "        0.9372549 , 0.90588235, 0.85882353, 1.        , 0.31764706,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.97254902, 0.9254902 , 0.96862745, 0.94117647, 0.79607843,\n",
       "        0.78431373, 0.81568627, 0.80784314, 0.83921569, 0.75686275,\n",
       "        0.83529412, 0.83137255, 0.81568627, 0.83137255, 0.82745098,\n",
       "        0.95294118, 0.94901961, 0.88235294, 0.99607843, 0.25882353,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.96862745, 0.90196078, 0.98823529, 0.88627451, 0.78039216,\n",
       "        0.82745098, 0.79215686, 0.82745098, 0.83529412, 0.71372549,\n",
       "        0.83529412, 0.83137255, 0.80784314, 0.79215686, 0.85882353,\n",
       "        0.81176471, 0.96862745, 0.87058824, 0.92941176, 0.40784314,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.03921569,\n",
       "        0.95686275, 0.85882353, 0.98039216, 0.80392157, 0.78039216,\n",
       "        0.81960784, 0.79215686, 0.81960784, 0.82745098, 0.74117647,\n",
       "        0.83921569, 0.80784314, 0.82352941, 0.78431373, 0.83137255,\n",
       "        0.60392157, 0.94117647, 0.81568627, 0.85882353, 0.54901961,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.08235294,\n",
       "        1.        , 0.87058824, 0.93333333, 0.72156863, 0.82352941,\n",
       "        0.75294118, 0.80784314, 0.81960784, 0.82352941, 0.74117647,\n",
       "        0.83529412, 0.82745098, 0.81960784, 0.75294118, 0.89411765,\n",
       "        0.60784314, 0.88627451, 0.93333333, 0.94509804, 0.65098039,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.14509804,\n",
       "        0.96078431, 0.88627451, 0.94509804, 0.58823529, 0.77254902,\n",
       "        0.74117647, 0.8       , 0.81960784, 0.82352941, 0.71764706,\n",
       "        0.83529412, 0.83529412, 0.78823529, 0.72156863, 0.84313725,\n",
       "        0.57254902, 0.84705882, 0.9254902 , 0.88235294, 0.60392157,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.22745098,\n",
       "        0.9372549 , 0.89019608, 1.        , 0.61960784, 0.75686275,\n",
       "        0.76470588, 0.8       , 0.81960784, 0.83529412, 0.70588235,\n",
       "        0.81176471, 0.85098039, 0.78039216, 0.76078431, 0.82745098,\n",
       "        0.61960784, 0.85882353, 0.9254902 , 0.84705882, 0.59215686,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.26666667,\n",
       "        0.91372549, 0.88627451, 0.95294118, 0.54509804, 0.78431373,\n",
       "        0.75686275, 0.80392157, 0.82352941, 0.81568627, 0.70588235,\n",
       "        0.80392157, 0.83137255, 0.79607843, 0.76862745, 0.84705882,\n",
       "        0.61568627, 0.70196078, 1.        , 0.84705882, 0.60784314,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.31764706,\n",
       "        0.88235294, 0.87843137, 0.82745098, 0.54117647, 0.85882353,\n",
       "        0.7254902 , 0.78823529, 0.83529412, 0.81176471, 0.77254902,\n",
       "        0.88627451, 0.83137255, 0.78431373, 0.74509804, 0.84313725,\n",
       "        0.71764706, 0.35294118, 1.        , 0.82745098, 0.57647059,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.35686275,\n",
       "        0.82352941, 0.90196078, 0.61960784, 0.44705882, 0.80392157,\n",
       "        0.73333333, 0.81568627, 0.81960784, 0.80784314, 0.75686275,\n",
       "        0.82352941, 0.82745098, 0.8       , 0.76470588, 0.8       ,\n",
       "        0.70980392, 0.09019608, 1.        , 0.83529412, 0.61960784,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.34117647,\n",
       "        0.80392157, 0.90980392, 0.42745098, 0.64313725, 1.        ,\n",
       "        0.83921569, 0.87843137, 0.87058824, 0.82352941, 0.77254902,\n",
       "        0.83921569, 0.88235294, 0.87058824, 0.82745098, 0.8627451 ,\n",
       "        0.85098039, 0.        , 0.91764706, 0.84705882, 0.6627451 ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.36078431,\n",
       "        0.83529412, 0.90980392, 0.57254902, 0.01960784, 0.5254902 ,\n",
       "        0.59215686, 0.63529412, 0.66666667, 0.71764706, 0.71372549,\n",
       "        0.64313725, 0.65098039, 0.69803922, 0.63529412, 0.61176471,\n",
       "        0.38431373, 0.        , 0.94117647, 0.88235294, 0.82352941,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.16862745,\n",
       "        0.64313725, 0.80784314, 0.55294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.49803922, 0.49019608, 0.29803922,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "yellow-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build neural network with 2 hidden layers\n",
    "model = keras.models.Sequential() # Sequential Model (simplest of Keras model)\n",
    "# can also set keras.layers.InputLayer\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28])) # first layer: convert img into 1D array\n",
    "# Dense hidden layer w/ 300 neurs. Use ReLU activation function\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "informal-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tired-surrey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# first layer has 784 x 300 connection weights + 300 bias terms (235500)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "indian-poison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bigger-plaza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x21b0defd610>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x21b0defd520>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x21b2baff970>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x21b2bb09340>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "worth-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "distinct-registrar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "medical-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fifth-singles",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01799393, -0.01566144,  0.00867792, ...,  0.02165788,\n",
       "         0.02880877, -0.05797598],\n",
       "       [ 0.0495707 ,  0.03640613, -0.07079763, ...,  0.04520951,\n",
       "         0.04506169,  0.04153097],\n",
       "       [-0.06430025, -0.0250102 , -0.03008044, ..., -0.06167748,\n",
       "         0.05819206, -0.01542842],\n",
       "       ...,\n",
       "       [ 0.01952288,  0.05281962,  0.00455221, ...,  0.00783644,\n",
       "         0.07255007, -0.07078046],\n",
       "       [-0.00797911, -0.01503019,  0.0194175 , ..., -0.02023831,\n",
       "         0.00036897, -0.06422428],\n",
       "       [ 0.04801165, -0.02860861, -0.04867455, ..., -0.01501532,\n",
       "         0.05350287,  0.05701736]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tight-bones",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "instant-yorkshire",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "different-ecology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "swedish-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse_categorical_crossentropy - sparse labels (0-9 target class index)\n",
    "# sgd - train using Stoichastic Gradient Descent\n",
    "# thus Keras does backpropagation algorithm - reverse-model autodiff plus SGD\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "limited-surrey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 1.0134 - accuracy: 0.6696 - val_loss: 0.5122 - val_accuracy: 0.8320\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5067 - accuracy: 0.8258 - val_loss: 0.4614 - val_accuracy: 0.8444\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4495 - accuracy: 0.8424 - val_loss: 0.4179 - val_accuracy: 0.8628\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4178 - accuracy: 0.8552 - val_loss: 0.3977 - val_accuracy: 0.8624\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3887 - accuracy: 0.8632 - val_loss: 0.3879 - val_accuracy: 0.8710 - loss: 0.3781 -  - ETA: 1s - loss: 0.3836 - accuracy -\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3793 - accuracy: 0.8658 - val_loss: 0.3684 - val_accuracy: 0.8736\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3706 - accuracy: 0.8676 - val_loss: 0.3605 - val_accuracy: 0.8752\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3477 - accuracy: 0.8776 - val_loss: 0.3505 - val_accuracy: 0.8814\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3468 - accuracy: 0.8755 - val_loss: 0.3494 - val_accuracy: 0.8804\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3329 - accuracy: 0.8820 - val_loss: 0.3494 - val_accuracy: 0.8758\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3170 - accuracy: 0.8868 - val_loss: 0.3644 - val_accuracy: 0.8694\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3213 - accuracy: 0.8844 - val_loss: 0.3249 - val_accuracy: 0.8880\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3100 - accuracy: 0.8877 - val_loss: 0.3261 - val_accuracy: 0.8874\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2986 - accuracy: 0.8934 - val_loss: 0.3373 - val_accuracy: 0.8828\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2942 - accuracy: 0.8939 - val_loss: 0.3390 - val_accuracy: 0.8782\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2849 - accuracy: 0.8954 - val_loss: 0.3217 - val_accuracy: 0.8812\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2826 - accuracy: 0.8994 - val_loss: 0.3106 - val_accuracy: 0.8882\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2732 - accuracy: 0.9024 - val_loss: 0.3104 - val_accuracy: 0.8888\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2693 - accuracy: 0.9031 - val_loss: 0.3095 - val_accuracy: 0.8900\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2668 - accuracy: 0.9041 - val_loss: 0.3090 - val_accuracy: 0.8926\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2669 - accuracy: 0.9034 - val_loss: 0.3380 - val_accuracy: 0.8800\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2539 - accuracy: 0.9084 - val_loss: 0.3102 - val_accuracy: 0.8898\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2501 - accuracy: 0.9099 - val_loss: 0.3110 - val_accuracy: 0.8888\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2436 - accuracy: 0.9134 - val_loss: 0.3111 - val_accuracy: 0.8874\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2450 - accuracy: 0.9112 - val_loss: 0.2949 - val_accuracy: 0.8926\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2388 - accuracy: 0.9142 - val_loss: 0.3112 - val_accuracy: 0.8894\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2376 - accuracy: 0.9145 - val_loss: 0.3400 - val_accuracy: 0.8802\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2280 - accuracy: 0.9192 - val_loss: 0.2959 - val_accuracy: 0.8936\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2264 - accuracy: 0.9188 - val_loss: 0.3098 - val_accuracy: 0.8872\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2223 - accuracy: 0.9209 - val_loss: 0.3022 - val_accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "short-transportation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "soviet-buffer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "latin-cause",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "anonymous-belief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 55.1234 - accuracy: 0.8620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[55.12336730957031, 0.8619999885559082]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ruled-wealth",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_prob = model.predict(X_new)\n",
    "y_prob.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "greater-application",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_classes (deprecated) or np argmax \n",
    "# to give highest estiamted probability\n",
    "\n",
    "# y_pred = model.predict_classes(X_new)\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "arbitrary-trader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sticky-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "manual-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "remarkable-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "hollywood-spice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2656 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7413 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6604 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6245 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5770 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5609 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.5500 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5200 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5051 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.4910 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4794 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4693 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4537 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4586 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.4612 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.4407 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.4128 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 674us/step - loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "particular-gazette",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3885664],\n",
       "       [1.6792021],\n",
       "       [3.1022797]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "administrative-enhancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot test vs training data comparison\n",
    "# they're about 1/2 epoch off in interval\n",
    "\n",
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "congressional-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wide & deep neural network\n",
    "\n",
    "# input object\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "# concatenate input & output of second hidden layer\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "# pass result of cancatenation\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "# create Keras Model, specifying inputs and outputs\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "experimental-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30)           930         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "buried-scheduling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.2566 - val_loss: 0.6913\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6795 - val_loss: 0.9454\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6284 - val_loss: 0.6622\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5929 - val_loss: 0.5284\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5452 - val_loss: 0.5004\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5313 - val_loss: 0.5894\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.5889\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4938 - val_loss: 0.4690\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4789 - val_loss: 0.5305\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4728 - val_loss: 0.5466\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 969us/step - loss: 0.4614 - val_loss: 0.4996\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4521 - val_loss: 0.7264\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4522 - val_loss: 0.4205\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4421 - val_loss: 0.4467\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4467 - val_loss: 0.4167\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4471 - val_loss: 0.4486\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4021\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.3991\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4096 - val_loss: 0.4348\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4032 - val_loss: 0.3965\n",
      "162/162 [==============================] - 0s 653us/step - loss: 0.4164\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "owned-insider",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "assigned-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "thousand-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "infrared-sweden",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.1941 - val_loss: 0.8072\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7247 - val_loss: 0.6658\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6176 - val_loss: 0.5687\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5799 - val_loss: 0.5296\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5409 - val_loss: 0.4993\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5173 - val_loss: 0.4811\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5186 - val_loss: 0.4696\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4977 - val_loss: 0.4496\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4765 - val_loss: 0.4404\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4676 - val_loss: 0.4315\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4574 - val_loss: 0.4268\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4479 - val_loss: 0.4166\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4125\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.4074\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4044\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4495 - val_loss: 0.4007\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4013\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4375 - val_loss: 0.3987\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4151 - val_loss: 0.3934\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4078 - val_loss: 0.4204\n",
      "162/162 [==============================] - 0s 728us/step - loss: 0.4219\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "# length 5 (A) & 6 (B)\n",
    "# which matches shape in input A & B\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "suited-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "educated-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "global-assurance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.2165 - main_output_loss: 3.0213 - aux_output_loss: 4.9724 - val_loss: 1.5430 - val_main_output_loss: 0.9144 - val_aux_output_loss: 7.2005\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0694 - main_output_loss: 0.8370 - aux_output_loss: 3.1602 - val_loss: 1.3118 - val_main_output_loss: 0.6824 - val_aux_output_loss: 6.9755\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8493 - main_output_loss: 0.6993 - aux_output_loss: 2.1995 - val_loss: 1.2622 - val_main_output_loss: 0.6458 - val_aux_output_loss: 6.8096\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7420 - main_output_loss: 0.6330 - aux_output_loss: 1.7228 - val_loss: 1.2022 - val_main_output_loss: 0.6136 - val_aux_output_loss: 6.5002\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6819 - main_output_loss: 0.5849 - aux_output_loss: 1.5553 - val_loss: 1.1395 - val_main_output_loss: 0.5936 - val_aux_output_loss: 6.0520\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6386 - main_output_loss: 0.5506 - aux_output_loss: 1.4306 - val_loss: 1.0780 - val_main_output_loss: 0.5756 - val_aux_output_loss: 5.5994\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6399 - main_output_loss: 0.5537 - aux_output_loss: 1.4158 - val_loss: 1.0279 - val_main_output_loss: 0.5736 - val_aux_output_loss: 5.1171\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5975 - main_output_loss: 0.5204 - aux_output_loss: 1.2917 - val_loss: 0.9418 - val_main_output_loss: 0.5303 - val_aux_output_loss: 4.6458\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5751 - main_output_loss: 0.4983 - aux_output_loss: 1.2669 - val_loss: 0.8708 - val_main_output_loss: 0.4978 - val_aux_output_loss: 4.2276\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5649 - main_output_loss: 0.4843 - aux_output_loss: 1.2901 - val_loss: 0.8195 - val_main_output_loss: 0.4841 - val_aux_output_loss: 3.8377\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5500 - main_output_loss: 0.4752 - aux_output_loss: 1.2238 - val_loss: 0.7537 - val_main_output_loss: 0.4494 - val_aux_output_loss: 3.4921\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5370 - main_output_loss: 0.4633 - aux_output_loss: 1.2009 - val_loss: 0.7160 - val_main_output_loss: 0.4406 - val_aux_output_loss: 3.1950\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5294 - main_output_loss: 0.4632 - aux_output_loss: 1.1255 - val_loss: 0.6766 - val_main_output_loss: 0.4277 - val_aux_output_loss: 2.9166\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5217 - main_output_loss: 0.4565 - aux_output_loss: 1.1078 - val_loss: 0.6483 - val_main_output_loss: 0.4205 - val_aux_output_loss: 2.6986\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5216 - main_output_loss: 0.4592 - aux_output_loss: 1.0837 - val_loss: 0.6235 - val_main_output_loss: 0.4134 - val_aux_output_loss: 2.5145\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5248 - main_output_loss: 0.4614 - aux_output_loss: 1.0955 - val_loss: 0.6047 - val_main_output_loss: 0.4097 - val_aux_output_loss: 2.3605\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5109 - main_output_loss: 0.4483 - aux_output_loss: 1.0742 - val_loss: 0.5920 - val_main_output_loss: 0.4066 - val_aux_output_loss: 2.2606\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5107 - main_output_loss: 0.4486 - aux_output_loss: 1.0692 - val_loss: 0.5791 - val_main_output_loss: 0.4037 - val_aux_output_loss: 2.1570\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4822 - main_output_loss: 0.4247 - aux_output_loss: 1.0002 - val_loss: 0.5688 - val_main_output_loss: 0.4018 - val_aux_output_loss: 2.0722\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4768 - main_output_loss: 0.4193 - aux_output_loss: 0.9941 - val_loss: 0.5611 - val_main_output_loss: 0.4013 - val_aux_output_loss: 1.9989\n",
      "162/162 [==============================] - 0s 759us/step - loss: 0.4822 - main_output_loss: 0.4278 - aux_output_loss: 0.9714\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021B2BE1C430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "parliamentary-nightlife",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 1ms/step - loss: 0.4822 - main_output_loss: 0.4278 - aux_output_loss: 0.9714\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "[X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "rental-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "magnetic-dinner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3289803],\n",
       "       [1.8843516],\n",
       "       [3.3908253]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "worldwide-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subclass api to build model\n",
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args (e.g., name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cathedral-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save & load a trained model\n",
    "# model.save(\"my_keras_model.h5\")\n",
    "# model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cognitive-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks to save at reguar intervals\n",
    "# checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")\n",
    "# history = model.fit(X_train, y_train, epochs=10, callbacks=\n",
    "# [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "rental-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "patient-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "surgical-construction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.3697 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6964 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6167 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5846 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5321 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5083 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5044 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4813 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4549 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 606us/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "# rollback to best model\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") \n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "constitutional-bicycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4578 - val_loss: 0.4110\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4430 - val_loss: 0.4266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.3996\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4361 - val_loss: 0.3939\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.3889\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4112 - val_loss: 0.3866\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4226 - val_loss: 0.3860\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.3793\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4039 - val_loss: 0.3746\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.3723\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3950 - val_loss: 0.3697\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.3669\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.3661\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3868 - val_loss: 0.3631\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.3660\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.3625\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.3592\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3801 - val_loss: 0.3563\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3679 - val_loss: 0.3535\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.3709\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3512\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.3699\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3476\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.3561\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.3527\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3626 - val_loss: 0.3700\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3432\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3684 - val_loss: 0.3592\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3581 - val_loss: 0.3521\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3687 - val_loss: 0.3626\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3431\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3555 - val_loss: 0.3765\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3620 - val_loss: 0.3374\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3407\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.3614\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3451 - val_loss: 0.3348\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.3573\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.3367\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.3425\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.3369\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3675 - val_loss: 0.3515\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3471 - val_loss: 0.3426\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.3677\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3564\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3499 - val_loss: 0.3457\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3623 - val_loss: 0.3433\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 0.3659\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3286\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3268\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3483 - val_loss: 0.3439\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3263\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3468 - val_loss: 0.3910\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3275\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3462 - val_loss: 0.3561\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.3237\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3395 - val_loss: 0.3242\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3315 - val_loss: 0.3765\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3394 - val_loss: 0.3289\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3502\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3456\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3445\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3290\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.3217\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3351\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3232\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3470 - val_loss: 0.3566\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.3257\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3348\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3316 - val_loss: 0.3560\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.3583\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3201 - val_loss: 0.3287\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3203\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3327 - val_loss: 0.3840\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3268 - val_loss: 0.3233\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3322 - val_loss: 0.3476\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.3407\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 0.3462\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3310 - val_loss: 0.3347\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3354\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3297 - val_loss: 0.3274\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.3167\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.3280\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3182 - val_loss: 0.3634\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.3176\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3184 - val_loss: 0.3156\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3395 - val_loss: 0.3529\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.3258\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.3630\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3192 - val_loss: 0.3376\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3211\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3456\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.3158\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3209 - val_loss: 0.3409\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3379\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3341 - val_loss: 0.3213\n",
      "162/162 [==============================] - 0s 614us/step - loss: 0.3310\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "atomic-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "julian-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "emerging-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "infrared-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "failing-hindu",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 3.3697 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6964 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6167 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5846 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5321 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5083 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5044 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4813 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4549 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4416 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4295 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4326 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4070 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3902 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3978 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3823 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3839 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3843 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "documentary-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run: tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "arabic-apollo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_03_30-21_56_23'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "amazing-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "looking-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with diff learning rate\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "automatic-dimension",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.7645 - val_loss: 302.8536\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 8159520618.2209 - val_loss: 1.3230\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3439 - val_loss: 1.3176\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3546 - val_loss: 1.3261\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3513 - val_loss: 1.3154\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3274 - val_loss: 1.3203\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3639 - val_loss: 1.3149\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3487 - val_loss: 1.3157\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3445 - val_loss: 1.3150\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3172\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3622 - val_loss: 1.3174\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3389 - val_loss: 1.3150\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3336 - val_loss: 1.3270\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3429 - val_loss: 1.3195\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3275 - val_loss: 1.3157\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3669 - val_loss: 1.3182\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3645 - val_loss: 1.3223\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3839 - val_loss: 1.3154\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3078 - val_loss: 1.3168\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3215 - val_loss: 1.3151\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3344 - val_loss: 1.3174\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3269 - val_loss: 1.3204\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3590 - val_loss: 1.3164\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3381 - val_loss: 1.3157\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3265 - val_loss: 1.3180\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3532 - val_loss: 1.3195\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3552 - val_loss: 1.3157\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3447 - val_loss: 1.3222\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3379 - val_loss: 1.3267\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3583 - val_loss: 1.3174\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "monthly-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "alternative-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "corporate-importance",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.8887 - val_loss: 10.5492\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9724 - val_loss: 0.5672\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5460 - val_loss: 0.4875\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5080 - val_loss: 0.4654\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4745 - val_loss: 0.4563\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4489 - val_loss: 0.4691\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4608 - val_loss: 0.4507\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4390 - val_loss: 0.4346\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4270 - val_loss: 0.4450\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4237 - val_loss: 0.4676\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4109 - val_loss: 0.4191\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4110 - val_loss: 0.4730\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4081 - val_loss: 0.4531\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4157\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4068 - val_loss: 0.4239\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4113\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3917 - val_loss: 0.4587\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3940 - val_loss: 0.4396\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4269\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.4792\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3892 - val_loss: 0.4489\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3718 - val_loss: 0.4685\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4007 - val_loss: 0.3778\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3789 - val_loss: 0.4161\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.4650\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.4595\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.3705\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3839 - val_loss: 0.4312\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3750 - val_loss: 0.3977\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3812 - val_loss: 0.4618\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3732 - val_loss: 0.4339\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3711 - val_loss: 0.4634\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3725 - val_loss: 0.3736\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3651 - val_loss: 0.3775\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3606 - val_loss: 0.4735\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3591 - val_loss: 0.3513\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3887 - val_loss: 0.4120\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3616\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3851 - val_loss: 0.3634\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.4097\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.4119\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3591 - val_loss: 0.4322\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 0.4297\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.4451\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3687 - val_loss: 0.3515\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3710\n",
      "162/162 [==============================] - 0s 889us/step - loss: 0.3567\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021B12017550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), \n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "painted-andrews",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3566841185092926\n"
     ]
    }
   ],
   "source": [
    "# print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "nervous-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "interstate-circumstances",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.6483 - val_loss: 5.1557\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5594 - val_loss: 0.5296\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 3.7910\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 39.2703\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5196 - val_loss: 185.7293\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.2191 - val_loss: 3.7338\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8607 - val_loss: 660.4578\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 13.5879 - val_loss: 0.3848\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4367 - val_loss: 0.3630\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2181 - val_loss: 0.3990\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3864 - val_loss: 0.5166\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.3527\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.3748\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3558 - val_loss: 0.4305\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3523 - val_loss: 0.5472\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 0.5236\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3538 - val_loss: 0.4320\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.4679\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3405 - val_loss: 0.5767\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.4673\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.5454\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3296 - val_loss: 0.5765\n",
      "121/121 [==============================] - 0s 952us/step - loss: 0.4420\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3346 - val_loss: 0.9301\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5167 - val_loss: 1.0495\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4350 - val_loss: 0.5192\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4234 - val_loss: 0.4027\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.3724\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.4646\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3747 - val_loss: 0.5767\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3804 - val_loss: 0.6026\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.7661\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.5914\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.6084\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.6878\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3538 - val_loss: 0.7264\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.6627\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3752 - val_loss: 0.7097\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3750\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 4ms/step - loss: 1.7169 - val_loss: 11.7695\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5539 - val_loss: 11.5835\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4959 - val_loss: 24.3214\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1074 - val_loss: 7.1118\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 16.3869\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4673 - val_loss: 14.0548\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 4.1146\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5020 - val_loss: 0.6038\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.3981\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3889 - val_loss: 0.3660\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3982 - val_loss: 0.3588\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.3705\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3533 - val_loss: 0.3677\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3603 - val_loss: 0.3773\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.3818\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3681 - val_loss: 0.3863\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3544 - val_loss: 0.3803\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3835\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.3927\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3652 - val_loss: 0.3767\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3599 - val_loss: 0.3920\n",
      "121/121 [==============================] - 0s 911us/step - loss: 0.3560\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.7196 - val_loss: 2.1147\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.7930 - val_loss: 1.0904\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0401 - val_loss: 0.8717\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8399 - val_loss: 0.7978\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7453 - val_loss: 0.7637\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6976 - val_loss: 0.9539\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7038 - val_loss: 0.9115\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6633 - val_loss: 0.9150\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6499 - val_loss: 0.7103\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6449 - val_loss: 0.8962\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6131 - val_loss: 0.9130\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5813 - val_loss: 0.6472\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6271 - val_loss: 0.9216\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6104 - val_loss: 0.9877\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.6916\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5764 - val_loss: 0.8105\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6063 - val_loss: 0.8299\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5976 - val_loss: 0.9014\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5740 - val_loss: 0.9224\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5773 - val_loss: 0.8940\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5525 - val_loss: 0.6349\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5465 - val_loss: 0.8120\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5674 - val_loss: 0.8051\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5494 - val_loss: 0.7874\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5611 - val_loss: 0.6789\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5348 - val_loss: 0.5677\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5536 - val_loss: 0.8559\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5519 - val_loss: 0.5688\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5586 - val_loss: 0.7242\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 0.6296\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5300 - val_loss: 0.6162\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 0.5506\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 0.6676\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5290 - val_loss: 0.6517\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 0.5241\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 0.7211\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5285 - val_loss: 0.4970\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5063 - val_loss: 0.7689\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 0.5393\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5141 - val_loss: 0.5939\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5271 - val_loss: 0.7149\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5286 - val_loss: 0.5228\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5247 - val_loss: 0.5106\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5287 - val_loss: 0.7260\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5249 - val_loss: 0.6374\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5212 - val_loss: 0.5445\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5295 - val_loss: 0.6899\n",
      "121/121 [==============================] - 0s 942us/step - loss: 0.5362\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.3479 - val_loss: 2.4553\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4824 - val_loss: 0.8518\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8543 - val_loss: 1.1030\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7094 - val_loss: 2.1890\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6510 - val_loss: 3.6959\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6195 - val_loss: 5.4094\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6068 - val_loss: 7.1602\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5833 - val_loss: 8.9128\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5842 - val_loss: 10.5386\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5605 - val_loss: 11.9490\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5571 - val_loss: 13.3744\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5421 - val_loss: 14.6578\n",
      "121/121 [==============================] - 0s 839us/step - loss: 0.8872\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.7084 - val_loss: 1.8662\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4596 - val_loss: 0.9545\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8084 - val_loss: 0.7318\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6642 - val_loss: 0.9490\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 0.6142\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6051 - val_loss: 0.6865\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5996 - val_loss: 0.7155\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6094 - val_loss: 0.9473\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 0.7320\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5620 - val_loss: 0.5642\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5822 - val_loss: 0.8602\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5611 - val_loss: 0.6222\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 0.5509\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5469 - val_loss: 0.6462\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5670 - val_loss: 0.5655\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5609 - val_loss: 0.7729\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5424 - val_loss: 0.6007\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5628 - val_loss: 0.5707\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5584 - val_loss: 0.8382\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 0.6476\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5339 - val_loss: 0.6257\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5613 - val_loss: 0.6573\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5404 - val_loss: 0.5347\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5761\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 0.5594\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5339 - val_loss: 0.5075\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5438 - val_loss: 0.8151\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5365 - val_loss: 0.6117\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 0.7563\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5351 - val_loss: 0.6256\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5161 - val_loss: 0.6939\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5560 - val_loss: 0.7703\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5446 - val_loss: 0.7666\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 0.8131\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 0.8086\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5270 - val_loss: 0.5403\n",
      "121/121 [==============================] - 0s 989us/step - loss: 0.5370\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4507 - val_loss: 4.7146\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6904 - val_loss: 0.8579\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5945 - val_loss: 0.5235\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.4665\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.4308\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4394 - val_loss: 0.4266\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4262 - val_loss: 0.3982\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4064 - val_loss: 0.4098\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3875 - val_loss: 0.4003\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3844 - val_loss: 0.4010\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.3771\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3488 - val_loss: 0.3749\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3743 - val_loss: 0.3986\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3613 - val_loss: 0.4078\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3910\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.3972\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3627 - val_loss: 0.4096\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3652 - val_loss: 0.3878\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.3927\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3482 - val_loss: 0.3901\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3442 - val_loss: 0.4032\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.3806\n",
      "121/121 [==============================] - 0s 900us/step - loss: 0.3626\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4967 - val_loss: 2.5064\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6853 - val_loss: 1.1056\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5759 - val_loss: 0.6110\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5258 - val_loss: 0.4764\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4733 - val_loss: 0.6001\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.6127\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4030 - val_loss: 0.5762\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3976 - val_loss: 0.4785\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3821 - val_loss: 0.3788\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3784 - val_loss: 0.3589\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.3643\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3591 - val_loss: 0.3898\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3540 - val_loss: 0.4591\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.5911\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.6608\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3511 - val_loss: 0.7116\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.7958\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 0.9400\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3477 - val_loss: 0.8617\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3491 - val_loss: 0.8279\n",
      "121/121 [==============================] - 0s 979us/step - loss: 0.3614\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.3674 - val_loss: 6.6062\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6401 - val_loss: 1.3799\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5315 - val_loss: 0.4674\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4632 - val_loss: 0.5007\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4321 - val_loss: 0.4210\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3992 - val_loss: 0.4677\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3973 - val_loss: 0.3967\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4085 - val_loss: 0.4038\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3850 - val_loss: 0.4586\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3750 - val_loss: 0.3554\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.5397\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3642 - val_loss: 0.3704\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.3501\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3472 - val_loss: 0.5354\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3735 - val_loss: 0.3396\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3555 - val_loss: 0.4486\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3415 - val_loss: 0.3370\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.3853\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3620 - val_loss: 0.4336\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3497 - val_loss: 0.3800\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3407 - val_loss: 0.3549\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3551 - val_loss: 0.3281\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3376 - val_loss: 0.3514\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3312 - val_loss: 0.4534\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3313 - val_loss: 0.3534\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3318 - val_loss: 0.3704\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3437 - val_loss: 0.4422\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3404 - val_loss: 0.3236\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3387 - val_loss: 0.5099\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3327 - val_loss: 0.3324\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3205 - val_loss: 0.3705\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.4150\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.3968\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3126 - val_loss: 0.4108\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3199 - val_loss: 0.3126\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.4577\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3213 - val_loss: 0.3627\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.6810\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3284 - val_loss: 0.3128\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3203 - val_loss: 0.4535\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2970 - val_loss: 0.3632\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3059 - val_loss: 0.4231\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3178 - val_loss: 0.3436\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3254 - val_loss: 0.4581\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3056 - val_loss: 0.3069\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3036 - val_loss: 0.4151\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3067 - val_loss: 0.3228\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3017 - val_loss: 0.3372\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.4176\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3068 - val_loss: 0.3244\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3127 - val_loss: 0.4831\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3012 - val_loss: 0.3003\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3065 - val_loss: 0.3378\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3022 - val_loss: 0.3050\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2974 - val_loss: 0.3716\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3033 - val_loss: 0.3061\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2988 - val_loss: 0.4754\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3081 - val_loss: 0.3258\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3073 - val_loss: 0.5514\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3059 - val_loss: 0.3128\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3077 - val_loss: 0.4331\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2954 - val_loss: 0.3114\n",
      "121/121 [==============================] - 0s 906us/step - loss: 0.3096\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3090 - val_loss: 57.3582\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7631 - val_loss: 91.9754\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0398 - val_loss: 728.5334\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.4581 - val_loss: 2593.5779\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7.1066 - val_loss: 14511.6504\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 425.7737 - val_loss: 70093.5312\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 654.2595 - val_loss: 344974.1875\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7104.4847 - val_loss: 1687624.1250\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 8398.5480 - val_loss: 8323115.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 219081.6030 - val_loss: 43390992.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 646474.5919 - val_loss: 210583696.0000\n",
      "121/121 [==============================] - 0s 765us/step - loss: 560137.4375\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.1679 - val_loss: 13.8923\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 19.5349\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5615 - val_loss: 22.2693\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 21.4686\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5195 - val_loss: 21.0216\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5112 - val_loss: 20.7014\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4939 - val_loss: 19.9036\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5139 - val_loss: 21.0553\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5012 - val_loss: 19.9696\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4824 - val_loss: 15.2080\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5090 - val_loss: 19.0376\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9495\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.9092 - val_loss: 9.5512\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6395 - val_loss: 0.5289\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5906 - val_loss: 89.7746\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3984 - val_loss: 190.7023\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6444 - val_loss: 1022.8389\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.9746 - val_loss: 1458.7605\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0564 - val_loss: 3025.8481\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 114.1252 - val_loss: 5764.1558\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 30.7031 - val_loss: 10943.1455\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 14.1326 - val_loss: 17092.8926\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 920.5803 - val_loss: 30534.7559\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 80.5056 - val_loss: 53874.7617\n",
      "121/121 [==============================] - 0s 781us/step - loss: 57.5214\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1554 - val_loss: 1.0052\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9200 - val_loss: 0.8017\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8058 - val_loss: 0.7472\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7389 - val_loss: 0.6796\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6880 - val_loss: 0.6486\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6382 - val_loss: 0.6218\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6278 - val_loss: 0.5858\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5884 - val_loss: 0.5640\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5527 - val_loss: 0.5338\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5522 - val_loss: 0.5332\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 0.5038\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4899 - val_loss: 0.4956\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5156 - val_loss: 0.4970\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5079 - val_loss: 0.4650\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.4573\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4718 - val_loss: 0.4570\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.4473\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.4578\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4554 - val_loss: 0.4293\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4582 - val_loss: 0.4358\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4490 - val_loss: 0.4224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4349 - val_loss: 0.4259\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.4167\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 0.4219\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.4138\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4136\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4457 - val_loss: 0.4072\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4056\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4372 - val_loss: 0.4090\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4272 - val_loss: 0.4158\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.4105\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4165 - val_loss: 0.4139\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.3978\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.4014\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4105 - val_loss: 0.4041\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.3952\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.4213\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.3975\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 0.4035\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3940 - val_loss: 0.3923\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 0.3912\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.3933\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.3959\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.3967\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.3892\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3947 - val_loss: 0.3864\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4064 - val_loss: 0.3854\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3867 - val_loss: 0.3854\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4148 - val_loss: 0.3872\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.3863\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3853 - val_loss: 0.3834\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.3829\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.3825\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3986 - val_loss: 0.3832\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3870 - val_loss: 0.3820\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4220 - val_loss: 0.3811\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3995 - val_loss: 0.3833\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.3794\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3994 - val_loss: 0.3799\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.3794\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.3778\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3883 - val_loss: 0.3854\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.3782\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3853 - val_loss: 0.3780\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.3775\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4238 - val_loss: 0.3767\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.3755\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.3755\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3996 - val_loss: 0.3753\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.3751\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.3742\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.3743\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4030 - val_loss: 0.3743\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4010 - val_loss: 0.3939\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.3856\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3877 - val_loss: 0.3893\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3769\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3799 - val_loss: 0.3933\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.3812\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3874 - val_loss: 0.3796\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3651 - val_loss: 0.3948\n",
      "121/121 [==============================] - 0s 858us/step - loss: 0.4093\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.4596 - val_loss: 37.6565\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0097 - val_loss: 23.2195\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8197 - val_loss: 12.2851\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7242 - val_loss: 5.8536\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6758 - val_loss: 2.4889\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6398 - val_loss: 1.1222\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6125 - val_loss: 0.6489\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5796 - val_loss: 0.5745\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5683 - val_loss: 0.7584\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5415 - val_loss: 1.0834\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5288 - val_loss: 1.1827\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5055 - val_loss: 1.2593\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 1.3219\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4824 - val_loss: 1.3323\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5117 - val_loss: 1.3683\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4861 - val_loss: 1.3687\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 1.3746\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4886 - val_loss: 1.3710\n",
      "121/121 [==============================] - 0s 922us/step - loss: 0.5194\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.9321 - val_loss: 1.4106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9994 - val_loss: 0.8862\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7284 - val_loss: 0.6484\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6445 - val_loss: 0.5858\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5951 - val_loss: 0.6210\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5579 - val_loss: 0.5397\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5449 - val_loss: 0.5027\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5443 - val_loss: 0.4836\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5212 - val_loss: 0.5105\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4971 - val_loss: 0.4809\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5130 - val_loss: 0.4609\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4814 - val_loss: 0.4803\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4519 - val_loss: 0.4548\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.4726\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4947 - val_loss: 0.4614\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4707 - val_loss: 0.4404\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4512 - val_loss: 0.4382\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4732 - val_loss: 0.4421\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4598 - val_loss: 0.4407\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4554 - val_loss: 0.4357\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4431 - val_loss: 0.4347\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4672 - val_loss: 0.4263\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4393 - val_loss: 0.4318\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4292 - val_loss: 0.4564\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4416 - val_loss: 0.4187\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.4171\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.4389\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.4150\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4274 - val_loss: 0.4383\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.4268\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.4192\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4451 - val_loss: 0.4345\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4288 - val_loss: 0.4264\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4444\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 0.4183\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.4130\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4202 - val_loss: 0.4020\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 0.4317\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4244 - val_loss: 0.4093\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4112 - val_loss: 0.4147\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3886 - val_loss: 0.4330\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4030 - val_loss: 0.4241\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4135 - val_loss: 0.3966\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4125 - val_loss: 0.4185\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3974 - val_loss: 0.4274\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3950 - val_loss: 0.4448\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.4282\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4005 - val_loss: 0.4265\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 0.4494\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3940 - val_loss: 0.4492\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4167 - val_loss: 0.4533\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 0.4502\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3983 - val_loss: 0.4363\n",
      "121/121 [==============================] - 0s 823us/step - loss: 0.3941\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2646 - val_loss: 1.0616\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6187 - val_loss: 18.5438\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 10.2514\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 2.3169\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.3914\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4012 - val_loss: 0.3948\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3966 - val_loss: 0.3854\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3855 - val_loss: 0.3970\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3926\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3910\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3548 - val_loss: 0.3685\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3421 - val_loss: 0.3670\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.3716\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3571 - val_loss: 0.3871\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3553 - val_loss: 0.3739\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 0.3782\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3611 - val_loss: 0.3818\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3647 - val_loss: 0.3796\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3425 - val_loss: 0.3810\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3497 - val_loss: 0.3652\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3441 - val_loss: 0.3691\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3368 - val_loss: 0.3653\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3470 - val_loss: 0.3598\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.3389\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3448 - val_loss: 0.3586\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.3368\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3509 - val_loss: 0.3530\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3618\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3396 - val_loss: 0.3552\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.3334\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3352 - val_loss: 0.3296\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3262 - val_loss: 0.3259\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3270 - val_loss: 0.3460\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3225 - val_loss: 0.3507\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3253 - val_loss: 0.3213\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3230 - val_loss: 0.3537\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3212 - val_loss: 0.3141\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3292 - val_loss: 0.3648\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3169 - val_loss: 0.3179\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3049 - val_loss: 0.3476\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.3178\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3212 - val_loss: 0.3150\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3193 - val_loss: 0.3162\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3159 - val_loss: 0.3337\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3223 - val_loss: 0.3115\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3019 - val_loss: 0.3254\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3109 - val_loss: 0.3453\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3027 - val_loss: 0.3291\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3255 - val_loss: 0.3046\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3042 - val_loss: 0.3452\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2961 - val_loss: 0.3366\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3211 - val_loss: 0.3362\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3036 - val_loss: 0.3245\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3028 - val_loss: 0.3081\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3005 - val_loss: 0.3452\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3232 - val_loss: 0.3005\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3067 - val_loss: 0.3466\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3046 - val_loss: 0.3254\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3099 - val_loss: 0.2977\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2993 - val_loss: 0.3188\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2922 - val_loss: 0.3395\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2921 - val_loss: 0.3358\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3028 - val_loss: 0.3162\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2910 - val_loss: 0.3543\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2820 - val_loss: 0.3180\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3167 - val_loss: 0.2965\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2982 - val_loss: 0.3834\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2928 - val_loss: 0.3044\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2917 - val_loss: 0.3515\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.3018\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2972 - val_loss: 0.3353\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3105 - val_loss: 0.3108\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3001 - val_loss: 0.2946\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2977 - val_loss: 0.4249\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2910 - val_loss: 0.2905\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2918 - val_loss: 0.3864\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2802 - val_loss: 0.3235\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2802 - val_loss: 0.5268\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2888 - val_loss: 0.3005\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2834 - val_loss: 0.4453\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2758 - val_loss: 0.2926\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2733 - val_loss: 0.4031\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2654 - val_loss: 0.2867\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2901 - val_loss: 0.4039\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2863 - val_loss: 0.2857\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2705 - val_loss: 0.3945\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2682 - val_loss: 0.3432\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2870 - val_loss: 0.3827\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2795 - val_loss: 0.3029\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2676 - val_loss: 0.5373\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2934 - val_loss: 0.4111\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2951 - val_loss: 0.5079\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3016 - val_loss: 0.3130\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2844 - val_loss: 0.3582\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2648 - val_loss: 0.3251\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3181\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7387 - val_loss: 1.1363\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5409 - val_loss: 0.7875\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 1.0076\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.7761\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4198 - val_loss: 0.5573\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3966 - val_loss: 0.3753\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3807 - val_loss: 0.3905\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3868 - val_loss: 0.4174\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.5520\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4537\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.5535\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.5405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3506 - val_loss: 0.6752\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3404 - val_loss: 0.6284\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3654 - val_loss: 0.6078\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3454 - val_loss: 0.5916\n",
      "121/121 [==============================] - 0s 971us/step - loss: 0.3667\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.8751 - val_loss: 1.5162\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5599 - val_loss: 9.0229\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5018 - val_loss: 7.8586\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 1.0625\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4054 - val_loss: 0.5701\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.5088\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3788 - val_loss: 0.4782\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3971 - val_loss: 0.4620\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.4618\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4360\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.4510\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3577 - val_loss: 0.4443\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3384 - val_loss: 0.4263\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3466 - val_loss: 0.4340\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3696 - val_loss: 0.4183\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3529 - val_loss: 0.4203\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3367 - val_loss: 0.4156\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 0.4130\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.4173\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3507 - val_loss: 0.4066\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3454 - val_loss: 0.4039\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3545 - val_loss: 0.3880\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3371 - val_loss: 0.3867\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3328 - val_loss: 0.4113\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3305 - val_loss: 0.3581\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3293 - val_loss: 0.3561\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3411 - val_loss: 0.3846\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3386 - val_loss: 0.3618\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3346 - val_loss: 0.3922\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3306 - val_loss: 0.3797\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3191 - val_loss: 0.3708\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.3790\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3246 - val_loss: 0.4200\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3141 - val_loss: 0.3913\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3147 - val_loss: 0.3794\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3097 - val_loss: 0.3639\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3263\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 4ms/step - loss: 3.6355 - val_loss: 2.8270\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8705 - val_loss: 0.8048\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5993 - val_loss: 0.5299\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5776 - val_loss: 0.5277\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5512 - val_loss: 0.5180\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5467 - val_loss: 0.8690\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5574 - val_loss: 0.6085\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5395 - val_loss: 0.6957\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5434 - val_loss: 0.5092\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.8496\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5330 - val_loss: 0.6773\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5040 - val_loss: 0.5298\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 1.0519\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5588 - val_loss: 0.8051\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5463 - val_loss: 0.4968\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 0.7700\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5569 - val_loss: 0.6655\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5541 - val_loss: 0.8302\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5376 - val_loss: 0.8192\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5422 - val_loss: 0.7860\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.4938\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 0.8925\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5471 - val_loss: 0.6560\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5287 - val_loss: 0.6951\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5409 - val_loss: 0.5301\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5213 - val_loss: 0.4961\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 1.1069\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5353 - val_loss: 0.5457\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5447 - val_loss: 0.8344\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 0.4971\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5351\n",
      "121/121 [==============================] - 0s 907us/step - loss: 0.5343\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.5649 - val_loss: 13.4471\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4681 - val_loss: 4.4784\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9071 - val_loss: 1.1126\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7823 - val_loss: 0.8591\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7111 - val_loss: 2.2521\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6616 - val_loss: 4.4444\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6370 - val_loss: 6.8539\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 9.2874\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5930 - val_loss: 11.4397\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5688 - val_loss: 13.0991\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5623 - val_loss: 14.8188\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 16.2545\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5422 - val_loss: 17.4981\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5061 - val_loss: 18.0887\n",
      "121/121 [==============================] - 0s 924us/step - loss: 0.9629\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.6993 - val_loss: 5.5735\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1838 - val_loss: 0.8289\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8059 - val_loss: 0.7539\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7284 - val_loss: 1.2672\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6761 - val_loss: 0.7809\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6672 - val_loss: 0.7607\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6463 - val_loss: 0.6682\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6425 - val_loss: 1.1709\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6201 - val_loss: 0.6062\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5856 - val_loss: 0.6060\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6062 - val_loss: 1.2251\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5681 - val_loss: 0.5439\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5344 - val_loss: 0.5470\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5507 - val_loss: 0.6486\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5750 - val_loss: 0.5270\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5609 - val_loss: 0.9385\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5427 - val_loss: 0.5128\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5653 - val_loss: 0.5173\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5540 - val_loss: 1.0549\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5398 - val_loss: 0.5139\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5343 - val_loss: 0.5667\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5580 - val_loss: 0.5992\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5379 - val_loss: 0.5227\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5287 - val_loss: 0.5436\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5268 - val_loss: 0.4976\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5338 - val_loss: 0.5613\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5443 - val_loss: 1.2042\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 0.4953\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.8868\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5342 - val_loss: 0.5118\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5140 - val_loss: 0.7110\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5589 - val_loss: 0.7705\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5451 - val_loss: 0.7363\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 0.8367\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.7934\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 0.5139\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.5342\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5380 - val_loss: 0.9711\n",
      "121/121 [==============================] - 0s 841us/step - loss: 0.5253\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.8358 - val_loss: 1.7451\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8647 - val_loss: 0.7198\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7107 - val_loss: 0.6231\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6632 - val_loss: 0.5931\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6245 - val_loss: 0.5619\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5743 - val_loss: 0.5256\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5625 - val_loss: 0.5014\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5262 - val_loss: 0.4889\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5046 - val_loss: 0.4888\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.4500\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.4374\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 0.4376\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.4235\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.4453\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4363 - val_loss: 0.4311\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4171 - val_loss: 0.4160\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4310 - val_loss: 0.4469\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4272 - val_loss: 0.4133\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.4455\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4063 - val_loss: 0.4142\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3980 - val_loss: 0.4346\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3854 - val_loss: 0.4103\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3982 - val_loss: 0.4087\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.3743\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4244\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.3691\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3977 - val_loss: 0.4283\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.3823\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3876 - val_loss: 0.4221\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.3627\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.3706\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3651 - val_loss: 0.3592\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 0.4134\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.3754\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3635 - val_loss: 0.3485\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3609 - val_loss: 0.4470\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3617 - val_loss: 0.3752\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.5443\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3620 - val_loss: 0.3548\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3473 - val_loss: 0.4429\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3557 - val_loss: 0.3523\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3578 - val_loss: 0.3462\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3574 - val_loss: 0.3437\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3561 - val_loss: 0.4489\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.3411\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3406 - val_loss: 0.3781\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3527 - val_loss: 0.3808\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 0.3525\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.3494\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3483 - val_loss: 0.4169\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3345 - val_loss: 0.3574\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3602 - val_loss: 0.3474\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3435 - val_loss: 0.3643\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3510 - val_loss: 0.3353\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3363 - val_loss: 0.4186\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3665 - val_loss: 0.3342\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.4318\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3517 - val_loss: 0.3509\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3513 - val_loss: 0.3409\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3433 - val_loss: 0.3551\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.3648\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.3964\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3514 - val_loss: 0.3438\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3337 - val_loss: 0.4157\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3239 - val_loss: 0.3542\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3660 - val_loss: 0.3420\n",
      "121/121 [==============================] - 0s 830us/step - loss: 0.3630\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.6968 - val_loss: 11.5455\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8800 - val_loss: 6.9542\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7398 - val_loss: 4.0216\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6894 - val_loss: 2.2844\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6527 - val_loss: 1.3541\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6066 - val_loss: 0.8723\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5713 - val_loss: 0.5755\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5388 - val_loss: 0.4996\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 0.5185\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4989 - val_loss: 0.5813\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4774 - val_loss: 0.6502\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4512 - val_loss: 0.7764\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4467 - val_loss: 0.8238\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.7605\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4540 - val_loss: 0.7675\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4315 - val_loss: 0.7099\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 0.6694\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 0.6167\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4302\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.6540 - val_loss: 1.1995\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9936 - val_loss: 0.7058\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6950 - val_loss: 0.6181\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6311 - val_loss: 0.5786\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5898 - val_loss: 0.5513\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5538 - val_loss: 0.5230\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5418 - val_loss: 0.4991\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5292 - val_loss: 0.4871\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5057 - val_loss: 0.4718\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4750 - val_loss: 0.4518\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4821 - val_loss: 0.4425\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.4333\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4239 - val_loss: 0.4197\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4282 - val_loss: 0.4396\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.4085\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4329 - val_loss: 0.4125\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.3957\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4277 - val_loss: 0.3909\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4233 - val_loss: 0.4027\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4103 - val_loss: 0.3896\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.3858\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4203 - val_loss: 0.3814\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3962 - val_loss: 0.3777\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3929 - val_loss: 0.4041\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3925 - val_loss: 0.3695\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3904 - val_loss: 0.3682\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4010 - val_loss: 0.4054\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3979 - val_loss: 0.3696\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3813 - val_loss: 0.4236\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3834 - val_loss: 0.3685\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.3638\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3975 - val_loss: 0.3983\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3788 - val_loss: 0.3737\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3662 - val_loss: 0.4105\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3607\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3588\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.3543\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3670 - val_loss: 0.3939\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.3523\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3726 - val_loss: 0.3666\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3474 - val_loss: 0.3949\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.3711\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.3510\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.3745\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3553 - val_loss: 0.3631\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.3652\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3505\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3547 - val_loss: 0.3444\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.3913\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.3637\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.3650\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.3654\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3553 - val_loss: 0.3395\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3389\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.3396\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 0.3462\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3677\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3567 - val_loss: 0.3445\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3541 - val_loss: 0.3516\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3631 - val_loss: 0.3362\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3621 - val_loss: 0.3381\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3635\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3472 - val_loss: 0.3342\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3380\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3529 - val_loss: 0.3364\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.3652\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3524 - val_loss: 0.3339\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.3619\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.336 - 0s 2ms/step - loss: 0.3385 - val_loss: 0.3359\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 0.3597\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3630 - val_loss: 0.3323\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.3438\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3479 - val_loss: 0.3325\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3444 - val_loss: 0.3304\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3370 - val_loss: 0.3434\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3477 - val_loss: 0.3593\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3504 - val_loss: 0.3299\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3452 - val_loss: 0.3326\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3453 - val_loss: 0.3305\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 0.3331\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3307 - val_loss: 0.3317\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3356 - val_loss: 0.3353\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3285 - val_loss: 0.3293\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.3646\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3361 - val_loss: 0.3481\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3314 - val_loss: 0.3320\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3368 - val_loss: 0.3601\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3228 - val_loss: 0.3261\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3442 - val_loss: 0.3544\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3314 - val_loss: 0.3280\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3412 - val_loss: 0.3381\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3466\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3266 - val_loss: 0.3802\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3436 - val_loss: 0.3239\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.3431\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3304 - val_loss: 0.3389\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3315 - val_loss: 0.3413\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3265 - val_loss: 0.3489\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3225 - val_loss: 0.3902\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3211 - val_loss: 0.3325\n",
      "121/121 [==============================] - 0s 963us/step - loss: 0.3390\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4281 - val_loss: 2.0303\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 14.0501\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4829 - val_loss: 4.7639\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4228 - val_loss: 3.5068\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3933 - val_loss: 44.1242\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0227 - val_loss: 0.5355\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4035 - val_loss: 23.5814\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6828 - val_loss: 5.3871\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.3793\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.3397\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3347 - val_loss: 0.3442\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3235 - val_loss: 0.3508\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3600 - val_loss: 0.3451\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3300 - val_loss: 0.3348\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3234 - val_loss: 0.3305\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3228 - val_loss: 0.3403\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3299 - val_loss: 0.3387\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3363 - val_loss: 0.3463\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3121 - val_loss: 0.3441\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3168 - val_loss: 0.3372\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3133 - val_loss: 0.3469\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3046 - val_loss: 0.3575\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3098 - val_loss: 0.3547\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.3138\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3099 - val_loss: 0.3444\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2951 - val_loss: 0.3224\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3120 - val_loss: 0.3341\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3039 - val_loss: 0.3189\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2990 - val_loss: 0.3357\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2983 - val_loss: 0.3078\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2934 - val_loss: 0.3120\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2838 - val_loss: 0.2931\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2884 - val_loss: 0.3250\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2839 - val_loss: 0.3304\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2856 - val_loss: 0.2973\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2874 - val_loss: 0.3258\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2757 - val_loss: 0.2966\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2898 - val_loss: 0.3419\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2795 - val_loss: 0.3061\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2659 - val_loss: 0.3068\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2767 - val_loss: 0.2924\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2798 - val_loss: 0.3047\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2791 - val_loss: 0.2861\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2750 - val_loss: 0.3819\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2787 - val_loss: 0.2849\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2668 - val_loss: 0.3180\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2696 - val_loss: 0.2810\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2663 - val_loss: 0.3015\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2780 - val_loss: 1.2181\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3138 - val_loss: 0.3572\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2615 - val_loss: 0.3000\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2780 - val_loss: 0.3593\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2648 - val_loss: 0.2812\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2603 - val_loss: 0.2869\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2644 - val_loss: 0.3389\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2826 - val_loss: 0.2939\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2736 - val_loss: 0.3389\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3122\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4916 - val_loss: 0.4903\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4769 - val_loss: 0.3935\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4030 - val_loss: 0.6605\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3953 - val_loss: 0.5726\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.4826\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3624 - val_loss: 0.6819\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3498 - val_loss: 0.8798\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3524 - val_loss: 0.6548\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.6669\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.3292\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.4355\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3265 - val_loss: 0.4744\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3209 - val_loss: 0.5687\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3152 - val_loss: 0.3467\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.4113\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3177 - val_loss: 0.3797\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3278 - val_loss: 0.3102\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3290 - val_loss: 0.3382\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3217 - val_loss: 0.4956\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3196 - val_loss: 0.3106\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3137 - val_loss: 0.3484\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3160 - val_loss: 0.3141\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3133 - val_loss: 0.3367\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3080 - val_loss: 0.3250\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.2885 - val_loss: 0.3342\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2962 - val_loss: 0.3487\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3102 - val_loss: 0.3379\n",
      "121/121 [==============================] - 0s 908us/step - loss: 0.3286\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.5797 - val_loss: 2.0113\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4947 - val_loss: 6.6799\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 3.5218\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4426 - val_loss: 0.4432\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3752 - val_loss: 0.4053\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 0.3677\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3504 - val_loss: 0.3404\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3725\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.3981\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3513 - val_loss: 0.5310\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3686 - val_loss: 1.2319\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3396 - val_loss: 0.6328\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3163 - val_loss: 0.9565\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3282 - val_loss: 0.3822\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.3830\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3277 - val_loss: 0.3707\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3173 - val_loss: 0.3962\n",
      "121/121 [==============================] - 0s 914us/step - loss: 0.3324\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.8471 - val_loss: 960.8043\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.4832 - val_loss: 2935.6733\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 9.9291 - val_loss: 16503.0195\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 33.7284 - val_loss: 66904.0703\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 122.9314 - val_loss: 323209.8125\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 12975.1795 - val_loss: 1470428.2500\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 11894.1113 - val_loss: 6868802.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 180729.6782 - val_loss: 32001202.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 165497.9608 - val_loss: 150264064.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5372171.1468 - val_loss: 762475520.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 11077679.8233 - val_loss: 3510366208.0000\n",
      "121/121 [==============================] - 0s 731us/step - loss: 9299110.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.9363 - val_loss: 7.4193\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5302 - val_loss: 20.3954\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5274 - val_loss: 24.5031\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5073 - val_loss: 22.5275\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 21.9264\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5086 - val_loss: 21.3398\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4930 - val_loss: 19.9948\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5197 - val_loss: 22.3743\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5022 - val_loss: 20.1167\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4828 - val_loss: 11.3086\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5122 - val_loss: 19.6184\n",
      "121/121 [==============================] - 0s 906us/step - loss: 0.9624\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0255 - val_loss: 691.5567\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8212 - val_loss: 340.5777\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.5377 - val_loss: 1374.5984\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 71.1765 - val_loss: 1359.4503\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6666 - val_loss: 3841.7917\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 9.4562 - val_loss: 2633.5271\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.7724 - val_loss: 2972.5684\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 137.4193 - val_loss: 2972.0820\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12.2204 - val_loss: 3070.8611\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.8773 - val_loss: 1283.4507\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 108.9408 - val_loss: 1050.6660\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.3612 - val_loss: 541.3770\n",
      "121/121 [==============================] - 0s 722us/step - loss: 0.7811\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.1011 - val_loss: 4.9358\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6967 - val_loss: 8.1044\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5419 - val_loss: 0.4479\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3962 - val_loss: 14.0478\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3896 - val_loss: 22.2882\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5739 - val_loss: 0.3589\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4019 - val_loss: 1.4908\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 1.3867\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3565 - val_loss: 7.5702\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5332 - val_loss: 2.5372\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3401 - val_loss: 2.4622\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4005 - val_loss: 1.1562\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3387 - val_loss: 0.3194\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3268 - val_loss: 0.3209\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3250 - val_loss: 0.3205\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3277 - val_loss: 0.3135\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3092 - val_loss: 0.3198\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3126 - val_loss: 0.3081\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3058 - val_loss: 0.3072\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2968 - val_loss: 0.3167\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3020 - val_loss: 0.3070\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2895 - val_loss: 0.3018\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.307 - 1s 1ms/step - loss: 0.3071 - val_loss: 0.3044\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2966 - val_loss: 0.2928\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2923 - val_loss: 0.2916\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2944 - val_loss: 0.2969\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2942 - val_loss: 0.2876\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2923 - val_loss: 0.2902\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2840 - val_loss: 0.2862\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.2953\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2826 - val_loss: 0.2966\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2820 - val_loss: 0.2911\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2823 - val_loss: 0.2840\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2749 - val_loss: 0.2887\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2712 - val_loss: 0.2783\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2696 - val_loss: 0.2764\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2931 - val_loss: 0.2787\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2745 - val_loss: 0.2763\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2869 - val_loss: 0.2728\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2743 - val_loss: 0.2743\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2826 - val_loss: 0.2732\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2667 - val_loss: 0.2680\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2769 - val_loss: 0.3066\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2663 - val_loss: 0.2777\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2705 - val_loss: 0.2666\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2731 - val_loss: 0.2789\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2806 - val_loss: 0.2717\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2613 - val_loss: 0.2706\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2679 - val_loss: 0.2728\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.274 - 1s 2ms/step - loss: 0.2730 - val_loss: 0.2622\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2670 - val_loss: 0.2658\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2640 - val_loss: 0.2664\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2638 - val_loss: 0.2873\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2517 - val_loss: 0.2776\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2638 - val_loss: 0.2713\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2579 - val_loss: 0.2683\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2528 - val_loss: 0.2635\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2512 - val_loss: 0.3108\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2604 - val_loss: 0.2645\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2589 - val_loss: 0.2651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000021B11F84E80>,\n",
       "                   param_distributions={'learning_rate': [0.008970833342026068,\n",
       "                                                          0.0032919821711509113,\n",
       "                                                          0.002141683880893672,\n",
       "                                                          0.017000120918675775,\n",
       "                                                          0.0020517924281260934,\n",
       "                                                          0.0025177172524152723,\n",
       "                                                          0.02869484488292748,\n",
       "                                                          0.00030032833048423545,\n",
       "                                                          0.000704801912495...\n",
       "                                                          0.0018780018799311132,\n",
       "                                                          0.00045763573021745987,\n",
       "                                                          0.001412089365586438,\n",
       "                                                          0.0033278185478667808,\n",
       "                                                          0.008743088391841593,\n",
       "                                                          0.00030465897654504114,\n",
       "                                                          0.0025807312921102546,\n",
       "                                                          0.001177950409891257,\n",
       "                                                          0.015232279431175843,\n",
       "                                                          0.00809520563460375,\n",
       "                                                          0.004522080858943114, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10,cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "unlikely-impression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 72, 'n_hidden': 2, 'learning_rate': 0.011017704084849417}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "exterior-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3243759473164876"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dimensional-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
